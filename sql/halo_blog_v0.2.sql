/*
 Navicat Premium Data Transfer

 Source Server         : Halo
 Source Server Type    : MySQL
 Source Server Version : 80022
 Source Host           : mysql:3306
 Source Schema         : halo_blog

 Target Server Type    : MySQL
 Target Server Version : 80022
 File Encoding         : 65001

 Date: 09/10/2021 15:36:08
*/

SET NAMES utf8mb4;
SET FOREIGN_KEY_CHECKS = 0;

-- ----------------------------
-- Table structure for m_blog
-- ----------------------------
DROP TABLE IF EXISTS `m_blog`;
CREATE TABLE `m_blog`  (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `user_id` bigint NOT NULL,
  `blog_title` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `description` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NOT NULL,
  `content` longtext CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL,
  `created` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP,
  `status` tinyint NULL DEFAULT 1 COMMENT '状态（1:正常,0:删除）',
  `blog_cover` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL,
  `blog_like` int NULL DEFAULT 0,
  `update_time` datetime NULL DEFAULT NULL,
  `tag_uid` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '标签id',
  `collect_count` int NULL DEFAULT NULL COMMENT '收藏数',
  `blog_sort_uid` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_0900_ai_ci NULL DEFAULT NULL COMMENT '博客分类id',
  `is_publish` tinyint NULL DEFAULT 1 COMMENT '是否发布（0:否,1:是）',
  `is_open_comment` tinyint(1) NULL DEFAULT 1 COMMENT '是否开启评论（0:否,1:是）',
  `is_original` tinyint(1) NULL DEFAULT 0 COMMENT '是否原创(0:否,1:是)',
  `create_time` datetime NULL DEFAULT NULL COMMENT '创建时间',
  `deleted` tinyint(1) NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 16 CHARACTER SET = utf8mb4 COLLATE = utf8mb4_0900_ai_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of m_blog
-- ----------------------------
INSERT INTO `m_blog` VALUES (1, 1, '123', '123', '123', '2021-09-23 13:11:11', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-23 13:11:11', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (2, 1, '1234', '1', '1', '2021-09-23 19:02:55', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-23 19:02:55', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (3, 1, '12345', '12345', '12345', '2021-09-23 19:03:08', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-23 19:03:08', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (4, 1, '123456', '123456', '123456', '2021-09-23 19:03:19', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-23 19:03:19', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (5, 1, '1234567', '1234567', '1234567', '2021-09-23 19:03:31', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-23 19:03:31', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (6, 1, '12345678', '12345678', '12345678', '2021-09-23 19:03:41', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 1, '2021-09-23 19:03:41', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (7, 1, 'Docker', '初识 Docker', '## 初识 Docker\n\n### 什么是 Docker\n\n微服务虽然具备各种各样的优势，但服务的拆分通用给部署带来了很大的麻烦。\n\n- 分布式系统中，依赖的组件非常多，不同组件之间部署时往往会产生一些冲突。\n- 在数百上千台服务中重复部署，环境不一定一致，会遇到各种问题\n\n#### 应用部署的环境问题\n\n大型项目组件较多，运行环境也较为复杂，部署时会碰到一些问题：\n\n- 依赖关系复杂，容易出现兼容性问题\n\n- 开发、测试、生产环境有差异\n\n例如一个项目中，部署时需要依赖于 node.js、Redis、RabbitMQ、MySQL 等，这些服务部署时所需要的函数库、依赖项各不相同，甚至会有冲突。给部署带来了极大的困难。\n\n#### Docker 解决依赖兼容问题\n\n而 Docker 确巧妙的解决了这些问题，Docker 是如何实现的呢？\n\nDocker 为了解决依赖的兼容问题的，采用了两个手段：\n\n- 将应用的 Libs（函数库）、Deps（依赖）、配置与应用一起打包\n\n- 将每个应用放到一个隔离**容器**去运行，避免互相干扰\n\n这样打包好的应用包中，既包含应用本身，也保护应用所需要的 Libs、Deps，无需再操作系统上安装这些，自然就不存在不同应用之间的兼容问题了。\n\n虽然解决了不同应用的兼容问题，但是开发、测试等环境会存在差异，操作系统版本也会有差异，怎么解决这些问题呢？\n\n#### Docker 解决操作系统环境差异\n\n要解决不同操作系统环境差异问题，必须先了解操作系统结构。计算机系统结构如下：\n\n- 计算机硬件：例如 CPU、内存、磁盘等\n- 系统内核：所有 Linux 发行版的内核都是 Linux，例如 CentOS、Ubuntu、Fedora 等。内核可以与计算机硬件交互，对外提供内核指令，用于操作计算机硬件。\n- 系统应用：操作系统本身提供的应用、函数库。这些函数库是对内核指令的封装，使用更加方便。\n\n应用于计算机交互的流程如下：\n\n+ 应用调用操作系统应用（函数库），实现各种功能\n+ 系统函数库是对内核指令集的封装，会调用内核指令\n+ 内核指令操作计算机硬件\n\nUbuntu 和 CentOS 都是基于 Linux 内核，无非是系统应用不同，提供的函数库有差异。此时，如果将一个 Ubuntu 版本的 MySQL 应用安装到 CentOS 系统，MySQL 在调用 Ubuntu 函数库时，会发现找不到或者不匹配，就会报错了。\n\nDocker 如何解决不同系统环境的问题？\n\n- Docker 将用户程序与所需要调用的系统（比如 Ubuntu）函数库一起打包\n- Docker 运行到不同操作系统时，直接基于打包的函数库，借助于操作系统的 Linux 内核来运行\n\n#### 什么是 Docker 小结\n\nDocker 如何解决大型项目依赖关系复杂，不同组件依赖的兼容性问题？\n\n- Docker 允许开发中将应用、依赖、函数库、配置一起**打包**，形成可移植镜像\n- Docker 应用运行在容器中，使用沙箱机制，相互**隔离**\n\nDocker如何解决开发、测试、生产环境有差异的问题？\n\n- Docker 镜像中包含完整运行环境，包括系统函数库，仅依赖系统的 Linux 内核，因此可以在任意 Linux 操作系统上运行\n\nDocker 是一个快速交付应用、运行应用的技术，具备下列优势：\n\n- 可以将程序及其依赖、运行环境一起打包为一个镜像，可以迁移到任意 Linux 操作系统\n- 运行时利用沙箱机制形成隔离容器，各个应用互不干扰\n- 启动、移除都可以通过一行命令完成，方便快捷\n\n### Docker 和虚拟机的区别\n\nDocker 可以让一个应用在任何操作系统中非常方便的运行。而以前我们接触的虚拟机，也能在一个操作系统中，运行另外一个操作系统，保护系统中的任何应用。\n\n虚拟机（virtual machine）是在操作系统中模拟硬件设备，然后运行另一个操作系统，比如在 Windows 系统里面运行 Ubuntu 系统，这样就可以运行任意的 Ubuntu 应用了。\n\nDocker 仅仅是封装函数库，并没有模拟完整的操作系统\n\n两者有什么差异呢？\n\n- Docker 是一个系统进程；虚拟机是在操作系统中的操作系统\n\n- Docker 体积小、启动速度快、性能好；虚拟机体积大、启动速度慢、性能一般\n\n### Docker 基本知识\n\n#### 镜像和容器\n\nDocker 中有几个重要的概念：\n\n+ 镜像（Image）：Docker 将应用程序及其所需的依赖、函数库、环境、配置等文件打包在一起，称为镜像。\n+ 容器（Container）：镜像中的应用程序运行后形成的进程就是**容器**，只是 Docker 会给容器进程做隔离，对外不可见。\n\n一切应用最终都是代码组成，都是硬盘中的一个个的字节形成的**文件**。只有运行时，才会加载到内存，形成进程。\n\n+ 镜像，就是把一个应用在硬盘上的文件、及其运行环境、部分系统函数库文件一起打包形成的文件包。这个文件包是只读的。\n+ 容器，就是将这些文件中编写的程序、函数加载到内存中允许，形成进程，只不过要隔离起来。\n\n因此一个镜像可以启动多次，形成多个容器进程。\n\n#### DockerHub\n\n开源应用程序非常多，打包这些应用往往是重复的劳动。为了避免这些重复劳动，人们就会将自己打包的应用镜像，例如 Redis、MySQL 镜像放到网络上，共享使用，就像 GitHub 的代码共享一样。\n\n- DockerHub ：DockerHub 是一个官方的 Docker 镜像的托管平台。这样的平台称为 Docker Registry。\n\n- 国内也有类似于 DockerHub 的公开服务，比如 [网易云镜像服务](https://c.163yun.com/hub)、[阿里云镜像库](https://cr.console.aliyun.com/) 等。\n\n#### Docker 架构\n\n我们要使用 Docker 来操作镜像、容器，就必须要安装 Docker。\n\nDocker 是一个 CS 架构的程序，由两部分组成：\n\n- 服务端（server）：Docker 守护进程，负责处理 Docker 指令，管理镜像、容器等\n\n- 客户端（client）：通过命令或 RestAPI 向 Docker 服务端发送指令。可以在本地或远程向服务端发送指令。\n\n![Docker架构](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Docker架构.4alzm4dto2g0.svg)\n\n## 配置 Docker\n\nDocker 分为 CE 和 EE 两大版本。CE 即社区版（免费，支持周期 7 个月），EE 即企业版，强调安全，付费使用，支持周期 24 个月。\n\nDocker CE 分为 `stable` `test` 和 `nightly` 三个更新频道。\n\n官方网站上有各种环境下的 [安装指南](https://docs.docker.com/install/)，这里主要介绍 Docker CE 在 CentOS上的安装。\n\n### CentOS 安装 Docker\n\nDocker CE 支持 64 位版本 CentOS 7，并且要求内核版本不低于 3.10， CentOS 7 满足最低内核的要求，所以我们在 CentOS 7 安装 Docker。\n\n#### 卸载 Docker（可选）\n\n如果之前安装过旧版本的 Docker，可以使用下面命令卸载：\n\n```sh\nyum remove docker \\\n                  docker-client \\\n                  docker-client-latest \\\n                  docker-common \\\n                  docker-latest \\\n                  docker-latest-logrotate \\\n                  docker-logrotate \\\n                  docker-selinux \\\n                  docker-engine-selinux \\\n                  docker-engine \\\n                  docker-ce\n```\n\n#### 安装 Docker\n\n安装 yum 工具\n\n```sh\nyum install -y yum-utils \\\n           device-mapper-persistent-data \\\n           lvm2 --skip-broken\n```\n\n然后更新本地镜像源：\n\n```sh\n# 设置docker镜像源\nyum-config-manager \\\n    --add-repo \\\n    https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo\n    \nsed -i \'s/download.docker.com/mirrors.aliyun.com\\/docker-ce/g\' /etc/yum.repos.d/docker-ce.repo\n\nyum makecache fast\n```\n\n然后输入命令：\n\n```sh\nyum install -y docker-ce\n```\n\ndocker-ce 为社区免费版本。稍等片刻，docker 即可安装成功。\n\n### 启动 Docker\n\nDocker 应用需要用到各种端口，逐一去修改防火墙设置。学习时可以直接关闭防火墙。\n\n```sh\n# 关闭\nsystemctl stop firewalld\n# 禁止开机启动防火墙\nsystemctl disable firewalld\n```\n\n通过命令启动 Docker：\n\n```sh\nsystemctl start docker  # 启动docker服务\nsystemctl stop docker  # 停止docker服务\nsystemctl restart docker  # 重启docker服务\n```\n\n然后输入命令，可以查看 Docker 版本：\n\n```sh\ndocker -v\n```\n\n### 配置镜像加速\n\nDocker 官方镜像仓库网速较差，我们需要设置国内镜像服务：\n\n参考阿里云的镜像加速文档：https://cr.console.aliyun.com/cn-hangzhou/instances/mirrors\n\n通过修改 daemon 配置文件 /etc/docker/daemon.json 来使用加速器\n\n```sh\nsudo mkdir -p /etc/docker\nsudo tee /etc/docker/daemon.json <<-\'EOF\'\n{\n  \"registry-mirrors\": [\"https://578xeysa.mirror.aliyuncs.com\"]\n}\nEOF\nsudo systemctl daemon-reload\nsudo systemctl restart docker\n```\n\n## Docker 的基本操作\n\n### 镜像操作\n\n#### 镜像名称\n\n首先来看下镜像的名称组成：\n\n- 镜名称一般分两部分组成：[repository]:[tag]。\n- 在没有指定 tag 时，默认是 latest，代表最新版本的镜像\n\n#### 镜像命令\n\n常见的镜像操作命令如图：\n\n![Docker镜像操作命令](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Docker镜像操作命令.71pfsgm3nn00.svg)\n\n#### 拉取、查看镜像\n\n需求：从 DockerHub 中拉取一个 Nginx 镜像并查看\n\n1. 首先去镜像仓库搜索 Nginx 镜像，比如 [DockerHub](https://hub.docker.com/):\n2. 根据查看到的镜像名称，拉取自己需要的镜像，通过命令：`docker pull nginx`\n3. 通过命令：`docker images` 查看拉取到的镜像\n\n#### 保存镜像\n\n需求：利用 docker save 将 Nginx 镜像导出磁盘，然后再通过 load 加载回来\n\n利用 `docker xx --help` 命令查看 `docker save` 和 `docker load` 的语法。例如，查看save命令用法，可以输入命令：\n\n```sh\ndocker save --help\n```\n\n命令格式：\n\n```sh\ndocker save -o [保存的目标文件名称] [镜像名称]\n```\n\n使用 `docker save` 导出镜像到磁盘，运行命令：\n\n```sh\ndocker save -o nginx.tar nginx:latest\n```\n\n#### 导入镜像\n\n先删除本地的 Nginx 镜像：\n\n```sh\ndocker rmi nginx:latest\n```\n\n然后运行命令，加载本地文件：\n\n```sh\ndocker load -i nginx.tar\n```\n\n### 容器操作\n\n#### 容器相关命令\n\n容器操作的命令如图：\n\n![Docker容器相关命令](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Docker容器相关命令.54kd7pt4p2w0.svg)\n\n容器保护三个状态：\n\n- 运行：进程正常运行\n- 暂停：进程暂停，CPU 不再运行，并不释放内存\n- 停止：进程终止，回收进程占用的内存、CPU 等资源\n\n其中：\n\n- `docker run`：创建并运行一个容器，处于运行状态\n- `docker pause`：让一个运行的容器暂停\n- `docker unpause`：让一个容器从暂停状态恢复运行\n- `docker stop`：停止一个运行的容器\n- `docker start`：让一个停止的容器再次运行\n- `docker rm`：删除一个容器\n- `docker logs` ：查看容器日志的命令，添加 `-f` 参数可以持续查看日志\n- `docker ps` ：查看容器状态，`-a` 查看所有容器，包括已经停止的\n\n#### 创建并运行一个容器\n\n创建并运行 Nginx 容器的命令：\n\n```sh\ndocker run --name haloNginx -p 81:80 -d nginx\n```\n\n命令解读：\n\n- `docker run` ：创建并运行一个容器\n- `--name` : 给容器起一个名字，比如叫做 haloNginx\n- `-p` ：将宿主机端口与容器端口映射，冒号左侧是宿主机端口，右侧是容器端口\n- `-d`：后台运行容器\n- `nginx`：镜像名称，例如 nginx\n\n这里的 `-p` 参数，是将容器端口映射到宿主机端口。\n\n默认情况下，容器是隔离环境，我们直接访问宿主机的 81 端口，肯定访问不到容器中的 Nginx。\n\n现在，将容器的 80 与宿主机的 81 关联起来，当我们访问宿主机的 81 端口时，就会被映射到容器的80，这样就能访问到 Nginx 了\n\n#### 进入容器并修改文件\n\n**需求**：进入 Nginx 容器，修改 HTML 文件内容，添加“Halo World!”\n\n> 提示：进入容器要用到 `docker exec` 命令。\n\n① 进入容器。进入我们刚刚创建的 Nginx 容器的命令为：\n\n```sh\ndocker exec -it haloNginx bash\n```\n\n命令解读：\n\n- `docker exec` ：进入容器内部，执行一个命令\n\n- `-it` : 给当前进入的容器创建一个标准输入、输出终端，允许我们与容器交互\n\n- `haloNginx`：要进入的容器的名称\n\n- `bash`：进入容器后执行的命令，bash 是一个 Linux 终端交互命令\n\n② 进入 Nginx 的 HTML 所在目录 /usr/share/nginx/html\n\n容器内部会模拟一个独立的 Linux 文件系统，看起来如同一个 Linux 服务器一样\n\nNginx 的环境、配置、运行文件全部都在这个文件系统中，包括我们要修改的 html 文件。\n\n查看 DockerHub 网站中的 Nginx 页面，可以知道 Nginx 的 html 目录位置在 `/usr/share/nginx/html`\n\n我们执行命令，进入该目录：\n\n```sh\ncd /usr/share/nginx/html\n```\n\n③ 修改 index.html 的内容\n\n容器内没有 vi 命令，无法直接修改，我们用下面的命令来修改：\n\n```sh\nsed -i -e \'s#Welcome to nginx#Halo World!#g\' -e \'s#<head>#<head><meta charset=\"utf-8\">#g\' index.html\n```\n\n### 数据卷（容器数据管理）\n\n在之前的 Nginx 案例中，修改 Nginx 的 html 页面时，需要进入 Nginx 内部。并且因为没有编辑器，修改文件也很麻烦。\n\n这就是因为容器与数据（容器内文件）耦合带来的后果。容器与数据耦合的问题：\n\n+ 不便于修改：当我们要修改 Nginx 的 html 内容时，需要进入容器内部修改，很不方便。\n+ 数据不可复用：在容器内的修改对外是不可见的。所有修改对新创建的容器是不可复用的。\n+ 升级维护困难：数据在容器内，如果要升级容器必然删除旧容器，所有数据都跟着删除了\n\n要解决这个问题，必须将数据与容器解耦，这就要用到数据卷了。\n\n#### 什么是数据卷\n\n数据卷（volume）是一个虚拟目录，指向宿主机文件系统中的某个目录。\n\n一旦完成数据卷挂载，对容器的一切操作都会作用在数据卷对应的宿主机目录了。\n\n这样，我们操作宿主机的 /var/lib/docker/volumes/html 目录，就等于操作容器内的 /usr/share/nginx/html 目录了\n\n#### 数据集操作命令\n\n数据卷操作的基本语法如下：\n\n```sh\ndocker volume [COMMAND]\n```\n\n`docker volume` 命令是数据卷操作，根据命令后跟随的 `command` 来确定下一步的操作：\n\n- `create` ：创建一个 volume\n- `inspect` ：显示一个或多个 volume 的信息\n- `ls` ：列出所有的 volume\n- `prune` ：删除未使用的 volume\n- `rm` ：删除一个或多个指定的 volume\n\n#### 创建和查看数据卷\n\n① 创建数据卷\n\n```sh\ndocker volume create nginx-html\n```\n\n② 查看所有数据\n\n```sh\ndocker volume ls\n```\n\n③ 查看数据卷详细信息卷\n\n```sh\ndocker volume inspect nginx-html\n```\n\n可以看到，我们创建的 nginx-html 这个数据卷关联的宿主机目录为 `/var/lib/docker/volumes/nginx-html/_data` 目录。\n\n#### 挂载数据卷\n\n我们在创建容器时，可以通过 `-v` 参数来挂载一个数据卷到某个容器内目录，命令格式如下：\n\n```sh\ndocker run \\\n  --name halo-nginx \\\n  -v nginx-html:/usr/share/nginx/html \\\n  -p 81:80\n  nginx \\\n```\n\n这里的 `-v` 就是挂载数据卷的命令。`-v nginx-html:/root/htm` ：把 nginx-html 数据卷挂载到容器内的 /root/html 这个目录中\n\n需求：创建一个 Nginx 容器，修改容器内的 html 目录内的 index.html 内容\n\n分析：上个案例中，我们进入 Nginx 容器内部，已经知道 Nginx 的 html 目录所在位置 /usr/share/nginx/html ，我们需要把这个目录挂载到 html 这个数据卷上，方便操作其中的内容。\n\n① 创建容器并挂载数据卷到容器内的 HTML 目录\n\n```sh\ndocker run --name halo-nginx -v nginx-html:/usr/share/nginx/html -p 81:80 -d nginx\n```\n\n② 进入 nginx-html 数据卷所在位置，并修改 HTML 内容\n\n```sh\n# 查看html数据卷的位置\ndocker volume inspect nginx-html\n# 进入该目录\ncd /var/lib/docker/volumes/nginx-html/_data\n# 修改文件\nvi index.html\n```\n\n> 数据卷不存在会自动创建\n\n#### 挂载本地目录\n\n容器不仅仅可以挂载数据卷，也可以直接挂载到宿主机目录上。关联关系如下：\n\n- 带数据卷模式：宿主机目录 → 数据卷 → 容器内目录\n- 直接挂载模式：宿主机目录 → 容器内目录\n\n目录挂载与数据卷挂载的语法是类似的：\n\n- `-v [宿主机目录]:[容器内目录]`\n- `-v [宿主机文件]:[容器内文件]`\n\n需求：创建并运行一个 MySQL 容器，将宿主机目录直接挂载到容器\n\n1. 拉取 MySQL 镜像\n\n2. 创建目录 /develop/docker-volumes/halo-mysql/data\n\n3. 创建目录 /develop/docker-volumes/halo-mysql/conf ，并在其中创建 halo.conf，内容如下\n\n   ```\n   [mysqld]\n   skip-name-resolve\n   character_set_server=utf8\n   datadir=/var/lib/mysql\n   server-id=1000\n   ```\n\n4. 进行挂载\n\n   ```\n   docker run \\\n     --name halo-mysql \\\n     -e MYSQL_ROOT_PASSWORD=halo \\\n     -p 3307:3306 \\\n     -v /develop/docker-volumes/halo-mysql/conf/halo.conf:/etc/mysql/conf.d/halo.conf \\\n     -v /develop/docker-volumes/halo-mysql/data:/var/lib/mysql \\\n     -d \\\n     mysql:latest\n   ```\n\n## Dockerfile 自定义镜像\n\n### 镜像结构\n\n镜像是将应用程序及其需要的系统函数库、环境、配置、依赖打包而成。\n\n+ 基础镜像（Base Image）：应用依赖的系统函数库、环境、配置、文件等\n+ 层（ Layer ）：在 Base Image 基础上添加安装包、依赖、配置等，每次操作都形成新的一层。\n+ 入口（Entry Point）：镜像运行入口，一般是程序启动的脚本和参数\n\n简单来说，镜像就是在系统函数库、运行环境基础上，添加应用程序文件、配置文件、依赖文件等组合，然后编写好启动脚本打包在一起形成的文件。\n\n我们要构建镜像，其实就是实现上述打包的过程。\n\n### Dockerfile 语法\n\n构建自定义的镜像时，并不需要一个个文件去拷贝，打包。\n\n我们只需要告诉 Docker，我们的镜像的组成，需要哪些 Base Image、需要拷贝什么文件、需要安装什么依赖、启动脚本是什么，将来 Docker 会帮助我们构建镜像。\n\n而描述上述信息的文件就是 Dockerfile 文件。\n\nDockerfile 就是一个文本文件，其中包含一个个的指令（Instruction），用指令来说明要执行什么操作来构建镜像。每一个指令都会形成一层 Layer。\n\n| 指令       | 说明                                           | 示例                          |\n| ---------- | ---------------------------------------------- | ----------------------------- |\n| FROM       | 指定基础镜像                                   | `FROM centos:6`               |\n| ENV        | 设置环境变量，可在后面指令使用                 | `ENV key value`               |\n| COPY       | 拷贝本地文件到镜像的指定目录                   | `COPY ./mysql-5.7.rpm /tmp`   |\n| RUN        | 执行 Linux 的 shell 命令，一般是安装过程的命令 | `RUN yum install gcc`         |\n| EXPOSE     | 指定容器运行时监听的端口，是给镜像使用者看的   | `EXPOSE 8080`                 |\n| ENTRYPOINT | 镜像中应用的启动命令，容器运行时调用           | `ENTRYPOINT java -jar xx.jar` |\n\n更新详细语法说明，请参考官网文档： https://docs.docker.com/engine/reference/builder\n\n### 直接构建 Java 项目\n\n需求：基于 Ubuntu 镜像构建一个新镜像，运行一个 Java 项目\n\n1. Linux 下新建一个空文件夹 docker-demo\n\n2. 拷贝 docker-demo.jar 文件到 docker-demo 这个目录\n\n3. 拷贝 jdk8.tar.gz 文件到 docker-demo 这个目录\n\n4. 拷贝 Dockerfile 到 docker-demo 这个目录，其中的内容如下：\n\n   ```dockerfile\n   # 指定基础镜像\n   FROM ubuntu:16.04\n   # 配置环境变量，JDK的安装目录\n   ENV JAVA_DIR=/usr/local\n   \n   # 拷贝jdk和java项目的包\n   COPY ./jdk8.tar.gz $JAVA_DIR/\n   COPY ./docker-demo.jar /tmp/app.jar\n   \n   # 安装JDK\n   RUN cd $JAVA_DIR \\\n    && tar -xf ./jdk8.tar.gz \\\n    && mv ./jdk1.8.0_144 ./java8\n   \n   # 配置环境变量\n   ENV JAVA_HOME=$JAVA_DIR/java8\n   ENV PATH=$PATH:$JAVA_HOME/bin\n   \n   # 暴露端口\n   EXPOSE 8090\n   # 入口，java项目的启动命令\n   ENTRYPOINT java -jar /tmp/app.jar\n   ```\n\n5. 进入 docker-demo ，运行命令：\n\n   ```sh\n   docker build -t javaweb:1.0 .\n   ```\n\n6. 运行测试\n\n### 基于 java8-alpine  构建 Java 项目\n\n虽然我们可以基于 Ubuntu 基础镜像，添加任意自己需要的安装包，构建镜像，但是却比较麻烦。所以大多数情况下，我们都可以在一些安装了部分软件的基础镜像上做改造。\n\n例如，构建 Java 项目的镜像，可以在已经准备了JDK 的基础镜像基础上构建。\n\n需求：基于 java:8-alpine 镜像，将一个 Java 项目构建为镜像\n\n实现思路如下：\n\n+  新建一个空的目录，然后在目录中新建一个文件，命名为 Dockerfile\n\n+ 拷贝 docker-demo.jar 到这个目录中\n\n+ 编写 Dockerfile 文件，内容如下：\n\n  ```dockerfile\n  FROM java:8-alpine\n  COPY ./app.jar /tmp/app.jar\n  EXPOSE 8090\n  ENTRYPOINT java -jar /tmp/app.jar\n  ```\n\n+ 进入 docker-demo ，运行命令：\n\n  ```\n  docker build -t javaweb:2.0 .\n  ```\n\n### Dockerfile 小结\n\n1. Dockerfile 的本质是一个文件，通过指令描述镜像的构建过程\n\n2. Dockerfile 的第一行必须是 FROM，从一个基础镜像来构建\n\n3. 基础镜像可以是基本操作系统，如 Ubuntu。也可以是其他人制作好的镜像，例如：java:8-alpine\n\n## Docker Compose\n\nDocker Compose 可以基于 Compose 文件帮我们快速的部署分布式应用，而无需手动一个个创建和运行容器。\n\n### 初识 Docker Compose\n\nCompose 文件是一个文本文件，通过指令定义集群中的每个容器如何运行。格式如下：\n\n```json\nversion: \"3.8\"\n services:\n  mysql:\n    image: mysql:5.7.25\n    environment:\n     MYSQL_ROOT_PASSWORD: 123 \n    volumes:\n     - \"/tmp/mysql/data:/var/lib/mysql\"\n     - \"/tmp/mysql/conf/hmy.cnf:/etc/mysql/conf.d/hmy.cnf\"\n  web:\n    build: .\n    ports:\n     - \"8090:8090\"\n```\n\n上面的 Compose 文件就描述一个项目，其中包含两个容器：\n\n- mysql：一个基于 `mysql:5.7.25` 镜像构建的容器，并且挂载了两个目录\n- web：一个基于 `docker build` 临时构建的镜像容器，映射端口时 8090\n\nDocker Compose 的详细语法参考官网：https://docs.docker.com/compose/compose-file/\n\n其实 Docker Compose 文件可以看做是将多个 docker run 命令写到一个文件，只是语法稍有差异。\n\n### 安装 Docker Compose\n\n1. 下载 docker-compose，Linux 下需要通过命令下载（速度较慢）：\n\n   ```sh\n   curl -L https://github.com/docker/compose/releases/download/1.23.1/docker-compose-`uname -s`-`uname -m` > /usr/local/bin/docker-compose\n   ```\n\n2. 修改文件权限\n\n   ```sh\n   chmod +x /usr/local/bin/docker-compose\n   ```\n\n配置 Base 自动补全命令\n\n```sh\ncurl -L https://raw.githubusercontent.com/docker/compose/1.29.1/contrib/completion/bash/docker-compose > /etc/bash_completion.d/docker-compose\n```\n\n如果这里出现错误，需要修改自己的 hosts 文件：\n\n```sh\necho \"199.232.68.133 raw.githubusercontent.com\" >> /etc/hosts\n```\n\n### 部署微服务集群\n\n需求：将之前学习的 spring-cloud-demo 微服务集群利用 Docker Compose 部署\n\n实现思路：\n\n1. 编写 docker-compose 文件\n2. 修改自己的 cloud-demo 项目，将数据库、nacos 地址都命名为 docker-compose 中的服务名\n3. 使用 maven 打包工具，将项目中的每个微服务都打包为 app.jar\n4. 将打包好的 app.jar 拷贝到 cloud-demo 中的每一个对应的子目录中\n5. 到 cloud-demo 目录，利用 `docker-compose up -d` 来部署\n\n## Docker 镜像仓库 \n\n### 搭建私有镜像仓库\n\n搭建镜像仓库可以基于 Docker 官方提供的 Docker Registry 来实现。\n\n官网地址：https://hub.docker.com/_/registry\n\n#### 简化版镜像仓库\n\nDocker 官方的 Docker Registry 是一个基础版本的 Docker 镜像仓库，具备仓库管理的完整功能，但是没有图形化界面。\n\n搭建方式比较简单，命令如下：\n\n```sh\ndocker run -d \\\n    --restart=always \\\n    --name registry	\\\n    -p 5000:5000 \\\n    -v registry-data:/var/lib/registry \\\n    registry\n```\n\n命令中挂载了一个数据卷 registry-data 到容器内的 /var/lib/registry 目录，这是私有镜像库存放数据的目录。\n\n访问 http://halo:5000/v2/_catalog 可以查看当前私有镜像服务中包含的镜像\n\n#### 带有图形化界面版本\n\n使用 Docker Compose 部署带有图象界面的 Docker Registry，命令如下：\n\n```yaml\nversion: \'3.0\'\nservices:\n  registry:\n    image: registry\n    volumes:\n      - ./registry-data:/var/lib/registry\n  ui:\n    image: joxit/docker-registry-ui:static\n    ports:\n      - 8181:80\n    environment:\n      - REGISTRY_TITLE=Halo-Docker-Registry\n      - REGISTRY_URL=http://registry:5000\n    depends_on:\n      - registry\n```\n\n配置 Docker 信任地址，私服采用的是 http 协议，默认不被 Docker 信任，所以需要做一个配置：\n\n```sh\n# 打开要修改的文件\nvi /etc/docker/daemon.json\n# 添加内容：\n\"insecure-registries\":[\"http://halo:8181\"]\n# 重加载\nsystemctl daemon-reload\n# 重启docker\nsystemctl restart docker\n```\n\n### 推送、拉取镜像\n\n推送镜像到私有镜像服务必须先 tag，步骤如下：\n\n① 重新 tag 本地镜像，名称前缀为私有仓库的地址：halo:8181/\n\n```sh\ndocker tag nginx:latest halo:8181/nginx:1.0 \n```\n\n② 推送镜像\n\n```sh\ndocker push halo:8181/nginx:1.0 \n```\n\n③ 拉取镜像\n\n```\ndocker pull halo:8181/nginx:1.0 \n```', '2021-09-23 19:06:19', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 5, '2021-09-23 21:37:25', NULL, NULL, '2', 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (8, 1, 'RabbitMQ 入门', 'RabbitMQ 入门', '## 初识 RabbitMQ\n\n### 同步和异步通讯\n\n微服务间通讯有同步和异步两种方式：\n\n+ 同步通讯：就像打电话，需要实时响应。\n+ 异步通讯：就像发邮件，不需要马上回复。\n\n#### 同步通讯\n\n我们之前学习的 Feign 调用就属于同步方式，虽然调用可以实时得到结果，但存在下面的问题：\n\n+ 耦合度高：每次加入新的需求，都要修改原来的代码\n+ 性能下降：调用者需要等待服务提供者响应，如果调用链过长则响应时间等于每次调用的时间之和。\n+ 资源浪费：调用链中的每个服务在等待响应过程中，不能释放请求占用的资源，高并发场景下会极度浪费系统资源\n+ 级联失败：如果服务提供者出现问题，所有调用方都会跟着出问题，如同多米诺骨牌一样，迅速导致整个微服务群故障\n\n#### 异步通讯\n\n异步调用则可以避免上述问题：\n\n我们以购买商品为例，用户支付后需要调用订单服务完成订单状态修改，调用物流服务，从仓库分配响应的库存并准备发货。\n\n+ 在事件模式中，支付服务是事件发布者（publisher），在支付完成后只需要发布一个支付成功的事件（event），事件中带上订单 id。\n+ 订单服务和物流服务是事件订阅者（Consumer），订阅支付成功的事件，监听到事件后完成自己业务即可。\n+ 为了解除事件发布者与订阅者之间的耦合，两者并不是直接通信，而是有一个中间人（Broker）。发布者发布事件到 Broker，不关心谁来订阅事件。订阅者从 Broker 订阅事件，不关心谁发来的消息。\n\nBroker 是一个像数据总线一样的东西，所有的服务要接收数据和发送数据都发到这个总线上，这个总线就像协议一样，让服务间的通讯变得标准和可控。\n\n异步通讯的优点：\n\n- 吞吐量提升：无需等待订阅者处理完成，响应更快速\n\n- 故障隔离：服务没有直接调用，不存在级联失败问题\n- 调用间没有阻塞，不会造成无效的资源占用\n- 耦合度极低，每个服务都可以灵活插拔，可替换\n- 流量削峰：不管发布事件的流量波动多大，都由 Broker 接收，订阅者可以按照自己的速度去处理事件\n\n异步通讯的缺点：\n\n- 架构复杂了，业务没有明显的流程线，不好管理\n- 需要依赖于 Broker 的可靠、安全、性能\n\n### 技术对比\n\nMQ，中文是消息队列（Message Queue），字面来看就是存放消息的队列。也就是事件驱动架构中的 Broker。\n\n比较常见的MQ实现：\n\n- ActiveMQ\n- RabbitMQ\n- RocketMQ\n- Kafka\n\n几种常见 MQ 的对比：\n\n|            | RabbitMQ                | ActiveMQ                          | RocketMQ   | Kafka        |\n| ---------- | ----------------------- | --------------------------------- | ---------- | ------------ |\n| 公司/社区  | Rabbit                  | Apache                            | 阿里       | Apache       |\n| 开发语言   | Erlang                  | Java                              | Java       | Scala & Java |\n| 协议支持   | AMQP，XMPP，SMTP，STOMP | OpenWire，STOMP，REST，XMPP，AMQP | 自定义协议 | 自定义协议   |\n| 可用性     | 高                      | 一般                              | 高         | 高           |\n| 单机吞吐量 | 一般                    | 差                                | 高         | 非常高       |\n| 消息延迟   | 微秒级                  | 毫秒级                            | 毫秒级     | 毫秒以内     |\n| 消息可靠性 | 高                      | 一般                              | 高         | 一般         |\n\n追求可用性：Kafka、 RocketMQ 、RabbitMQ\n\n追求可靠性：RabbitMQ、RocketMQ\n\n追求吞吐能力：RocketMQ、Kafka\n\n追求消息低延迟：RabbitMQ、Kafka\n\n## RabbitMQ 快速入门\n\nRabbitMQ 是基于 Erlang 语言开发的开源消息通信中间件，官网地址：https://www.rabbitmq.com/\n\n### 安装 RabbitMQ\n\n在 Centos 7 虚拟机中使用 Docker 来安装\n\n```sh\ndocker pull rabbitmq:3-management\n```\n\n执行下面的命令来运行 MQ 容器：\n\n```\ndocker run \\\n -e RABBITMQ_DEFAULT_USER=halo \\\n -e RABBITMQ_DEFAULT_PASS=halo \\\n --name halo-rabbitmq-1 \\\n --hostname halo-rabbitmq-1 \\\n -p 15672:15672 \\\n -p 5672:5672 \\\n -d \\\n rabbitmq:3-management\n```\n\n### RabbitMQ 的基本结构\n\nRabbitMQ 的基本结构：\n\n![RabbitMQ的结构和概念](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/RabbitMQ的结构和概念.5365ey5rjww0.svg)\n\nRabbitMQ 中的一些角色：\n\n- publisher：生产者\n- consumer：消费者\n- exchange：交换机，负责消息路由\n- queue：队列，存储消息\n- virtualHost：虚拟主机，隔离不同租户的 exchange、queue、消息的隔离\n\n### RabbitMQ 消息模型\n\n[RabbitMQ 官方](https://www.rabbitmq.com/getstarted.html) 提供了 5 个不同的 Demo 示例，对应了不同的消息模型：\n\n+ 基本消息队列（Basic Queue）\n+ 工作消息队列（Work Queue）\n+ 发布订阅（Publish、Subscribe），又根据交换机类型不同分为三种：\n  + Fanout Exchange：广播\n  + Direct Exchange：路由\n  + Topic Exchange：主题\n\n![RabbitMQ消息模型](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/RabbitMQ消息模型.1fiomitimbsw.png)\n\n### Hello World 案例\n\n官方的 HelloWorld 是基于最基础的消息队列模型来实现的，只包括三个角色：\n\n•publisher：消息发布者，将消息发送到队列 queue\n\n•queue：消息队列，负责接受并缓存消息\n\n•consumer：订阅队列，处理队列中的消息\n\n![HelloWorld案例](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/HelloWorld案例.zb6pinalxzk.svg)\n\npublisher 实现思路：\n\n- 建立连接\n- 创建 Channel\n- 声明队列\n- 发送消息\n- 关闭连接和 Channel\n\n代码实现：\n\n```java\npackage cn.itcast.mq.helloworld;\n\nimport com.rabbitmq.client.Channel;\nimport com.rabbitmq.client.Connection;\nimport com.rabbitmq.client.ConnectionFactory;\nimport org.junit.Test;\n\nimport java.io.IOException;\nimport java.util.concurrent.TimeoutException;\n\npublic class PublisherTest {\n    @Test\n    public void testSendMessage() throws IOException, TimeoutException {\n        // 1.建立连接\n        ConnectionFactory factory = new ConnectionFactory();\n        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码\n        factory.setHost(\"halo\");\n        factory.setPort(5672);\n        factory.setVirtualHost(\"/\");\n        factory.setUsername(\"halo\");\n        factory.setPassword(\"halo\");\n        // 1.2.建立连接\n        Connection connection = factory.newConnection();\n\n        // 2.创建通道Channel\n        Channel channel = connection.createChannel();\n\n        // 3.创建队列\n        String queueName = \"simple.queue\";\n        channel.queueDeclare(queueName, false, false, false, null);\n\n        // 4.发送消息\n        String message = \"hello, rabbitmq!\";\n        channel.basicPublish(\"\", queueName, null, message.getBytes());\n        System.out.println(\"发送消息成功：【\" + message + \"】\");\n\n        // 5.关闭通道和连接\n        channel.close();\n        connection.close();\n\n    }\n}\n```\n\nconsumer 实现思路：\n\n- 建立连接\n- 创建 Channel\n- 声明队列\n- 订阅消息\n\n代码实现：\n\n```java\npackage cn.itcast.mq.helloworld;\n\nimport com.rabbitmq.client.*;\n\nimport java.io.IOException;\nimport java.util.concurrent.TimeoutException;\n\npublic class ConsumerTest {\n\n    public static void main(String[] args) throws IOException, TimeoutException {\n        // 1.建立连接\n        ConnectionFactory factory = new ConnectionFactory();\n        // 1.1.设置连接参数，分别是：主机名、端口号、vhost、用户名、密码\n        factory.setHost(\"halo\");\n        factory.setPort(5672);\n        factory.setVirtualHost(\"/\");\n        factory.setUsername(\"halo\");\n        factory.setPassword(\"halo\");\n        // 1.2.建立连接\n        Connection connection = factory.newConnection();\n\n        // 2.创建通道Channel\n        Channel channel = connection.createChannel();\n\n        // 3.创建队列\n        String queueName = \"simple.queue\";\n        channel.queueDeclare(queueName, false, false, false, null);\n\n        // 4.订阅消息\n        channel.basicConsume(queueName, true, new DefaultConsumer(channel) {\n            @Override\n            public void handleDelivery(String consumerTag, Envelope envelope,\n                                       AMQP.BasicProperties properties, byte[] body) throws IOException {\n                // 5.处理消息\n                String message = new String(body);\n                System.out.println(\"接收到消息：【\" + message + \"】\");\n            }\n        });\n        System.out.println(\"等待接收消息。。。。\");\n    }\n}\n```\n\n基本消息队列的消息发送流程：\n\n1. 建立 connection\n\n2. 创建 channel\n\n3. 利用 channel 声明队列\n\n4. 利用 channel 向队列发送消息\n\n基本消息队列的消息接收流程：\n\n1. 建立 connection\n\n2. 创建 channel\n\n3. 利用 channel 声明队列\n\n4. 定义 consumer 的消费行为 `handleDelivery()`\n\n5. 利用 channel 将消费者与队列绑定\n\n## Spring AMQP\n\nSpring AMQP 是基于 RabbitMQ 封装的一套模板，并且还利用 Spring Boot 对其实现了自动装配，使用起来非常方便。\n\nSpring AMQP 的官方地址：https://spring.io/projects/spring-amqp\n\nAMQP ：Advanced Message Queuing Protocol，是用于在应用程序之间传递业务消息的开放标准。该协议与语言和平台无关，更符合微服务中独立性的要求。\n\nSpring AMQP ：Spring AMQP 是基于 AMQP 协议定义的一套 API 规范，提供了模板来发送和接收消息。包含两部分，其中 spring-amqp 是基础抽象，spring-rabbit 是底层的默认实现。\n\nSpring AMQP 提供了三个功能：\n\n- 自动声明队列、交换机及其绑定关系\n- 基于注解的监听器模式，异步接收消息\n- 封装了 RabbitTemplate 工具，用于发送消息 \n\n### Basic Queue 基本消息队列\n\n![HelloWorld案例](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/HelloWorld案例.zb6pinalxzk.svg)\n\n流程如下：\n\n+ 在父工程中引入 spring-amqp 的依赖\n+ 在 publisher 服务中利用 RabbitTemplate 发送消息到 simple.queue 这个队列\n+ 在 consumer 服务中编写消费逻辑，绑定 simple.queue 这个队列\n\n#### 引入依赖\n\n在父工程 mq-demo 中引入依赖\n\n```xml\n<!--AMQP依赖，包含RabbitMQ-->\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n\n#### 消息发送\n\n首先配置 RabbitMQ 地址，在 publisher 服务的 application.yml 中添加配置：\n\n```yaml\nspring:\n  rabbitmq:\n    host: halo # 主机名\n    port: 5672 # 端口\n    virtual-host: / # 虚拟主机\n    username: halo # 用户名\n    password: halo # 密码\n```\n\n然后在 publisher 服务中编写测试类 `SpringAmqpTest`，并利用 RabbitTemplate 实现消息发送：\n\n```java\npackage cn.itcast.mq.spring;\n\nimport org.junit.Test;\nimport org.junit.runner.RunWith;\nimport org.springframework.amqp.rabbit.core.RabbitTemplate;\nimport org.springframework.beans.factory.annotation.Autowired;\nimport org.springframework.boot.test.context.SpringBootTest;\nimport org.springframework.test.context.junit4.SpringRunner;\n\n@RunWith(SpringRunner.class)\n@SpringBootTest\npublic class SpringAmqpTest {\n\n    @Autowired\n    private RabbitTemplate rabbitTemplate;\n\n    @Test\n    public void testSimpleQueue() {\n        // 队列名称\n        String queueName = \"simple.queue\";\n        // 消息\n        String message = \"hello, spring amqp!\";\n        // 发送消息\n        rabbitTemplate.convertAndSend(queueName, message);\n    }\n}\n```\n\n#### 消息接收\n\n首先配置 RabbitMQ 地址，在 consumer 服务的 application.yml 中添加配置：\n\n```yaml\nspring:\n  rabbitmq:\n    host: halo # 主机名\n    port: 5672 # 端口\n    virtual-host: / # 虚拟主机\n    username: halo # 用户名\n    password: halo # 密码\n```\n\n然后在 consumer 服务的 `cn.itcast.mq.listener` 包中新建一个类 `SpringRabbitListener`，代码如下：\n\n```java\npackage cn.itcast.mq.listener;\n\nimport org.springframework.amqp.rabbit.annotation.RabbitListener;\nimport org.springframework.stereotype.Component;\n\n@Component\npublic class SpringRabbitListener {\n\n    @RabbitListener(queues = \"simple.queue\")\n    public void listenSimpleQueueMessage(String msg) throws InterruptedException {\n        System.out.println(\"spring 消费者接收到消息：【\" + msg + \"】\");\n    }\n}\n```\n\n注意：消息一旦消费就会从队列删除，RabbitMQ 没有消息回溯功能\n\n### Work Queue 工作队列\n\n![WorkQueue工作队列](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/WorkQueue工作队列.3xixqzsmydc0.svg)\n\nWork Queue，也被称为（Task queues），任务模型。简单来说就是让多个消费者绑定到一个队列，共同消费队列中的消息。\n\n当消息处理比较耗时的时候，可能生产消息的速度会远远大于消息的消费速度。长此以往，消息就会堆积越来越多，无法及时处理。\n\n此时就可以使用 work 模型，多个消费者共同处理消息处理，速度就能大大提高了。\n\n基本思路如下：\n\n1. 在 publisher 服务中定义测试方法，每秒产生 50 条消息，发送到 simple.queue\n2. 在 consumer 服务中定义两个消息监听者，都监听 simple.queue 队列\n3. 消费者 1 每秒处理 50 条消息，消费者 2 每秒处理 10 条消息\n\n#### 消息发送\n\n这次我们循环发送，模拟大量消息堆积现象。\n\n在 publisher 服务中的 SpringAmqpTest 类中添加一个测试方法：\n\n```java\n@Test\npublic void testWorkQueue() throws InterruptedException {\n    // 队列名称\n    String queueName = \"simple.queue\";\n    // 消息\n    String message = \"hello, message_\";\n    for (int i = 0; i < 50; i++) {\n        // 发送消息\n        rabbitTemplate.convertAndSend(queueName, message + i);\n        Thread.sleep(20);\n    }\n}\n```\n\n#### 消息接收\n\n要模拟多个消费者绑定同一个队列，我们在 consumer 服务的 `SpringRabbitListener` 中添加 2 个新的方法：\n\n```java\n@RabbitListener(queues = \"simple.queue\")\npublic void listenWorkQueue1(String msg) throws InterruptedException {\n    System.out.println(\"消费者-[1]-接收到消息：【\" + msg + \"】\" + LocalTime.now());\n    Thread.sleep(20);\n}\n\n@RabbitListener(queues = \"simple.queue\")\npublic void listenWorkQueue2(String msg) throws InterruptedException {\n    System.err.println(\"消费者-[2]-接收到消息：【\" + msg + \"】\" + LocalTime.now());\n    Thread.sleep(200);\n}\n```\n\n#### 测试分析\n\n启动 `ConsumerApplication` 后，在执行 publisher 服务中刚刚编写的发送测试方法 `testWorkQueue`。\n\n可以看到消费者 1 很快完成了自己的 25 条消息。消费者 2 却在缓慢的处理自己的 25 条消息。\n\n也就是说消息是平均分配给每个消费者，并没有考虑到消费者的处理能力。这样显然是有问题的。\n\n#### 能者多劳\n\n在 spring 中有一个简单的配置，可以解决这个问题。我们修改 consumer 服务的 application.yml 文件，添加配置：\n\n```yaml\nspring:\n  rabbitmq:\n    listener:\n      simple:\n        prefetch: 1 # 每次只能获取一条消息，处理完成才能获取下一个消息\n```\n\n设置 `preFetch` 这个值，可以控制预取消息的上限：\n\n### 发布与订阅\n\n发布订阅的模型如图：\n\n![发布订阅模式](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/发布订阅模式.g64vagn8am0.svg)\n\n可以看到，在订阅模型中，多了一个 exchange 角色，而且过程略有变化：\n\n- Publisher（生产者）：也就是要发送消息的程序，但是不再发送到队列中，而是发给 exchange \n- Exchange（交换机）：一方面，接收生产者发送的消息。另一方面，知道如何处理消息，例如递交给某个特别队列、递交给所有队列、或是将消息丢弃。到底如何操作，取决于 Exchange 的类型。Exchange 有以下 3 种类型：\n  - Fanout：广播，将消息交给所有绑定到交换机的队列\n  - Direct：定向，把消息交给符合指定 routing key 的队列\n  - Topic：通配符，把消息交给符合 routing pattern（路由模式） 的队列\n- Consumer：消费者，与以前一样，订阅队列，没有变化\n- Queue：消息队列也与以前一样，接收消息、缓存消息。\n\nExchange（交换机）只负责转发消息，不具备存储消息的能力，因此如果没有任何队列与 Exchange 绑定，或者没有符合路由规则的队列，那么消息会丢失！\n\n### Fanout Exchange\n\nFanout，英文翻译是扇出，在 MQ 中叫广播更合适。\n\n![Fanout](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Fanout.5ru00gaykjs0.svg)\n\n在广播模式下，消息发送流程是这样的：\n\n- 可以有多个队列\n- 每个队列都要绑定到 Exchange\n- 生产者发送的消息，只能发送到交换机，交换机来决定要发给哪个队列，生产者无法决定\n- 交换机把消息发送给绑定过的所有队列\n- 订阅队列的消费者都能拿到消息\n\n利用 Spring AMQP 演示 Fanout Exchange 的使用，实现思路如下：\n\n1. 在 consumer 服务中，利用代码声明队列、交换机（halo.fanout），并将两者绑定\n2. 在 consumer 服务中，编写两个消费者方法，分别监听 fanout.queue1 和 fanout.queue2\n3. 在 publisher 中编写测试方法，向 halo.fanout 发送消息\n\n#### 声明队列和交换机\n\nSpring 提供了一个接口 Exchange，来表示所有不同类型的交换机：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.1jmh85mmwahs.png)\n\n在 consumer 中创建一个类，声明 Exchange、Queue、Binding：\n\n```java\npackage cn.itcast.mq.config;\n\nimport org.springframework.amqp.core.Binding;\nimport org.springframework.amqp.core.BindingBuilder;\nimport org.springframework.amqp.core.FanoutExchange;\nimport org.springframework.amqp.core.Queue;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.context.annotation.Configuration;\n\n@Configuration\npublic class FanoutConfig {\n    /**\n     * 声明交换机\n     *\n     * @return Fanout类型交换机\n     */\n    @Bean\n    public FanoutExchange fanoutExchange() {\n        return new FanoutExchange(\"halo.fanout\");\n    }\n\n    /**\n     * 第1个队列\n     */\n    @Bean\n    public Queue fanoutQueue1() {\n        return new Queue(\"fanout.queue1\");\n    }\n\n    /**\n     * 绑定队列和交换机\n     */\n    @Bean\n    public Binding bindingQueue1(Queue fanoutQueue1, FanoutExchange fanoutExchange) {\n        return BindingBuilder.bind(fanoutQueue1).to(fanoutExchange);\n    }\n\n    /**\n     * 第2个队列\n     */\n    @Bean\n    public Queue fanoutQueue2() {\n        return new Queue(\"fanout.queue2\");\n    }\n\n    /**\n     * 绑定队列和交换机\n     */\n    @Bean\n    public Binding bindingQueue2(Queue fanoutQueue2, FanoutExchange fanoutExchange) {\n        return BindingBuilder.bind(fanoutQueue2).to(fanoutExchange);\n    }\n}\n```\n\n#### 消息发送\n\n在 publisher 服务的 SpringAmqpTest 类中添加测试方法：\n\n```java\n@Test\npublic void testFanoutExchange() {\n    // 队列名称\n    String exchangeName = \"halo.fanout\";\n    // 消息\n    String message = \"hello, everyone!\";\n    // 发送\n    rabbitTemplate.convertAndSend(exchangeName, \"\", message);\n}\n```\n\n#### 消息接收\n\n在 consumer 服务的 `SpringRabbitListener` 中添加两个方法，作为消费者：\n\n```java\n@RabbitListener(queues = \"fanout.queue1\")\npublic void listenFanoutQueue1(String msg) {\n    System.out.println(\"消费者-[1]-接收到Fanout消息：【\" + msg + \"】\");\n}\n\n@RabbitListener(queues = \"fanout.queue2\")\npublic void listenFanoutQueue2(String msg) {\n    System.err.println(\"消费者-[2]-接收到Fanout消息：【\" + msg + \"】\");\n}\n```\n\n#### Fanout Exchange 小结\n\n交换机的作用是什么？\n\n- 接收 publisher 发送的消息\n- 将消息按照规则路由到与之绑定的队列\n- 不能缓存消息，路由失败，消息丢失\n- Fanout Exchange 的会将消息路由到每个绑定的队列\n\n声明队列、交换机、绑定关系的 Bean 是什么？\n\n- Queue\n- Fanout Exchange\n- Binding\n\n### Direct Exchange\n\n在 Fanout 模式中，一条消息，会被所有订阅的队列都消费。但是，在某些场景下，我们希望不同的消息被不同的队列消费。这时就要用到 Direct 类型的 Exchange。\n\n![DirectExchange](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/DirectExchange.1xsf8z6diw00.svg)\n\nDirect Exchange 会将接收到的消息根据规则路由到指定的 Queue，因此称为路由模式（routes）。\n\n+ 每一个 Queue 都与 Exchange 设置一个 BindingKey\n+ 发布者发送消息时，指定消息的 RoutingKey\n+ Exchange 将消息路由到 BindingKey 与消息 RoutingKey 一致的队列\n\n案例需求如下：\n\n+ 利用 `@RabbitListener` 声明 Exchange、Queue、RoutingKey\n+ 在 consumer 服务中，编写两个消费者方法，分别监听 direct.queue1 和 direct.queue2\n+ 在 publisher 中编写测试方法，向 halo.direct发送消息\n\n#### 消息发送\n\n在 publisher 服务的 SpringAmqpTest 类中添加测试方法：\n\n```java\n@Test\npublic void testSendDirectExchange() {\n    // 交换机名称\n    String exchangeName = \"halo.direct\";\n    // 发送消息\n    rabbitTemplate.convertAndSend(exchangeName, \"red\", \"halo-direct-red\");\n    rabbitTemplate.convertAndSend(exchangeName, \"yellow\", \"halo-direct-yellow\");\n    rabbitTemplate.convertAndSend(exchangeName, \"blue\", \"halo-direct-blue\");\n}\n```\n\n#### 基于注解声明队列和交换机\n\n基于 `@Bean` 的方式声明队列和交换机比较麻烦，Spring 还提供了基于注解方式来声明。\n\n在 consumer 的 SpringRabbitListener 中添加两个消费者，同时基于注解来声明队列和交换机：\n\n```java\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"direct.queue1\"),\n    exchange = @Exchange(name = \"halo.direct\", type = ExchangeTypes.DIRECT),\n    key = {\"red\", \"blue\"}\n))\npublic void listenDirectQueue1(String msg) {\n    System.out.println(\"消费者接收到direct.queue1的消息：【\" + msg + \"】\");\n}\n\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"direct.queue2\"),\n    exchange = @Exchange(name = \"halo.direct\", type = ExchangeTypes.DIRECT),\n    key = {\"red\", \"yellow\"}\n))\npublic void listenDirectQueue2(String msg) {\n    System.out.println(\"消费者接收到direct.queue2的消息：【\" + msg + \"】\");\n}\n```\n\n#### Direct Exchange 小结\n\n描述下 Direct 交换机与 Fanout 交换机的差异？\n\n- Fanout 交换机将消息路由给每一个与之绑定的队列\n- Direct 交换机根据 Routing Key 判断路由给哪个队列\n- 如果多个队列具有相同的 Routing Key，则与 Fanout 功能类似\n\n基于 `@RabbitListener` 注解声明队列和交换机有哪些常见注解？\n\n- `@Queue`\n- `@Exchange`\n\n### Topic Exchange \n\nTopic 类型的 Exchange 与 Direct 相比，都是可以根据 Routing Key 把消息路由到不同的队列。\n\n只不过 Topic 类型 Exchange 可以让队列在绑定 Routing key 的时候使用通配符！\n\nRouting Key 一般都是有一个或多个单词组成，多个单词之间以 `.` 分割，例如：item.insert\n\n 通配符规则：\n\n`#`：匹配一个或多个词\n\n`*`：匹配不多不少恰好 1 个词\n\n举例：\n\n`item.#`：能够匹配 `item.spu.insert` 或者 `item.spu`\n\n`item.*`：只能匹配 `item.spu`\n\n![Topic](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Topic.60w0j0blgsw0.svg)\n\n- Queue1：绑定的是 `china.#` ，因此凡是以 `china.` 开头的 Routing Key 都会被匹配到。包括`china.news` 和 `china.weather`\n- Queue2：绑定的是 `#.news` ，因此凡是以 `.news` 结尾的 Routing Key 都会被匹配。包括 `china.news` 和 `japan.news`\n- 其他队列同理\n\n实现思路如下：\n\n1. 利用 `@RabbitListener` 声明 Exchange、Queue、RoutingKey\n\n2. 在 consumer 服务中，编写两个消费者方法，分别监听 topic.queue1 和 topic.queue2\n\n3. 在 publisher 中编写测试方法，向 halo. topic发送消息\n\n#### 消息发送\n\n在 publisher 服务的 SpringAmqpTest 类中添加测试方法：\n\n```java\n@Test\npublic void testSendTopicExchange() {\n    // 交换机名称\n    String exchangeName = \"itcast.topic\";\n    // 消息\n    String message = \"喜报！孙悟空大战哥斯拉，胜!\";\n    // 发送消息\n    rabbitTemplate.convertAndSend(exchangeName, \"china.news\", message);\n}\n```\n\n#### 消息接收\n\n在 consumer 服务的 SpringRabbitListener 中添加方法：\n\n```java\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"topic.queue1\"),\n    exchange = @Exchange(name = \"halo.topic\", type = ExchangeTypes.TOPIC),\n    key = \"china.#\"\n))\npublic void listenTopicQueue1(String msg){\n    System.out.println(\"消费者接收到topic.queue1的消息：【\" + msg + \"】\");\n}\n\n@RabbitListener(bindings = @QueueBinding(\n    value = @Queue(name = \"topic.queue2\"),\n    exchange = @Exchange(name = \"halo.topic\", type = ExchangeTypes.TOPIC),\n    key = \"#.news\"\n))\npublic void listenTopicQueue2(String msg){\n    System.out.println(\"消费者接收到topic.queue2的消息：【\" + msg + \"】\");\n}\n```\n\n### 消息转换器\n\n之前说过，Spring 会把你发送的消息序列化为字节发送给 MQ，接收消息的时候，还会把字节反序列化为 Java 对象。\n\n只不过，默认情况下 Spring 采用的序列化方式是 JDK 序列化。众所周知，JDK 序列化存在下列问题：\n\n- 数据体积过大\n- 有安全漏洞\n- 可读性差\n\n#### 测试默认转换器\n\n我们修改消息发送的代码，发送一个 Map 对象：\n\n```java\n@Test\npublic void testSendMap() {\n    // 队列名称\n    String queueName = \"object.queue\";\n    // 准备消息\n    Map<String, Object> msg = new HashMap<>();\n    msg.put(\"name\", \"Jack\");\n    msg.put(\"age\", 21);\n    // 发送消息\n    rabbitTemplate.convertAndSend(queueName, msg);\n}\n```\n\n发送消息后查看控制台：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.2jjb6wxbs120.png)\n\nSpring 的对消息对象的处理是由 `org.springframework.amqp.support.converter.MessageConverter` 来处理的。而默认实现是 `SimpleMessageConverter`，基于 JDK 的 `ObjectOutputStream` 完成序列化。\n\n#### 配置 JSON 转换器\n\n显然，JDK 序列化方式并不合适。我们希望消息体的体积更小、可读性更高，因此可以使用 JSON 方式来做序列化和反序列化。如果要修改只需要定义一个 `MessageConverter` 类型的Bean即可，步骤如下：\n\n在 publisher 和 consumer 两个服务中都引入依赖：\n\n```xml\n<dependency>\n    <groupId>com.fasterxml.jackson.core</groupId>\n    <artifactId>jackson-databind</artifactId>\n</dependency>\n```\n\n配置消息转换器。\n\n在启动类中添加一个 Bean 即可：\n\n```java\n@Bean\npublic MessageConverter jsonMessageConverter(){\n    return new Jackson2JsonMessageConverter();\n}\n```\n\n\n\n\n\n\n\n', '2021-09-23 19:11:31', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 19, '2021-09-26 11:55:54', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (9, 1, 'Test', 'Test', '## 你好\n\n', '2021-09-23 21:30:37', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-23 21:30:37', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (10, 1, 'Test', 'halo', 'halo', '2021-09-26 11:54:21', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-26 11:54:21', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (11, 1, '1111', '111', '111', '2021-09-26 12:08:15', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-26 12:08:15', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (12, 1, 'ElasticaSeach 入门', 'ElasticaSeach 入门', '\n## 初识 ElasticSearch\n\n### 了解 ElasticSearch\n\n#### ElasticSearch 的作用\n\nElasticSearch 是一款非常强大的开源搜索引擎，具备非常多强大功能，可以帮助我们从海量数据中快速找到需要的内容\n\n#### ELK 技术栈\n\nElasticSearch 结合 Kibana、Logstash、Beats，也就是 Elastic stack（ELK）。被广泛应用在日志数据分析、实时监控等领域。\n\n#### ElasticSearch 和 Lucene\n\nElasticSearch 底层是基于 Lucene 来实现的。\n\nLucene 是一个 Java 语言的搜索引擎类库，是 Apache 公司的顶级项目，由 DougCutting 于 1999 年研发。\n\nLucene 官网地址：https://lucene.apache.org/ 。\n\nLucene 的优势：易扩展、高性能（基于倒排索引）\n\nLucene 的缺点：只限于 Java 语言开发、学习曲线陡峭、不支持水平扩展\n\nElasticSearch 的发展历史：\n\n- 2004 年 Shay Banon 基于 Lucene 开发了 Compass\n- 2010 年 Shay Banon 重写了 Compass，取名为 ElasticSearch。\n\nElasticSearch 官网地址: https://www.elastic.co/cn/\n\n相比与 Lucene ，ElasticSearch 具备下列优势：\n\n+ 支持分布式，可水平扩展\n+ 提供 Restful 接口，可被任何语言调用\n\n### 倒排索引\n\n倒排索引的概念是基于 MySQL 这样的正向索引而言的。\n\n#### 正向索引\n\n如果是根据 id 查询，那么直接走索引，查询速度非常快。\n\n但如果是基于 title 做模糊查询，只能是逐行扫描数据，流程如下：\n\n1. 用户搜索数据，条件是 title 符合 `\"%手机%\"`\n2. 逐行获取数据，比如 id 为 1 的数据\n3. 判断数据中的 title 是否符合用户搜索条件\n4. 如果符合则放入结果集，不符合则丢弃。回到步骤 1\n\n逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低。当数据量达到数百万时，就是一场灾难。\n\n#### 倒排索引\n\n倒排索引中有两个非常重要的概念：\n\n- 文档（Document）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息\n- 词条（Term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条\n\n创建倒排索引是对正向索引的一种特殊处理，流程如下：\n\n- 将每一个文档的数据利用算法分词，得到一个个词条\n- 创建表，每行数据包括词条、词条所在文档 id、位置等信息\n- 因为词条唯一性，可以给词条创建索引，例如 hash 表结构索引\n\n如图：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5jp2imzxno00.png)\n\n倒排索引的搜索流程如下（以搜索“华为手机”为例）：\n\n1. 用户输入条件 `\"华为手机\"` 进行搜索。\n2. 对用户输入内容分词，得到词条：`华为`、`手机`。\n3. 拿着词条在倒排索引中查找，可以得到包含词条的文档 id：1、2、3。\n4. 拿着文档 id 到正向索引中查找具体文档。\n\n虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档 id 都建立了索引，查询速度非常快！无需全表扫描。\n\n#### 正向和倒排\n\n那么为什么一个叫做正向索引，一个叫做倒排索引呢？\n\n- 正向索引是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是根据文档找词条的过程。\n\n- 倒排索引则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的 id，然后根据 id 获取文档。是根据词条找文档的过程。\n\n正向索引\n\n+ 优点：可以给多个字段创建索引、根据索引字段搜索、排序速度非常快\n\n- 缺点：根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。\n\n倒排索引：\n\n- 优点：根据词条搜索、模糊搜索时，速度非常快\n- 缺点：只能给词条创建索引，而不是字段、无法根据字段做排序\n\n### ElasticSearch 中的一些概念\n\nElasticSearch 中有很多独有的概念，与 MySQL 中略有差别，但也有相似之处。\n\n#### 文档和字段\n\nElasticSearch 是面向文档（Document）存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为 JSON 格式后存储在 ElasticSearch 中：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.lwpnpfcxvds.png)\n\n而 JSON 文档中往往包含很多的字段（Field），类似于数据库中的列。\n\n#### 索引和映射\n\n索引（Index），就是相同类型的文档的集合。例如：\n\n- 所有用户文档，就可以组织在一起，称为用户的索引；\n- 所有商品的文档，可以组织在一起，称为商品的索引；\n- 所有订单的文档，可以组织在一起，称为订单的索引；\n\n![索引](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/索引.67l5ib0vvgo0.svg)\n\n因此，我们可以把索引当做是数据库中的表。\n\n数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有映射（mapping），是索引中文档的字段约束信息，类似表的结构约束。\n\n#### MySQL 与 ElasticSearch\n\n我们统一的把 MySQL 与 ElasticSearch 的概念做一下对比：\n\n| MySQL  | Elasticsearch | **说明**                                                     |\n| ------ | ------------- | ------------------------------------------------------------ |\n| Table  | Index         | 索引（index），就是文档的集合，类似数据库的表（table）       |\n| Row    | Document      | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |\n| Column | Field         | 字段（Field），就是 JSON 文档中的字段，类似数据库中的列（Column） |\n| Schema | Mapping       | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |\n| SQL    | DSL           | DSL是 ElasticSearch 提供的 JSON 风格的请求语句，用来操作 ElasticSearch，实现 CRUD |\n\n- MySQL ：擅长事务类型操作，可以确保数据的安全和一致性\n\n- ElasticSearch：擅长海量数据的搜索、分析、计算\n\n因此在企业中，往往是两者结合使用：\n\n- 对安全性要求较高的写操作，使用 MySQL 实现\n- 对查询性能要求较高的搜索需求，使用 ElasticSearch 实现\n- 两者再基于某种方式，实现数据的同步，保证一致性\n\n![ElasticSearch](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/ElasticSearch.4koj7qwgqge0.svg)\n\n### 安装 ElasticSearch 、Kibana\n\n#### 创建网络\n\n因为我们还需要部署 Kibana 容器，因此需要让 ElasticSearch 和 Kibana 容器互联。这里先创建一个网络：\n\n```sh\ndocker network create halo-es-net\n```\n\n#### 拉取或加载镜像\n\n```sh\ndocker pull elasticsearch:7.14.1\n```\n\n```sh\ndocker pull kibana:7.14.1\n```\n\n#### 运行（单点）\n\n运行 docker 命令，部署单点 ElasticSearch ：\n\n```sh\ndocker run -d \\\n	--name halo-es \\\n    -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n    -e \"discovery.type=single-node\" \\\n    -v es-data:/usr/share/elasticsearch/data \\\n    -v es-plugins:/usr/share/elasticsearch/plugins \\\n    --privileged \\\n    --network halo-es-net \\\n    -p 9200:9200 \\\n    -p 9300:9300 \\\nelasticsearch:7.14.1\n```\n\n命令解释：\n\n- `-e \"cluster.name=es-docker-cluster\"`：设置集群名称\n- `-e \"http.host=0.0.0.0\"`：监听的地址，可以外网访问\n- `-e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"`：内存大小\n- `-e \"discovery.type=single-node\"`：非集群模式\n- `-v es-data:/usr/share/elasticsearch/data`：挂载逻辑卷，绑定 ElasticSearch 的数据目录\n- `-v es-logs:/usr/share/elasticsearch/logs`：挂载逻辑卷，绑定 ElasticSearch 的日志目录\n- `-v es-plugins:/usr/share/elasticsearch/plugins`：挂载逻辑卷，绑定 ElasticSearch 的插件目录\n- `--privileged`：授予逻辑卷访问权\n- `--network halo-es-net` ：加入一个名为 halo-es-net 的网络中\n- `-p 9200:9200`：端口映射配置\n\n在浏览器中输入：http://halo:9200 即可看到 ElasticSearch 的响应结果：\n\n运行 docker 命令，部署 Kibana\n\n```sh\ndocker run -d \\\n--name halo-kibana \\\n-e ELASTICSEARCH_HOSTS=http://halo-es:9200 \\\n--network halo-es-net \\\n-p 5601:5601  \\\nkibana:7.14.1\n```\n\n- `--network es-net` ：加入一个名为es-net的网络中，与 elasticsearch 在同一个网络中\n- `-e ELASTICSEARCH_HOSTS=http://halo-es:9200\"`：设置 elasticsearch 的地址，因为 kibana 已经与elasticsearch 在一个网络，因此可以用容器名（halo-es）直接访问 elasticsearch\n- `-p 5601:5601`：端口映射配置\n\nkibana 启动一般比较慢，需要多等待一会，可以通过命令查看日志：\n\n```sh\ndocker logs -f kibana\n```\n\n在浏览器输入地址访问：http://halo:5601，即可看到结果\n\n### 安装 IK 分词器\n\nElasticSearch 在创建倒排索引时需要对文档分词；在搜索时，需要对用户输入内容分词。但默认的分词规则对中文处理并不友好。\n\n我们在 Kibana 的 DevTools 中测试：\n\n```json\nPOST /_analyze\n{\n  \"analyzer\": \"standard\",\n  \"text\": \"你好,世界! Hello,World!\"\n}\n```\n\n语法说明：\n\n+ POST：请求方式\n+ /_analyze：请求路径，这里省略了 http://halo:9200，有 kibana 帮我们补充\n+ 请求参数，JSON 风格：`analyzer`：分词器类型，这里是默认的 standard 分词器；`text`：要分词的内容\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"你\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 1,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"好\",\n      \"start_offset\" : 1,\n      \"end_offset\" : 2,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"世\",\n      \"start_offset\" : 3,\n      \"end_offset\" : 4,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"界\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 5,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"hello\",\n      \"start_offset\" : 7,\n      \"end_offset\" : 12,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"world\",\n      \"start_offset\" : 13,\n      \"end_offset\" : 18,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 5\n    }\n  ]\n}\n```\n\n处理中文分词，一般会使用 IK 分词器。https://github.com/medcl/elasticsearch-analysis-ik\n\n#### 在线安装 IK 插件\n\n```sh\n# 进入容器内部\ndocker exec -it elasticsearch /bin/bash\n\n# 在线下载并安装\n./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.14.1/elasticsearch-analysis-ik-7.14.1.zip\n\n#退出\nexit\n#重启容器\ndocker restart elasticsearch\n```\n\n#### 离线安装 IK 插件\n\n查看数据卷目录\n\n安装插件需要知道 elasticsearch 的 plugins 目录位置，而我们用了数据卷挂载，因此需要查看 elasticsearch 的数据卷目录，通过下面命令查看:\n\n```sh\ndocker volume inspect es-plugins\n```\n\n显示结果：\n\n```\n[\n    {\n        \"CreatedAt\": \"2021-09-11T12:50:57+08:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/es-plugins/_data\",\n        \"Name\": \"es-plugins\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n```\n\n说明 plugins 目录被挂载到了：`/var/lib/docker/volumes/es-plugins/_data ` 这个目录中。\n\n将 ik 分词器解压缩，重命名为 ik，上传到 es 容器的插件数据卷中后重启容器\n\n```sh\ndocker restart halo-es\n```\n\n#### 测试分词器\n\nIK 分词器包含两种模式：\n\n* `ik_smart` ：最少切分，粗粒度\n\n* `ik_max_word` ：最细切分，细粒度\n\n```json\nPOST /_analyze\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"你好,我的世界! Hello,World!\"\n}\n```\n\n结果：\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"你好\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 2,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"我\",\n      \"start_offset\" : 3,\n      \"end_offset\" : 4,\n      \"type\" : \"CN_CHAR\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"的\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 5,\n      \"type\" : \"CN_CHAR\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"世界\",\n      \"start_offset\" : 5,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"hello\",\n      \"start_offset\" : 9,\n      \"end_offset\" : 14,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"world\",\n      \"start_offset\" : 15,\n      \"end_offset\" : 20,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 5\n    }\n  ]\n}\n```\n\n#### 扩展和停用词词典\n\n随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。\n\n所以我们的词汇也需要不断的更新，IK 分词器提供了扩展词汇的功能。\n\n打开 IK 分词器 config 目录：\n\n```sh\ncd /var/lib/docker/volumes/es-plugins/_data/ik/config\n```\n\n在 IKAnalyzer.cfg.xml 配置文件内容添加：\n\n```xml\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\">\n<properties>\n        <comment>IK Analyzer 扩展配置</comment>\n        <!--用户可以在这里配置自己的扩展字典 -->\n        <entry key=\"ext_dict\">ext.dic</entry>\n         <!--用户可以在这里配置自己的扩展停止词字典-->\n        <entry key=\"ext_stopwords\">stopwort.dic</entry>\n        <!--用户可以在这里配置远程扩展字典 -->\n        <!-- <entry key=\"remote_ext_dict\">words_location</entry> -->\n        <!--用户可以在这里配置远程扩展停止词字典-->\n        <!-- <entry key=\"remote_ext_stopwords\">words_location</entry> -->\n</properties>\n```\n\n新建一个 ext.dic，可以参考 config 目录下复制一个配置文件进行修改\n\n```properties\n我的世界\n```\n\nstopwort.dic 添加\n\n```properties\n的\n```\n\n重启 ElasticSearch \n\n```sh\ndocker restart es\n\n# 查看 日志\ndocker logs -f elasticsearch\n```\n\n日志中已经成功加载 ext.dic 配置文件\n\n测试\n\n```json\nPOST /_analyze\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"你好,我的世界! Hello,World!\"\n}\n```\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"你好\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 2,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"我的世界\",\n      \"start_offset\" : 3,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"世界\",\n      \"start_offset\" : 5,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"hello\",\n      \"start_offset\" : 9,\n      \"end_offset\" : 14,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"world\",\n      \"start_offset\" : 15,\n      \"end_offset\" : 20,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 4\n    }\n  ]\n}\n```\n\n> 注意当前文件的编码必须是 UTF-8 格式，严禁使用 Windows 记事本编辑\n\n## DSL 索引库操作\n\n索引库就类似数据库表，mapping 映射就类似表的结构。我们要向 es 中存储数据，必须先创建“库”和“表”。\n\n### mapping 映射属性\n\nmapping 是对索引库中文档的约束，常见的mapping属性包括：\n\n- type：字段数据类型，常见的简单类型有：\n  - 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip 地址）\n  - 数值：long、integer、short、byte、double、float、\n  - 布尔：boolean\n  - 日期：date\n  - 对象：object\n- index：是否创建索引，默认为 true\n- analyzer：使用哪种分词器\n- properties：该字段的子字段\n\n例如下面的 JSON 文档：\n\n```json\n{\n    \"age\": 21,\n    \"weight\": 52.1,\n    \"isMarried\": false,\n    \"info\": \"黑马程序员Java讲师\",\n    \"email\": \"zy@itcast.cn\",\n    \"score\": [99.1, 99.5, 98.9],\n    \"name\": {\n        \"firstName\": \"云\",\n        \"lastName\": \"赵\"\n    }\n}\n```\n\n对应的每个字段映射（mapping）：\n\n- age：类型为 integer；参与搜索，因此需要 index 为 true；无需分词器\n- weight：类型为 float；参与搜索，因此需要 index 为 true；无需分词器\n- isMarried：类型为 boolean；参与搜索，因此需要 index 为 true；无需分词器\n- info：类型为字符串，需要分词，因此是 text；参与搜索，因此需要 index 为 true；分词器可以用 ik_smart\n- email：类型为字符串，但是不需要分词，因此是 keyword；不参与搜索，因此需要 index 为 false；无需分词器\n- score：虽然是数组，但是我们只看元素的类型，类型为 float；参与搜索，因此需要 index 为 true；无需分词器\n- name：类型为 object，需要定义多个子属性\n  - name.firstName：类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为 true；无需分词器\n  - name.lastName：类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为 true；无需分词器\n\n### 索引库的 CRUD\n\n这里统一使用 Kibana 编写 DSL 的方式来演示。\n\n#### 创建索引库和映射\n\n基本语法：\n\n+ 请求方式：PUT\n+ 请求路径：/索引库名，可以自定义\n+ 请求参数：mapping 映射\n\n```json\nPUT /索引库名称\n{\n  \"mappings\": {\n    \"properties\": {\n      \"字段名\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_smart\"\n      },\n      \"字段名2\":{\n        \"type\": \"keyword\",\n        \"index\": \"false\"\n      },\n      \"字段名3\":{\n        \"properties\": {\n          \"子字段\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      // ...略\n    }\n  }\n}\n```\n\n示例：\n\n```json\nPUT /heima\n{\n  \"mappings\": {\n    \"properties\": {\n      \"info\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_smart\"\n      },\n      \"email\":{\n        \"type\": \"keyword\",\n        \"index\": \"falsae\"\n      },\n      \"name\":{\n        \"properties\": {\n          \"firstName\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      // ... 略\n    }\n  }\n}\n```\n\n#### 查询索引库\n\n基本语法：\n\n- 请求方式：GET\n\n- 请求路径：/索引库名\n\n- 请求参数：无\n\n```\nGET /索引库名\n```\n\n#### 删除索引库\n\n语法：\n\n- 请求方式：DELETE\n\n- 请求路径：/索引库名\n\n- 请求参数：无\n\n```\nDELETE /索引库名\n```\n\n#### 修改索引库\n\n倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库一旦创建，无法修改 mapping。\n\n虽然无法修改 mapping 中已有的字段，但是却允许添加新的字段到 mapping 中，因为不会对倒排索引产生影响。\n\n语法说明：\n\n```json\nPUT /索引库名/_mapping\n{\n  \"properties\": {\n    \"新字段名\": {\n      \"type\": \"xxxx\"\n    }\n  }\n}\n```\n\n#### 索引库的 CRUD 小结\n\n- 创建索引库：PUT /索引库名\n- 查询索引库：GET /索引库名\n- 删除索引库：DELETE /索引库名\n- 添加字段：PUT /索引库名/_mapping\n\n## DSL 文档操作\n\n### 新增文档\n\n 语法：\n\n```json\nPOST /索引库名/_doc/文档id\n{\n    \"字段1\": \"值1\",\n    \"字段2\": \"值2\",\n    \"字段3\": {\n        \"子属性1\": \"值3\",\n        \"子属性2\": \"值4\"\n    },\n    // ...\n}\n```\n\n示例：\n\n```json\nPOST /halo/_doc/1\n{\n  \"info\": \"黑马程序员Java讲师\",\n  \"email\": \"zy@itcast.cn\",\n  \"name\": {\n    \"firstName\": \"云\",\n    \"lastName\": \"赵\"\n  }\n}\n```\n\n### 查询文档\n\n根据 rest 风格，新增是 post，查询应该是 get，不过查询一般都需要条件，这里我们把文档 id 带上。\n\n语法：\n\n```\nGET /{索引库名称}/_doc/{id}\n```\n\n通过 kibana 查看数据：\n\n```\nGET /halo/_doc/1\n```\n\n### 删除文档\n\n删除使用 DELETE 请求，同样，需要根据 id 进行删除：\n\n语法：\n\n```\nDELETE /{索引库名}/_doc/id值\n```\n\n示例：\n\n```\nDELETE /halo/_doc/1\n```\n\n### 修改文档\n\n修改有两种方式：\n\n- 全量修改：直接覆盖原来的文档\n- 增量修改：修改文档中的部分字段\n\n#### 全量修改\n\n全量修改是覆盖原来的文档，其本质是：\n\n- 根据指定的 id 删除文档\n- 新增一个相同 id 的文档\n\n> 注意：如果根据 id 删除时，id 不存在，第二步的新增也会执行，也就从修改变成了新增操作了。\n\n语法：\n\n```json\nPUT /{索引库名}/_doc/文档id\n{\n    \"字段1\": \"值1\",\n    \"字段2\": \"值2\",\n    // ... 略\n}\n```\n\n示例：\n\n```json\nPUT /halo/_doc/1\n{\n  \"info\": \"黑马程序员高级Java讲师2\",\n  \"email\": \"zy@itcast.cn\",\n  \"name\": {\n    \"firstName\": \"云\",\n    \"lastName\": \"赵\"\n  }\n}\n```\n\n#### 增量修改\n\n增量修改是只修改指定 id 匹配的文档中的部分字段。\n\n语法：\n\n```json\nPOST /{索引库名}/_update/文档id\n{\n    \"doc\": {\n         \"字段名\": \"新的值\",\n    }\n}\n```\n\n示例：\n\n```\nPOST /halo/_update/1\n{\n  \"doc\": {\n    \"email\": \"ZhaoYun@itcast.cn\"\n  }\n}\n```\n\n### 文档操作总结\n\n- 创建文档：POST /{索引库名}/_doc/文档id   { JSON 文档 }\n- 查询文档：GET /{索引库名}/_doc/文档id\n- 删除文档：DELETE /{索引库名}/_doc/文档id\n- 修改文档：\n  - 全量修改：PUT /{索引库名}/_doc/文档id { JSON 文档 }\n  - 增量修改：POST /{索引库名}/_update/文档id { \"doc\": {字段}}\n\n## Rest Client 索引库操作\n\nElasticSearch 官方提供了各种不同语言的客户端，用来操作 ElasticSearch。这些客户端的本质就是组装 DSL 语句，通过 http 请求发送给 ElasticSearch。官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html\n\n其中的 Java Rest Client 又包括两种：\n\n- Java Low Level Rest Client\n- Java High Level Rest Client\n\n我们学习的是 Java HighLevel Rest Client 客户端 API\n\n### 创建测试环境\n\n#### 初始化项目\n\n创建数据库，建立数据表\n\n```sql\nCREATE TABLE `tb_hotel`  (\n    `id` bigint(20) NOT NULL COMMENT \'酒店id\',\n    `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'酒店名称\',\n    `address` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'酒店地址\',\n    `price` int(10) NOT NULL COMMENT \'酒店价格\',\n    `score` int(2) NOT NULL COMMENT \'酒店评分\',\n    `brand` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'酒店品牌\',\n    `city` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'所在城市\',\n    `star_name` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT \'酒店星级，1星到5星，1钻到5钻\',\n    `business` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT \'商圈\',\n    `latitude` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'纬度\',\n    `longitude` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'经度\',\n    `pic` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT \'酒店图片\',\n    PRIMARY KEY (`id`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;\n```\n\n导入数据库数据：[链接](https://github.com/Lanqilu/HaloElasticSearch/blob/master/doc/database/tb_hotel.sql)\n\n初始项目代码：[链接](https://github.com/Lanqilu/HaloElasticSearch/commit/d64b305ccf9ca67b8a18bafee3df7163e7dd8246)\n\n#### mapping 映射分析\n\n创建索引库，最关键的是 mapping 映射，而 mapping 映射要考虑的信息包括：\n\n- 字段名\n- 字段数据类型\n- 是否参与搜索\n- 是否需要分词\n- 如果分词，分词器是什么？\n\n其中：\n\n- 字段名、字段数据类型，可以参考数据表结构的名称和类型\n- 是否参与搜索要分析业务来判断，例如图片地址，就无需参与搜索\n- 是否分词呢要看内容，内容如果是一个整体就无需分词，反之则要分词\n- 分词器，我们可以统一使用 ik_max_word\n\n来看下酒店数据的索引库结构：\n\n```json\nPUT /hotel\n{\n  \"mappings\": {\n    \"properties\": {\n      \"id\": {\n        \"type\": \"keyword\"\n      },\n      \"name\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"copy_to\": \"all\"\n      },\n      \"address\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"price\":{\n        \"type\": \"integer\"\n      },\n      \"score\":{\n        \"type\": \"integer\"\n      },\n      \"brand\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"city\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"starName\":{\n        \"type\": \"keyword\"\n      },\n      \"business\":{\n        \"type\": \"keyword\"\n      },\n      \"location\":{\n        \"type\": \"geo_point\"\n      },\n      \"pic\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"all\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\"\n      }\n    }\n  }\n}\n```\n\n几个特殊字段说明：\n\n- location：地理坐标，里面包含精度、纬度\n- all：一个组合字段，其目的是将多字段的值 利用 copy_to 合并，提供给用户搜索\n\n ES 中支持两种地理坐标数据类型：\n\n•geo_point：由纬度（latitude）和经度（longitude）确定的一个点。例如：\"32.8752345, 120.2981576\"\n\n•geo_shape：有多个geo_point组成的复杂几何图形。例如一条直线，\"LINESTRING (-77.03653 38.897676, -77.009051 38.889939)\"\n\n字段拷贝可以使用 copy_to 属性将当前字段拷贝到指定字段。示例：\n\n```json\n\"all\": {\n  \"type\": \"text\",\n  \"analyzer\": \"ik_max_word\"\n},\n\"brand\": {\n  \"type\": \"keyword\",\n  \"copy_to\": \"all\"\n}\n```\n\n#### 初始化 RestClient\n\n在 ElasticSearch 提供的 API 中，与 ElasticSearch 一切交互都封装在一个名为 RestHighLevelClient 的类中，必须先完成这个对象的初始化，建立与 ElasticSearch 的连接。\n\n分为三步：\n\n① 引入 ElasticSearch 的 RestHighLevelClient 依赖：\n\n```xml\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>elasticsearch-rest-high-level-client</artifactId>\n</dependency>\n```\n\n② 因为 SpringBoot 默认的 ElasticSearch 版本是 7.6.2，所以我们需要覆盖默认的 ElasticSearch 版本，与 ElasticSearch 版本保持一致\n\n```xml\n<properties>\n    <java.version>1.8</java.version>\n    <elasticsearch.version>7.14.1</elasticsearch.version>\n</properties>\n```\n\n③ 初始化 RestHighLevelClient：\n\n初始化的代码如下：\n\n```java\nRestHighLevelClient client = new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n```\n\n这里为了单元测试方便，我们创建一个测试类 HotelIndexTest，然后将初始化的代码编写在 `@BeforeEach` 方法中：\n\n```java\npublic class HotelIndexTest {\n\n    private RestHighLevelClient client;\n\n    @Test\n    void testInit() {\n        System.out.println(\"client = \" + client);\n    }\n\n    @BeforeEach\n    void setUp() {\n        this.client = new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n    }\n\n    @AfterEach\n    void tearDown() throws IOException {\n        this.client.close();\n    }\n}\n```\n\n### 创建索引库\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.zlx2xrhd54w.png)\n\n代码分为三步：\n\n1. 创建 Request 对象。因为是创建索引库的操作，因此 Request 是 CreateIndexRequest\n2. 添加请求参数，其实就是 DSL 的 JSON 参数部分。因为 JSON 字符串很长，这里是定义了静态字符串常量 MAPPING_TEMPLATE，让代码看起来更加优雅。\n3. 发送请求，`client.indices()` 方法的返回值是 IndicesClient 类型，封装了所有与索引库操作有关的方法。\n\n在 hotel-demo 中的 HotelIndexTest 测试类中，编写单元测试，实现创建索引：\n\n```java\n@Test\nvoid createHotelIndex() throws IOException {\n    // 1.创建Request对象\n    CreateIndexRequest request = new CreateIndexRequest(\"hotel\");\n    // 2.准备请求的参数：DSL语句\n    request.source(MAPPING_TEMPLATE, XContentType.JSON);\n    // 3.发送请求\n    client.indices().create(request, RequestOptions.DEFAULT);\n}\n```\n\n### 删除索引库\n\n删除索引库的 DSL 语句非常简单：\n\n```json\nDELETE /hotel\n```\n\n与创建索引库相比：\n\n- 请求方式从 PUT 变为 DELTE\n- 请求路径不变\n- 无请求参数\n\n所以代码的差异，注意体现在 Request 对象上。依然是三步走：\n\n- 创建 Request 对象。这次是 DeleteIndexRequest 对象\n- 准备参数。这里是无参\n- 发送请求。改用 delete 方法\n\n在 hotel-demo 中的 HotelIndexTest 测试类中，编写单元测试，实现删除索引：\n\n```java\n@Test\nvoid testDeleteHotelIndex() throws IOException {\n    // 1.创建Request对象\n    DeleteIndexRequest request = new DeleteIndexRequest(\"hotel\");\n    // 2.发送请求\n    client.indices().delete(request, RequestOptions.DEFAULT);\n}\n```\n\n### 判断索引库是否存在\n\n判断索引库是否存在，本质就是查询，对应的DSL是：\n\n```json\nGET /hotel\n```\n\n因此与删除的 Java 代码流程是类似的。依然是三步走：\n\n- 创建 Request 对象。这次是 GetIndexRequest 对象\n- 准备参数。这里是无参\n- 发送请求。改用 exists 方法\n\n```java\n@Test\nvoid testExistsHotelIndex() throws IOException {\n    // 1.创建Request对象\n    GetIndexRequest request = new GetIndexRequest(\"hotel\");\n    // 2.发送请求\n    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);\n    // 3.输出\n    System.err.println(exists ? \"索引库已经存在！\" : \"索引库不存在！\");\n}\n```\n\n### RestAPI 小结\n\nJavaRestClient 操作 ElasticSearch 的流程基本类似。核心是 `client.indices()` 方法来获取索引库的操作对象。\n\n索引库操作的基本步骤：\n\n- 初始化 RestHighLevelClient\n- 创建 XxxIndexRequest。Xxx 是Create、Get、Delete\n- 准备 DSL（ Create时需要，其它是无参）\n- 发送请求。调用 `RestHighLevelClient#indices().xxx()` 方法，xxx 是  create、exists、delete\n\n## Rest Client 文档操作\n\n去数据库查询酒店数据，导入到 hotel 索引库，实现酒店数据的 CRUD。基本步骤如下：\n\n+ 初始化 JavaRestClient\n+ 利用 JavaRestClient 新增酒店数据\n+ 利用 JavaRestClient 根据id查询酒店数据\n+ 利用 JavaRestClient 删除酒店数据\n+ 利用 JavaRestClient 修改酒店数据\n\n### 初始化 JavaRestClient\n\n为了与索引库操作分离，我们再次参加一个测试类，做两件事情：\n\n- 初始化 RestHighLevelClient，同上\n- 我们的酒店数据在数据库，需要利用 IHotelService 去查询，所以注入这个接口\n\n```java\n@SpringBootTest\npublic class HotelDocumentTest {\n    @Autowired\n    private IHotelService hotelService;\n\n    private RestHighLevelClient client;\n\n    @BeforeEach\n    void setUp() {\n        this.client = new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n    }\n\n    @AfterEach\n    void tearDown() throws IOException {\n        this.client.close();\n    }\n}\n```\n\n### 新增文档\n\n我们要将数据库的酒店数据查询出来，写入 ElasticSearch 中。\n\n#### 索引库实体类\n\n数据库查询后的结果是一个 Hotel 类型的对象。结构如下：\n\n```java\n@Data\n@TableName(\"tb_hotel\")\npublic class Hotel {\n    @TableId(type = IdType.INPUT)\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String longitude;\n    private String latitude;\n    private String pic;\n}\n```\n\n与我们的索引库结构存在差异：\n\n- longitude 和 latitude 需要合并为 location\n\n因此，我们需要定义一个新的类型，与索引库结构吻合：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n\n#### 语法说明\n\n新增文档的 DSL 语句如下：\n\n```json\nPOST /{索引库名}/_doc/1\n{\n    \"name\": \"Jack\",\n    \"age\": 21\n}\n```\n\n对应的 Java 代码如下：\n\n```java\n@Test\nvoid testIndexDocument() throws IOException {\n    // 1.创建request对象\n    IndexRequest request = new IndexRequest(\"indexName\").id(\"1\");\n    // 2.准备JSON文档\n    request.source(\"{\\\"name\\\": \\\"Jack\\\", \\\"age\\\": 21}\", XContentType.JSON);\n    // 3.发送请求\n    client.index(request, RequestOptions.DEFAULT);\n}\n```\n\n可以看到与创建索引库类似，同样是三步走：\n\n- 创建 Request 对象\n- 准备请求参数，也就是 DSL 中的 JSON 文档\n- 发送请求\n\n变化的地方在于，这里直接使用 `client.xxx()` 的 API，不再需要 `client.indices()` 了。\n\n#### 完整代码\n\n我们导入酒店数据，基本流程一致，但是需要考虑几点变化：\n\n- 酒店数据来自于数据库，我们需要先查询出来，得到 Hotel 对象\n- Hotel 对象需要转为 HotelDoc对象\n- HotelDoc 需要序列化为 JSON 格式\n\n因此，代码整体步骤如下：\n\n- 根据 id 查询酒店数据 Hotel\n- 将 Hotel 封装为 HotelDoc\n- 将 HotelDoc 序列化为 JSON\n- 创建 IndexRequest，指定索引库名和 id\n- 准备请求参数，也就是 JSON 文档\n- 发送请求\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testAddDocument() throws IOException {\n    // 1.根据id查询酒店数据\n    Hotel hotel = hotelService.getById(61083L);\n    // 2.转换为文档类型\n    HotelDoc hotelDoc = new HotelDoc(hotel);\n    // 3.将HotelDoc转json\n    String json = JSON.toJSONString(hotelDoc);\n\n    // 1.准备Request对象\n    IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString());\n    // 2.准备Json文档\n    request.source(json, XContentType.JSON);\n    // 3.发送请求\n    client.index(request, RequestOptions.DEFAULT);\n}\n```\n\n### 查询文档\n\n#### 语法说明\n\n查询的 DSL 语句如下：\n\n```json\nGET /hotel/_doc/{id}\n```\n\n非常简单，因此代码大概分两步：\n\n- 准备 Request 对象\n- 发送请求\n\n不过查询的目的是得到结果，解析为 HotelDoc，因此难点是结果的解析。示例代码如下：\n\n```java\n@Test\nvoid testGetDocumentById() throws IOException {\n    // 1.创建request对象\n    GetRequest request = new GetRequest(\"indexName\", \"1\");\n    // 2.发送请求，得到结果\n    GetResponse response = client.get(request, RequestOptions.DEFAULT);\n    // 3.解析结果\n    String json = response.getSourceAsString();\n    System.out.println(json);\n}\n```\n\n可以看到，结果是一个 JSON，其中文档放在一个 `_source` 属性中，因此解析就是拿到 `_source`，反序列化为 Java 对象即可。\n\n与之前类似，也是三步走：\n\n- 准备 Request 对象。这次是查询，所以是 GetRequest\n- 发送请求，得到结果。因为是查询，这里调用 `client.get()` 方法\n- 解析结果，就是对 JSON 做反序列化\n\n#### 完整代码\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testGetDocumentById() throws IOException {\n    // 1.准备Request\n    GetRequest request = new GetRequest(\"hotel\", \"61083\");\n    // 2.发送请求，得到响应\n    GetResponse response = client.get(request, RequestOptions.DEFAULT);\n    // 3.解析响应结果\n    String json = response.getSourceAsString();\n    HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n    System.out.println(hotelDoc);\n}\n```\n\n### 修改文档\n\n#### 语法说明\n\n修改我们讲过两种方式：\n\n- 全量修改：本质是先根据id删除，再新增\n- 增量修改：修改文档中的指定字段值\n\n在 RestClient 的 API 中，全量修改与新增的 API 完全一致，判断依据是 ID：\n\n- 如果新增时，ID 已经存在，则修改\n- 如果新增时，ID 不存在，则新增\n\n这里不再赘述，我们主要关注增量修改。\n\n```java\n@Test\nvoid testUpdateDocumentById() throws IOException {\n    // 1.创建request对象\n    UpdateRequest request = new UpdateRequest(\"indexName\", \"1\");\n    // 2.准备参数，每2个参数为一对 key value    \n    request.doc(\"age\", 18, \"name\", \"Rose\");\n    // 3.更新文档\n    client.update(request, RequestOptions.DEFAULT);\n}\n```\n\n与之前类似，也是三步走：\n\n- 准备 Request 对象。这次是修改，所以是 UpdateRequest\n- 准备参数。也就是 JSON 文档，里面包含要修改的字段\n- 更新文档。这里调用 `client.update()` 方法\n\n#### 完整代码\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testUpdateDocument() throws IOException {\n    // 1.准备Request\n    UpdateRequest request = new UpdateRequest(\"hotel\", \"61083\");\n    // 2.准备请求参数\n    request.doc(\n        \"price\", \"952\",\n        \"starName\", \"四钻\"\n    );\n    // 3.发送请求\n    client.update(request, RequestOptions.DEFAULT);\n}\n```\n\n### 删除文档\n\n删除的 DSL 为是这样的：\n\n```json\nDELETE /hotel/_doc/{id}\n```\n\n与查询相比，仅仅是请求方式从 DELETE 变成 GET，可以想象 Java 代码应该依然是三步走：\n\n- 准备 Request 对象，因为是删除，这次是 DeleteRequest 对象。要指定索引库名和 id\n- 准备参数，无参\n- 发送请求。因为是删除，所以是 `client.delete()` 方法\n\n```java\n@Test\nvoid testDeleteDocument() throws IOException {\n    // 1.准备Request\n    DeleteRequest request = new DeleteRequest(\"hotel\", \"61083\");\n    // 2.发送请求\n    client.delete(request, RequestOptions.DEFAULT);\n}\n```\n\n### 批量导入文档\n\n案例需求：利用 BulkRequest 批量将数据库数据导入到索引库中。\n\n步骤如下：\n\n- 利用 mybatis-plus 查询酒店数据\n\n- 将查询到的酒店数据（Hotel）转换为文档类型数据（HotelDoc）\n\n- 利用 JavaRestClient 中的 BulkRequest 批处理，实现批量新增文档\n\n#### 语法说明\n\n批量处理 BulkRequest，其本质就是将多个普通的 CRUD 请求组合在一起发送。\n\n其中提供了一个 add 方法，用来添加其他请求：\n\n- IndexRequest，也就是新增\n- UpdateRequest，也就是修改\n- DeleteRequest，也就是删除\n\n因此 Bulk 中添加了多个 IndexRequest，就是批量新增功能了。示例：\n\n```java\n@Test\nvoid testBulk() throws IOException {\n    // 1.创建Bulk请求\n    BulkRequest request = new BulkRequest();\n    // 2.添加要批量提交的请求：这里添加了两个新增文档的请求\n    request.add(new IndexRequest(\"hotel\")\n                .id(\"101\").source(\"json source\", XContentType.JSON));\n    request.add(new IndexRequest(\"hotel\")\n                .id(\"102\").source(\"json source2\", XContentType.JSON));\n    // 3.发起bulk请求\n    client.bulk(request, RequestOptions.DEFAULT);\n}\n```\n\n其实还是三步走：\n\n- 创建 Request 对象。这里是 BulkRequest\n- 准备参数。批处理的参数，就是其它 Request 对象，这里就是多个 IndexRequest\n- 发起请求。这里是批处理，调用的方法为 `client.bulk()` 方法\n\n我们在导入酒店数据时，将上述代码改造成 for 循环处理即可。\n\n#### 完整代码\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testBulkRequest() throws IOException {\n    // 批量查询酒店数据\n    List<Hotel> hotels = hotelService.list();\n\n    // 1.创建 Request\n    BulkRequest request = new BulkRequest();\n    // 2.准备参数，添加多个新增的 Request\n    for (Hotel hotel : hotels) {\n        // 2.1.转换为文档类型 HotelDoc\n        HotelDoc hotelDoc = new HotelDoc(hotel);\n        // 2.2.创建新增文档的 Request 对象\n        request.add(new IndexRequest(\"hotel\")\n                    .id(hotelDoc.getId().toString())\n                    .source(JSON.toJSONString(hotelDoc), XContentType.JSON));\n    }\n    // 3.发送请求\n    client.bulk(request, RequestOptions.DEFAULT);\n}\n```\n\n测试，批量查询\n\n```\nGET /hotel/_search\n```\n\n### Rest Client 文档操作小结\n\n文档操作的基本步骤：\n\n- 初始化 RestHighLevelClient\n- 创建 XxxRequest。Xxx 是 Index、Get、Update、Delete、Bulk\n- 准备参数（Index、Update、Bulk时需要）\n- 发送请求。调用 `RestHighLevelClient#.xxx()` 方法，xxx 是 index、get、update、delete、bulk\n- 解析结果（Get时需要）\n\n## DSL 查询文档\n\nElasticSearch 的查询依然是基于 JSON 风格的 DSL 来实现的。\n\n### DSL 查询分类\n\nElasticSearch 提供了基于 JSON 的 DSL（[Domain Specific Language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)）来定义查询。常见的查询类型包括：\n\n- 查询所有：查询出所有数据，一般测试用。例如：match_all\n\n- 全文检索查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：\n  - match_query\n  - multi_match_query\n- 精确查询：根据精确词条值查找数据，一般是查找 keyword、数值、日期、boolean 等类型字段。例如：\n  - ids\n  - range\n  - term\n- 地理（geo）查询：根据经纬度查询。例如：\n  - geo_distance\n  - geo_bounding_box\n- 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：\n  - bool\n  - function_score\n\n查询的语法基本一致：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"查询类型\": {\n      \"查询条件\": \"条件值\"\n    }\n  }\n}\n```\n\n 我们以查询所有为例，其中：\n\n- 查询类型为 match_all\n- 没有查询条件\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n其它查询无非就是查询类型、查询条件的变化。\n\n### 全文检索查询\n\n#### 使用场景\n\n全文检索查询的基本流程如下：\n\n- 对用户搜索的内容做分词，得到词条\n- 根据词条去倒排索引库中匹配，得到文档 id\n- 根据文档 id 找到文档，返回给用户\n\n比较常用的场景包括：\n\n- 商城的输入框搜索\n- 百度输入框搜索\n\n因为是拿着词条去匹配，因此参与搜索的字段也必须是可分词的 text 类型的字段。\n\n#### 基本语法\n\n常见的全文检索查询包括：\n\n- match 查询：单字段查询\n- multi_match 查询：多字段查询，任意一个字段符合条件就算符合查询条件\n\nmatch 查询语法如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match\": {\n      \"FIELD\": \"TEXT\"\n    }\n  }\n}\n```\n\nmulit_match 语法如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"TEXT\",\n      \"fields\": [\"FIELD1\", \" FIELD12\"]\n    }\n  }\n}\n```\n\n#### 使用示例\n\nmatch 查询示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家外滩\"\n    }\n  }\n}\n```\n\nmulti_match 查询示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"如家外滩\",\n      \"fields\": [\"brand\",\"name\",\"business\"]\n    }\n  }\n}\n```\n\n可以看到，两种查询结果是一样的，为什么？\n\n因为我们将 brand、name、business 值都利用 copy_to 复制到了 all 字段中。因此你根据三个字段搜索，和根据 all 字段搜索效果当然一样了。\n\n但是，搜索字段越多，对查询性能影响越大，因此建议采用 copy_to，然后单字段查询的方式。\n\nmatch 和 multi_match 的区别是什么？\n\n- match：根据一个字段查询\n- multi_match：根据多个字段查询，参与查询字段越多，查询性能越差\n\n### 精准查询\n\n精确查询一般是查找 keyword、数值、日期、boolean 等类型字段。所以不会对搜索条件分词。常见的有：\n\n- term：根据词条精确值查询\n- range：根据值的范围查询\n\n#### term 查询\n\n因为精确查询的字段搜是不分词的字段，因此查询的条件也必须是**不分词**的词条。查询时，用户输入的内容跟自动值完全匹配时才认为符合条件。如果用户输入的内容过多，反而搜索不到数据。\n\n语法说明：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"term\": {\n      \"FIELD\": {\n        \"value\": \"VALUE\"\n      }\n    }\n  }\n}\n```\n\n示例：\n\n当我搜索的是精确词条时，能正确查询出结果：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"city\": {\n        \"value\": \"上海\"\n      }\n    }\n  }\n}\n```\n\n但是，当我搜索的内容不是词条，而是多个词语形成的短语时，反而搜索不到：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"city\": {\n        \"value\": \"上海杭州\"\n      }\n    }\n  }\n}\n```\n\n#### range 查询\n\n范围查询，一般应用在对数值类型做范围过滤的时候。比如做价格范围过滤。\n\n基本语法：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"range\": {\n      \"FIELD\": {\n        \"gte\": 10,\n        \"lte\": 20\n      }\n    }\n  }\n}\n```\n\n+ gte 代表大于等于，gt 则代表大于\n+ lte 代表小于等于，lt 则代表小于\n\n示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"gte\": 1000,\n        \"lte\": 3000\n      }\n    }\n  }\n}\n```\n\n#### 精准查询小结\n\n精确查询常见的有哪些？\n\n- term 查询：根据词条精确匹配，一般搜索 keyword 类型、数值类型、布尔类型、日期类型字段\n- range 查询：根据数值范围查询，可以是数值、日期的范围\n\n### 地理坐标查询\n\n所谓的地理坐标查询，其实就是根据经纬度查询，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html)\n\n常见的使用场景包括：\n\n- 携程：搜索我附近的酒店\n- 滴滴：搜索我附近的出租车\n- 微信：搜索我附近的人\n\n#### 矩形范围查询\n\n矩形范围查询，也就是 geo_bounding_box 查询，查询坐标落在某个矩形范围的所有文档：\n\n查询时，需要指定矩形的**左上**、**右下**两个点的坐标，然后画出一个矩形，落在该矩形内的都是符合条件的点。\n\n语法如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"geo_bounding_box\": {\n      \"FIELD\": {\n        \"top_left\": {\n          \"lat\": 31.1,\n          \"lon\": 121.5\n        },\n        \"bottom_right\": {\n          \"lat\": 30.9,\n          \"lon\": 121.7\n        }\n      }\n    }\n  }\n}\n```\n\n#### 附近查询\n\n附近查询，也叫做距离查询（geo_distance）：查询到指定中心点小于某个距离值的所有文档。\n\n换句话来说，在地图上找一个点作为圆心，以指定距离为半径，画一个圆，落在圆内的坐标都算符合条件：\n\n语法说明：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"15km\",\n      \"FIELD\": \"31.21,121.5\"\n    }\n  }\n}\n```\n\n我们先搜索陆家嘴附近 15km 的酒店：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"2km\",\n      \"location\": \"31.21,121.5\"\n    }\n  }\n}\n```\n\n### 复合查询\n\n复合（compound）查询：复合查询可以将其它简单查询组合起来，实现更复杂的搜索逻辑。常见的有两种：\n\n- fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名\n- bool query：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索\n\n#### 相关性算分\n\n当我们利用 match 查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。\n\n例如，我们搜索 \"虹桥如家\"，结果如下：\n\n```json\n[\n  {\n    \"_score\" : 17.850193,\n    \"_source\" : {\n      \"name\" : \"虹桥如家酒店真不错\",\n    }\n  },\n  {\n    \"_score\" : 12.259849,\n    \"_source\" : {\n      \"name\" : \"外滩如家酒店真不错\",\n    }\n  },\n  {\n    \"_score\" : 11.91091,\n    \"_source\" : {\n      \"name\" : \"迪士尼如家酒店真不错\",\n    }\n  }\n]\n```\n\n在 ElasticSearch 中，早期使用的打分算法是 [TF-IDF 算法](https://www.ruanyifeng.com/blog/2013/03/tf-idf.html)，在后来的 5.1 版本升级中，ElasticSearch 将算法改进为 [BM25 算法](https://www.jianshu.com/p/1e498888f505)\n\nTF-IDF 算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而 BM25 则会让单个词条的算分有一个上限，曲线更加平滑：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.32gad6dlyzu0.png)\n\n#### 算分函数查询\n\n根据相关度打分是比较合理的需求，但合理的不一定是产品经理需要的。\n\n以百度为例，你搜索的结果中，并不是相关度越高排名越靠前，而是谁掏的钱多排名就越靠前。要想认为控制相关性算分，就需要利用 ElasticSearch 中的 function score 查询了。\n\n语法说明：\n\n![算分函数查询](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/算分函数查询.epggagjz1ts.svg)\n\nfunction score 查询中包含四部分内容：\n\n- 原始查询条件：query 部分，基于这个条件搜索文档，并且基于 BM25 算法给文档打分，原始算分（query score)\n- 过滤条件：filter 部分，符合该条件的文档才会重新算分\n- 算分函数：符合 filter 条件的文档要根据这个函数做运算，得到的函数算分（function score），有四种函数\n  - weight：函数结果是常量\n  - field_value_factor：以文档中的某个字段值作为函数结果\n  - random_score：以随机数作为函数结果\n  - script_score：自定义算分函数算法\n- 运算模式：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括：\n  - multiply：相乘\n  - replace：用 function score 替换 query score\n  - 其它，例如：sum、avg、max、min\n\nfunction score 的运行流程如下：\n\n- 根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score）\n- 根据过滤条件，过滤文档\n- 符合**过滤条件**的文档，基于算分函数运算，得到函数算分（function score）\n- 将原始算分（query score）和函数算分（function score）基于运算模式做运算，得到最终结果，作为相关性算分。\n\n因此，其中的关键点是：\n\n- 过滤条件：决定哪些文档的算分被修改\n- 算分函数：决定函数算分的算法\n- 运算模式：决定最终算分结果\n\n示例\n\n需求：给“如家”这个品牌的酒店排名靠前一些。翻译一下这个需求，转换为之前说的四个要点：\n\n- 原始条件：不确定，可以任意变化\n- 过滤条件：brand = \"如家\"\n- 算分函数：可以简单粗暴，直接给固定的算分结果，weight\n- 运算模式：比如求和\n\n因此最终的 DSL 语句如下：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": {\n          \"all\": \"外滩\"\n        }\n      },\n      \"functions\": [\n        {\n          \"filter\": {\n            \"term\": {\n              \"brand\": \"如家\"\n            }\n          },\n          \"weight\": 10\n        }\n      ],\n      \"boost_mode\": \"sum\"\n    }\n  }\n}\n```\n\n#### 布尔查询\n\n布尔查询是一个或多个查询子句的组合，每一个子句就是一个子查询。子查询的组合方式有：\n\n- must：必须匹配每个子查询，类似“与”\n- should：选择性匹配子查询，类似“或”\n- must_not：必须不匹配，**不参与算分**，类似“非”\n- filter：必须匹配，不参与算分\n\n比如在搜索酒店时，除了关键字搜索外，我们还可能根据品牌、价格、城市等字段做过滤。\n\n每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用 bool 查询了。\n\n需要注意的是，搜索时，参与打分的字段越多，查询的性能也越差。因此这种多条件查询时，建议这样做：\n\n- 搜索框的关键字搜索，是全文检索查询，使用 must 查询，参与算分\n- 其它过滤条件，采用 filter 查询。不参与算分\n\n语法示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"city\": \"上海\"\n          }\n        }\n      ],\n      \"should\": [\n        {\n          \"term\": {\n            \"brand\": \"皇冠假日\"\n          }\n        },\n        {\n          \"term\": {\n            \"brand\": \"华美达\"\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"range\": {\n            \"price\": {\n              \"lte\": 500\n            }\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"range\": {\n            \"score\": {\n              \"gte\": 45\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n案例示例：\n\n需求：搜索名字包含“如家”，价格不高于 400，在坐标 31.21,121.5 周围 10km 范围内的酒店。\n\n分析：\n\n- 名称搜索，属于全文检索查询，应该参与算分。放到 must 中\n- 价格不高于 400，用 range 查询，属于过滤条件，不参与算分。放到 must_not 中\n- 周围 10km 范围内，用 geo_distance 查询，属于过滤条件，不参与算分。放到 filter 中\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match\": {\n            \"name\": \"如家\"\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"range\": {\n            \"price\": {\n              \"gt\": 400\n            }\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"geo_distance\": {\n            \"distance\": \"10km\",\n            \"location\": {\n              \"lat\": 31.21,\n              \"lon\": 121.5\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nbool 查询有几种逻辑关系？\n\n- must：必须匹配的条件，可以理解为“与”\n- should：选择性匹配的条件，可以理解为“或”\n- must_not：必须不匹配的条件，不参与打分\n- filter：必须匹配的条件，不参与打分\n\n## DSL 搜索结果处理\n\n搜索的结果可以按照用户指定的方式去处理或展示。\n\n### 排序\n\nElasticSearch默认是根据相关度算分（_score）来排序，但是也支持自定义方式对搜索[结果排序](https://www.elastic.co/guide/en/elasticsearch/reference/current/sort-search-results.html)。可以排序字段类型有：keyword 类型、数值类型、地理坐标类型、日期类型等。\n\n#### 普通字段排序\n\nkeyword、数值、日期类型排序的语法基本一致。\n\n**语法**：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"FIELD\": \"desc\"  // 排序字段、排序方式ASC、DESC\n    }\n  ]\n}\n```\n\n排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推\n\n**示例**：\n\n需求描述：酒店数据按照用户评价（score）降序排序，评价相同的按照价格（price）升序排序\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"score\": \"desc\"\n    },\n    {\n      \"price\": \"asc\"\n    }\n  ]\n}\n```\n\n#### 地理坐标排序\n\n地理坐标排序略有不同。\n\n**语法说明**：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"_geo_distance\" : {\n          \"FIELD\" : \"纬度，经度\", // 文档中geo_point类型的字段名、目标坐标点\n          \"order\" : \"asc\", // 排序方式\n          \"unit\" : \"km\" // 排序的距离单位\n      }\n    }\n  ]\n}\n```\n\n这个查询的含义是：\n\n- 指定一个坐标，作为目标点\n- 计算每一个文档中，指定字段（必须是 geo_point 类型）的坐标到目标点的距离是多少\n- 根据距离排序\n\n**示例：**\n\n需求描述：实现对酒店数据按照到你的位置坐标的距离升序排序\n\n提示：获取经纬度的方式：https://lbs.amap.com/demo/jsapi-v2/example/map/click-to-get-lnglat/\n\n假设我的位置是：31.034661，121.612282，寻找我周围距离最近的酒店。\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"location\": {\n          \"lat\": 31.034661,\n          \"lon\": 121.612282\n        },\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ]\n}\n```\n\n### 分页\n\nElasticSearch 默认情况下只返回 top10 的数据。而如果要查询更多数据就需要修改分页参数了。ElasticSearch中通过修改 from、size 参数来控制要返回的分页结果：\n\n- from：从第几个文档开始\n- size：总共查询几个文档\n\n类似于 MySQL 中的 `limit ?, ?`\n\n#### 基本的分页\n\n分页的基本语法如下：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"price\": {\n        \"order\": \"asc\"\n      }\n    }\n  ],\n  \"from\": 0,\n  \"size\": 5\n}\n```\n\n#### 深度分页问题\n\n现在，我要查询 990~1000 的数据，查询逻辑要这么写：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"from\": 990, // 分页开始的位置，默认为0\n  \"size\": 10, // 期望获取的文档总数\n  \"sort\": [\n    {\"price\": \"asc\"}\n  ]\n}\n```\n\n这里是查询 990 开始的数据，也就是 第 990~1000 条 数据。\n\n不过，ElasticSearch 内部分页时，必须先查询 0~1000 条，然后截取其中的 990 ~ 1000 的这 10 条：\n\n查询 top 1000，如果 ElasticSearch 是单点模式，这并无太大影响。\n\n但是 ElasticSearch 将来一定是集群，例如我集群有 5 个节点，我要查询 top 1000 的数据，并不是每个节点查询 200 条就可以了。\n\n因为节点 A 的 top 200，在另一个节点可能排到 10000 名以外了。\n\n因此要想获取整个集群的 top 1000，必须先查询出每个节点的 top 1000，汇总结果后，重新排名，重新截取 top 1000。\n\n那如果我要查询 9900~10000 的数据呢？是不是要先查询 top 10000呢？那每个节点都要查询 10000 条？汇总到内存中？\n\n当查询分页深度较大时，汇总数据过多，对内存和 CPU 会产生非常大的压力，因此 ElasticSearch 会禁止 from + size 超过 10000 的请求。\n\n针对深度分页，ElasticSearch 提供了两种解决方案，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html)：\n\n- search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。\n- scroll：原理将排序后的文档 id 形成快照，保存在内存。官方已经不推荐使用。\n\n#### 分页小结\n\n分页查询的常见实现方案以及优缺点：\n\n- `from + size`：\n  - 优点：支持随机翻页\n  - 缺点：深度分页问题，默认查询上限（from + size）是 10000\n  - 场景：百度、京东、谷歌、淘宝这样的随机翻页搜索\n- `after search`：\n  - 优点：没有查询上限（单次查询的 size 不超过 10000）\n  - 缺点：只能向后逐页查询，不支持随机翻页\n  - 场景：没有随机翻页需求的搜索，例如手机向下滚动翻页\n\n- `scroll`：\n  - 优点：没有查询上限（单次查询的 size 不超过 10000）\n  - 缺点：会有额外内存消耗，并且搜索结果是非实时的\n  - 场景：海量数据的获取和迁移。从 ES 7.1开始不推荐，建议用 after search 方案。\n\n### 高亮\n\n高亮显示的实现分为两步：\n\n- 给文档中的所有关键字都添加一个标签，例如 `<em>` 标签\n- 页面给 `<em>` 标签编写 CSS 样式\n\n高亮的语法：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"FIELD\": \"TEXT\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"FIELD\": {\n        \"pre_tags\": \"<em>\",\n        \"post_tags\": \"</em>\"\n      }\n    }\n  }\n}\n```\n\n**注意：**\n\n- 高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。\n- 默认情况下，高亮的字段，必须与搜索指定的字段一致，否则无法高亮\n- 如果要对非搜索字段高亮，则需要添加一个属性： `\"require_field_match\": \"false\"`\n\n示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"name\": {\n        \"require_field_match\": \"false\"\n      }\n    }\n  }\n}\n```\n\n### 搜索结果处理小结\n\n查询的 DSL 是一个大的 JSON 对象，包含下列属性：\n\n- query：查询条件\n- from 和 size：分页条件\n- sort：排序条件\n- highlight：高亮条件\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"如家\"\n    }\n  },\n  \"from\": 0, // 分页开始的位置\n  \"size\": 20, // 期望获取的文档总数\n  \"sort\": [ \n    {  \"price\": \"asc\" }, // 普通排序\n    {\n      \"_geo_distance\" : { // 距离排序\n          \"location\" : \"31.040699,121.618075\", \n          \"order\" : \"asc\",\n          \"unit\" : \"km\"\n      }\n    }\n  ],\n  \"highlight\": {\n    \"fields\": { // 高亮字段\n      \"name\": {\n        \"pre_tags\": \"<em>\",  // 用来标记高亮字段的前置标签\n        \"post_tags\": \"</em>\" // 用来标记高亮字段的后置标签\n      }\n    }\n  }\n}\n```\n\n## Rest Client 查询文档\n\n文档的查询同样适用 RestHighLevelClient 对象，基本步骤包括：\n\n- 准备 Request 对象\n- 准备请求参数\n- 发起请求\n- 解析响应\n\n### 快速入门\n\n我们以 match_all 查询为例\n\n#### 发起查询请求\n\n```java\n@Test\nvoid testMatchAll() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.组织DSL参数\n    request.source().query(QueryBuilders.matchAllQuery());\n    // 3.发送请求，得到响应结果\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // ...解析响应结果\n}\n```\n\n代码解读：\n\n- 第一步，创建 `SearchRequest` 对象，指定索引库名\n\n- 第二步，利用 `request.source()` 构建 DSL，DSL 中可以包含查询、分页、排序、高亮等\n  - `query()`：代表查询条件，利用 `QueryBuilders.matchAllQuery()` 构建一个 match_all 查询的 DSL\n- 第三步，利用 `client.search()` 发送请求，得到响应\n\n这里关键的 API 有两个：\n\n+ 一个是 `request.source()`，其中包含了查询、排序、分页、高亮等所有功能。\n+ 另一个是 `QueryBuilders`，其中包含 match、term、function_score、bool 等各种查询：\n\n#### 解析响应\n\nElasticSearch 返回的结果是一个 JSON 字符串，结构包含：\n\n```json\n{\n   \"took\" : 0,\n   \"timed_out\" : false,\n   \"hits\" : {\n    \"total\" : {\n      \"value\" : 2,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"heima\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"1\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"info\" : \"Java讲师\", 	\"name\" : \"赵云\",\n       }\n      },\n      // ...\n    ]\n  }\n}\n```\n\n- `hits`：命中的结果\n  - `total`：总条数，其中的 value 是具体的总条数值\n  - `max_score`：所有结果中得分最高的文档的相关性算分\n  - `hits`：搜索结果的文档数组，其中的每个文档都是一个 JSON 对象\n    - `_source`：文档中的原始数据，也是 JSON 对象\n\n因此，我们解析响应结果，就是逐层解析 JSON 字符串，流程如下：\n\n```java\n@Test\nvoid testMatchAll() throws IOException {\n    // ... 略\n    // 4.解析结果\n    SearchHits searchHits = response.getHits();\n    // 4.1.查询的总条数\n    long total = searchHits.getTotalHits().value;\n    // 4.2.查询的结果数组\n    SearchHit[] hits = searchHits.getHits();\n    for (SearchHit hit : hits) {\n        // 4.3.得到source\n        String json = hit.getSourceAsString();\n        // 4.4.打印\n        System.out.println(json);\n    }\n}\n```\n\n- `SearchHits`：通过 `response.getHits()` 获取，就是 JSON 中的最外层的hits，代表命中的结果\n  - `SearchHits#getTotalHits().value`：获取总条数信息\n  - `SearchHits#getHits()`：获取 SearchHit 数组，也就是文档数组\n    - `SearchHit#getSourceAsString()`：获取文档结果中的_source，也就是原始的 JSON 文档数据\n\n#### 完整代码\n\n```java\n    @Test\n    void testMatchAll() throws IOException {\n        // 1.准备 Request\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.组织 DSL 参数\n        request.source().query(QueryBuilders.matchAllQuery());\n        // 3.发送请求，得到响应结果\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.解析结果\n        SearchHits searchHits = response.getHits();\n        // 4.1.查询的总条数\n        long total = searchHits.getTotalHits().value;\n        System.err.println(\"total = \" + total);\n        // 4.2.查询的结果数组\n        SearchHit[] hits = searchHits.getHits();\n        for (SearchHit hit : hits) {\n            // 4.3.得到source\n            String json = hit.getSourceAsString();\n            // 反序列化\n            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n            // 4.4.打印\n            System.out.println(hotelDoc);\n        }\n    }\n```\n\n#### 快速入门小结\n\n查询的基本步骤是：\n\n1. 创建 SearchRequest 对象\n2. 准备 `Request.source()`，也就是 DSL。\n   + QueryBuilders 来构建查询条件\n   + 传入 `Request.source()` 的 `query()` 方法\n3. 发送请求，得到结果\n4. 解析结果（参考 JSON 结果，从外到内，逐层解析）\n\n### match 查询\n\n全文检索的 match 和 multi_match 查询与 match_all 的 API 基本一致。差别是查询条件，也就是 query 的部分。\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家\"\n    }\n  }\n}\n\nGET /hotel/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"如家\",\n      \"fields\": [\"brand\", \"name\"]\n    }\n  }\n}\n```\n\n因此，Java 代码上的差异主要是 `request.source().query()` 中的参数了。同样是利用 QueryBuilders 提供的方法：\n\n```java\n// 单字段查询\nQueryBuilders.matchQuery(\"all\", \"如家\");\n// 多字段查询\nQueryBuilders.multiMatchQuery(\"如家\", \"name\", \"business\");\n```\n\n而结果解析代码则完全一致，可以抽取并共享。\n\n完整代码如下：\n\n```java\n@Test\nvoid testMatch() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    request.source().query(QueryBuilders.matchQuery(\"all\", \"如家\"));\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n> IDEA 代码抽取 Ctrl + Alt + M\n\n### 精确查询\n\n精确查询主要是两者：\n\n- term：词条精确匹配\n- range：范围查询\n\n与之前的查询相比，差异同样在查询条件，其它都一样。\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"city\": \"杭州\"\n    }\n  }\n}\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": { \"gte\": 100, \"lte\": 150 }\n    }\n  }\n}\n```\n\n查询条件构造的 API 如下：\n\n```java\n// 词条查询\nQueryBuilders.termQuery(\"city\", \"杭州\"); \n// 范围查询\nQueryBuilders.rangeQuery(\"price\").gte(100).lte(150);\n```\n\n### 布尔查询\n\n布尔查询是用 must、must_not、filter 等方式组合其它查询，代码示例如下：\n\n```java\n// 创建布尔查询\nBoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n// 添加must条件\nboolQuery.must(QueryBuilders.termQuery(\"city\", \"杭州\")); \n// 添加filter条件\nboolQuery.filter(QueryBuilders.rangeQuery(\"price\").lte(250));\n```\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": { \"city\": \"杭州\" }\n        }\n      ],\n      \"filter\": [\n        {\n          \"range\": {\n            \"price\": { \"lte\": 250 }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n可以看到，API 与其它查询的差别同样是在查询条件的构建，QueryBuilders，结果解析等其他代码完全不变。\n\n示例代码：\n\n```java\n@Test\nvoid testBool() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    \n    // 2.准备DSL\n    // 2.1.准备BooleanQuery\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    // 2.2.添加term\n    boolQuery.must(QueryBuilders.termQuery(\"city\", \"上海\"));\n    // 2.3.添加range\n    boolQuery.filter(QueryBuilders.rangeQuery(\"price\").lte(250));\n    \n    request.source().query(boolQuery);\n    \n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    \n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n\n\n## Rest Client 搜索结果处理\n\n### 排序与分页\n\n搜索结果的排序和分页是与 query 同级的参数，因此同样是使用 `request.source()` 来设置。\n\n对应的 API 如下：\n\n```java\n// 查询 \nrequest.source().query(QueryBuilders.matchAllQuery());\n// 排序\nrequest.source().sort(\"price\", SortOrder.ASC);\n// 分页\nrequest.source().from(0).size(5);\n```\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"from\": 0,\n  \"size\": 5, \n  \"sort\": [\n    {\n      \"FIELD\": \"desc\"  \n    },\n  ]\n}\n```\n\n代码示例：\n\n```java\n@Test\nvoid testPageAndSort() throws IOException {\n    // 页码，每页大小\n    int page = 1, size = 5;\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    // 2.1.query\n    request.source().query(QueryBuilders.matchAllQuery());\n    // 2.2.排序 sort\n    request.source().sort(\"price\", SortOrder.ASC);\n    // 2.3.分页 from、size\n    request.source().from((page - 1) * size).size(size);\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n### 高亮\n\n高亮的代码与之前代码差异较大，有两点：\n\n- 查询的 DSL：其中除了查询条件，还需要添加高亮条件，同样是与 query 同级。\n- 结果解析：结果除了要解析 _source 文档数据，还要解析高亮结果\n\n#### 高亮请求构建\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"name\": {\n        \"require_field_match\": \"false\"\n      }\n    }\n  }\n}\n```\n\n高亮请求的构建 API 如下：\n\n```java\nrequest.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false));\n```\n\n上述代码省略了查询条件部分，但是大家不要忘了：高亮查询必须使用全文检索查询，并且要有搜索关键字，将来才可以对关键字高亮。\n\n示例代码如下：\n\n```java\n@Test\nvoid testHighlight() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    // 2.1.query\n    request.source().query(QueryBuilders.matchQuery(\"all\", \"如家\"));\n    // 2.2.高亮\n    request.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false));\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n#### 高亮结果解析\n\n高亮的结果与查询的文档结果默认是分离的，并不在一起。\n\n```json\n{\n  \"_index\" : \"hotel\",\n  \"_type\" : \"_doc\",\n  \"_id\" : \"339952837\",\n  \"_score\" : 2.8947515,\n  \"_source\" : {\n    \"id\" : 339952837,\n    \"name\" : \"如家酒店(北京良乡西路店)\",\n    \"price\" : 159,\n    \"score\" : 46,\n    \"brand\" : \"如家\",\n    \"city\" : \"北京\",\n    \"location\" : \"39.73167, 116.132482\",\n    \"pic\" : \"t0.jpg\"\n  },\n  \"highlight\" : {\n    \"name\" : [\n      \"<em>如家</em>酒店(北京良乡西路店)\",\n    ]\n  }\n}\n```\n\n因此解析高亮的代码需要额外处理：\n\n```java\n// 获取source\nHotelDoc hotelDoc = JSON.parseObject(hit.getSourceAsString(), HotelDoc.class);\n// 处理高亮\nMap<String, HighlightField> highlightFields = hit.getHighlightFields();\nif (!CollectionUtils.isEmpty(highlightFields)) {\n    // 获取高亮字段结果\n    HighlightField highlightField = highlightFields.get(\"name\");\n    if (highlightField != null) {\n        // 取出高亮结果数组中的第一个，就是酒店名称\n        String name = highlightField.getFragments()[0].string();\n        hotelDoc.setName(name);\n    }\n}\n```\n\n代码解读：\n\n- 第一步：从结果中获取 source。`hit.getSourceAsString()`，这部分是非高亮结果，JSON 字符串。还需要反序列为 HotelDoc 对象\n- 第二步：获取高亮结果。`hit.getHighlightFields()`，返回值是一个 Map，key 是高亮字段名称，值是 HighlightField 对象，代表高亮值\n- 第三步：从 Map 中根据高亮字段名称，获取高亮字段值对象HighlightField\n- 第四步：从HighlightField 中获取 Fragments，并且转为字符串。这部分就是真正的高亮字符串了\n- 第五步：用高亮的结果替换 HotelDoc 中的非高亮结果\n\n## 酒店搜索案例\n\n下面，我们通过酒店搜索案例来实战演练下之前学习的知识。\n\n我们实现四部分功能：\n\n- 酒店搜索和分页\n- 酒店结果过滤\n- 我周边的酒店\n- 酒店竞价排名\n\n启动 hotel-demo 项目，其默认端口是 8089，访问 http://localhost:8090，就能看到项目页面了。\n\n### 酒店搜索和分页\n\n案例需求：实现黑马旅游的酒店搜索功能，完成关键字搜索和分页\n\n#### 需求分析\n\n- 请求方式：POST\n- 请求路径：/hotel/list\n- 请求参数：JSON 对象，包含4个字段：\n  - key：搜索关键字\n  - page：页码\n  - size：每页大小\n  - sortBy：排序，目前暂不实现\n- 返回值：分页查询，需要返回分页结果 PageResult，包含两个属性：\n  - `total`：总条数\n  - `List<HotelDoc>`：当前页的数据\n\n因此，我们实现业务的流程如下：\n\n- 步骤一：定义实体类，接收请求参数的 JSON 对象\n- 步骤二：编写 controller，接收页面的请求\n- 步骤三：编写业务实现，利用 RestHighLevelClient 实现搜索、分页\n\n#### 定义实体类\n\n实体类有两个，一个是前端的请求参数实体，一个是服务端应该返回的响应结果实体。\n\n① 请求参数，前端请求的 JSON 结构如下：\n\n```json\n{\n    \"key\": \"搜索关键字\",\n    \"page\": 1,\n    \"size\": 3,\n    \"sortBy\": \"default\"\n}\n```\n\n因此，我们在 `cn.itcast.hotel.pojo` 包下定义一个实体类：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\n\n@Data\npublic class RequestParams {\n    private String key;\n    private Integer page;\n    private Integer size;\n    private String sortBy;\n}\n```\n\n② 返回值，分页查询，需要返回分页结果 PageResult，包含两个属性：\n\n- `total` ：总条数\n- `List<HotelDoc>` ：当前页的数据\n\n因此，我们在 `cn.itcast.hotel.pojo` 中定义返回结果：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\n\nimport java.util.List;\n\n@Data\npublic class PageResult {\n    private Long total;\n    private List<HotelDoc> hotels;\n\n    public PageResult() {\n    }\n\n    public PageResult(Long total, List<HotelDoc> hotels) {\n        this.total = total;\n        this.hotels = hotels;\n    }\n}\n```\n\n#### 定义 controller\n\n定义一个 HotelController，声明查询接口，满足下列要求：\n\n- 请求方式：Post\n- 请求路径：/hotel/list\n- 请求参数：对象，类型为 RequestParam\n- 返回值：PageResult，包含两个属性\n  - `Long total`：总条数\n  - `List<HotelDoc> hotels`：酒店数据\n\n因此，我们在 `cn.itcast.hotel.web` 中定义 HotelController：\n\n```java\n@RestController\n@RequestMapping(\"/hotel\")\npublic class HotelController {\n\n    @Autowired\n    private IHotelService hotelService;\n	// 搜索酒店数据\n    @PostMapping(\"/list\")\n    public PageResult search(@RequestBody RequestParams params){\n        return hotelService.search(params);\n    }\n}\n```\n\n#### 实现搜索业务\n\n我们在 controller 调用了 IHotelService，并没有实现该方法，因此下面我们就在 IHotelService 中定义方法，并且去实现业务逻辑。\n\n① 在 `cn.itcast.hotel.service` 中的 `IHotelService` 接口中定义一个方法：\n\n```java\n/**\n * 根据关键字搜索酒店信息\n * @param params 请求参数对象，包含用户输入的关键字 \n * @return 酒店文档列表\n */\nPageResult search(RequestParams params);\n```\n\n② 实现搜索业务，肯定离不开 RestHighLevelClient，我们需要把它注册到 Spring 中作为一个 Bean。在 `cn.itcast.hotel` 中的 `HotelDemoApplication` 中声明这个 Bean：\n\n```java\n@Bean\npublic RestHighLevelClient client() {\n    return new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n}\n```\n\n③ 在 `cn.itcast.hotel.service.impl` 中的 `HotelService` 中实现 search 方法：\n\n```java\n@Autowired\nprivate RestHighLevelClient client;\n\n@Override\npublic PageResult search(RequestParams params) {\n    try {\n        // 1.准备Request\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.准备DSL\n        // 2.1.query\n        String key = params.getKey();\n        if (key == null || \"\".equals(key)) {\n            request.source().query(QueryBuilders.matchAllQuery());\n        } else {\n            request.source().query(QueryBuilders.matchQuery(\"all\", key));\n        }\n\n        // 2.2.分页\n        int page = params.getPage();\n        int size = params.getSize();\n        request.source().from((page - 1) * size).size(size);\n\n        // 3.发送请求\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.解析响应\n        return handleResponse(response);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\n// 结果解析\nprivate PageResult handleResponse(SearchResponse response) {\n    // 4.解析响应\n    SearchHits searchHits = response.getHits();\n    // 4.1.获取总条数\n    long total = searchHits.getTotalHits().value;\n    // 4.2.文档数组\n    SearchHit[] hits = searchHits.getHits();\n    // 4.3.遍历\n    List<HotelDoc> hotels = new ArrayList<>();\n    for (SearchHit hit : hits) {\n        // 获取文档source\n        String json = hit.getSourceAsString();\n        // 反序列化\n        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n        // 放入集合\n        hotels.add(hotelDoc);\n    }\n    // 4.4.封装返回\n    return new PageResult(total, hotels);\n}\n```\n\n### 酒店结果过滤\n\n需求：添加品牌、城市、星级、价格等过滤功能\n\n#### 需求分析\n\n包含的过滤条件有：\n\n- brand：品牌值\n- city：城市\n- minPrice~maxPrice：价格范围\n- starName：星级\n\n我们需要做两件事情：\n\n- 修改请求参数的对象 RequestParams，接收上述参数\n- 修改业务逻辑，在搜索条件之外，添加一些过滤条件\n\n#### 修改实体类\n\n修改在 `cn.itcast.hotel.pojo` 包下的实体类 RequestParams：\n\n```java\n@Data\npublic class RequestParams {\n    private String key;\n    private Integer page;\n    private Integer size;\n    private String sortBy;\n    // 下面是新增的过滤条件参数\n    private String city;\n    private String brand;\n    private String starName;\n    private Integer minPrice;\n    private Integer maxPrice;\n}\n```\n\n#### 修改搜索业务\n\n在 HotelService 的 search 方法中，只有一个地方需要修改：`requet.source().query( ... )` 其中的查询条件。\n\n在之前的业务中，只有 match 查询，根据关键字搜索，现在要添加条件过滤，包括：\n\n- 品牌过滤：是 keyword 类型，用 term 查询\n- 星级过滤：是 keyword 类型，用 term 查询\n- 价格过滤：是数值类型，用 range 查询\n- 城市过滤：是 keyword 类型，用 term 查询\n\n多个查询条件组合，肯定是 boolean 查询来组合：\n\n- 关键字搜索放到 must 中，参与算分\n- 其它过滤条件放到 filter 中，不参与算分\n\n因为条件构建的逻辑比较复杂，这里封装为一个函数，getBoolQueryBuilder 的代码如下：\n\n```java\nprivate BoolQueryBuilder getBoolQueryBuilder(RequestParams params) {\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    String key = params.getKey();\n    if (key == null || \"\".equals(key)) {\n        boolQuery.must(QueryBuilders.matchAllQuery());\n    } else {\n        boolQuery.must(QueryBuilders.matchQuery(\"all\", key));\n    }\n    // 条件过滤\n    // 城市条件\n    if (params.getCity() != null && !params.getCity().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"city\", params.getCity()));\n    }\n    // 品牌条件\n    if (params.getBrand() != null && !params.getBrand().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"brand\", params.getBrand()));\n    }\n    // 星级\n    if (params.getStarName() != null && !params.getStarName().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"starName\", params.getStarName()));\n    }\n    // 价格\n    if (params.getMinPrice() != null && params.getMaxPrice() != null) {\n        boolQuery.filter(QueryBuilders.rangeQuery(\"price\")\n                         .gte(params.getMinPrice()).lte(params.getMaxPrice()));\n    }\n    return boolQuery;\n}\n```\n\n### 我周边的酒店\n\n需求：我附近的酒店\n\n#### 需求分析\n\n在酒店列表页的右侧，有一个小地图，点击地图的定位按钮，地图会找到你所在的位置，并且，在前端会发起查询请求，将你的坐标发送到服务端。\n\n我们要做的事情就是基于这个 location 坐标，然后按照距离对周围酒店排序。实现思路如下：\n\n- 修改 RequestParams 参数，接收 location 字段\n- 修改 search 方法业务逻辑，如果 location 有值，添加根据 geo_distance 排序的功能\n\n#### 修改实体类\n\n修改在 `cn.itcast.hotel.pojo` 包下的实体类 RequestParams：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\n\n@Data\npublic class RequestParams {\n    private String key;\n    private Integer page;\n    private Integer size;\n    private String sortBy;\n    private String city;\n    private String brand;\n    private String starName;\n    private Integer minPrice;\n    private Integer maxPrice;\n    // 我当前的地理坐标\n    private String location;\n}\n```\n\n#### 距离排序 API\n\n我们以前学习过排序功能，包括两种：\n\n- 普通字段排序\n- 地理坐标排序\n\n我们只讲了普通字段排序对应的 Java 写法。地理坐标排序只学过 DSL 语法，如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"price\": \"asc\"  \n    },\n    {\n      \"_geo_distance\" : {\n          \"FIELD\" : \"纬度，经度\",\n          \"order\" : \"asc\",\n          \"unit\" : \"km\"\n      }\n    }\n  ]\n}\n```\n\n对应 Java 代码\n\n```java\n// 价格排序\nrequest.source().sort(\"price\", SortOrder.ASC);\n// 距离排序\nrequest.source().sort(SortBuilders.geoDistanceSort(\"location\", new GeoPoint(\"31.21, 121.5\"))\n                      .order(SortOrder.ASC).unit(DistanceUnit.KILOMETERS));\n```\n\n#### 添加距离排序\n\n在 `cn.itcast.hotel.service.impl` 的 `HotelService` 的 `search` 方法中，添加一个排序功能：\n\n```java\n@Override\npublic PageResult search(RequestParams params) {\n    try {\n        // 1.准备Request\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.准备DSL\n        // 2.1.query\n        // 构建 boolQuery\n        BoolQueryBuilder boolQuery = getBoolQueryBuilder(params);\n        request.source().query(boolQuery);\n\n        // 2.2.分页\n        int page = params.getPage();\n        int size = params.getSize();\n        request.source().from((page - 1) * size).size(size);\n\n        // 排序\n        String location = params.getLocation();\n        if (location != null && !location.equals(\"\")) {\n            request.source().sort(SortBuilders\n                                  .geoDistanceSort(\"location\", new GeoPoint(location))\n                                  .order(SortOrder.ASC)\n                                  .unit(DistanceUnit.KILOMETERS));\n        }\n\n        // 3.发送请求\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.解析响应\n        return handleResponse(response);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n#### 排序距离显示\n\n排序完成后，页面还要获取我附近每个酒店的具体**距离**值，这个值在响应结果中是独立的：\n\n因此，我们在结果解析阶段，除了解析 source 部分以外，还要得到 sort 部分，也就是排序的距离，然后放到响应结果中。\n\n我们要做两件事：\n\n- 修改 HotelDoc，添加排序距离字段，用于页面显示\n- 修改 HotelService 类中的 handleResponse 方法，添加对 sort 值的获取\n\n① 修改HotelDoc类，添加距离字段\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n    // 排序时的 距离值\n    private Object distance;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n\n② 修改 HotelService 中的 handleResponse 方法\n\n```java\n// 结果解析\nprivate PageResult handleResponse(SearchResponse response) {\n    // 4.解析响应\n    SearchHits searchHits = response.getHits();\n    // 4.1.获取总条数\n    long total = searchHits.getTotalHits().value;\n    // 4.2.文档数组\n    SearchHit[] hits = searchHits.getHits();\n    // 4.3.遍历\n    List<HotelDoc> hotels = new ArrayList<>();\n    for (SearchHit hit : hits) {\n        // 获取文档source\n        String json = hit.getSourceAsString();\n        // 反序列化\n        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n        // 获取排序值 - location\n        Object[] sortValues = hit.getSortValues();\n        if (sortValues.length > 0) {\n            Object sortValue = sortValues[0];\n            hotelDoc.setDistance(sortValue);\n        }\n\n        // 放入集合\n        hotels.add(hotelDoc);\n    }\n    // 4.4.封装返回\n    return new PageResult(total, hotels);\n}\n```\n\n### 酒店竞价排名\n\n需求：让指定的酒店在搜索结果中排名置顶\n\n#### 需求分析\n\n要让指定酒店在搜索结果中排名置顶，页面会给指定的酒店添加**广告**标记。\n\n我们之前学习过的 function_score 查询可以影响算分，算分高了，自然排名也就高了。而 function_score 包含 3 个要素：\n\n- 过滤条件：哪些文档要加分\n- 算分函数：如何计算 function score\n- 加权方式：function score 与 query score 如何运算\n\n这里的需求是：让**指定酒店**排名靠前。因此我们需要给这些酒店添加一个标记，这样在过滤条件中就可以根据这个标记来判断，是否要提高算分。\n\n比如，我们给酒店添加一个字段：isAD，Boolean 类型：\n\n- true：是广告\n- false：不是广告\n\n这样 function_score 包含 3 个要素就很好确定了：\n\n- 过滤条件：判断 isAD 是否为 true\n- 算分函数：我们可以用最简单暴力的 weight，固定加权值\n- 加权方式：可以用默认的相乘，大大提高算分\n\n因此，业务的实现步骤包括：\n\n1. 给 HotelDoc 类添加 isAD 字段，Boolean 类型\n\n2. 挑选几个你喜欢的酒店，给它的文档数据添加 isAD 字段，值为 true\n\n3. 修改 search方法，添加 function score 功能，给 isAD 值为 true 的酒店增加权重\n\n#### 修改 HotelDoc 实体\n\n给 `cn.itcast.hotel.pojo` 包下的 HotelDoc 类添加 isAD 字段：\n\n```java\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n    // 排序时的距离值\n    private Object distance;\n    private Boolean isAD;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n\n#### 添加广告标记\n\n用 DSL 添加酒店广告标记\n\n```java\nPOST /hotel/_update/36934\n{\n  \"doc\": {\n    \"isAD\": true\n  }\n}\n```\n\n#### 添加算分函数查询\n\n接下来我们就要修改查询条件了。之前是用的 boolean 查询，现在要改成 function_socre 查询。\n\nfunction_score 查询结构如下：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": {\n          \"name\": \"外滩\"\n        }\n      },\n      \"functions\": [ \n        {\n          \"filter\": {\n            \"term\": {\n              \"brand\": \"如家\"\n            }\n          },\n          \"weight\": 5\n        }\n      ]\n    }\n  }\n}\n```\n\n对应的 JavaAPI 如下\n\n```java\nFunctionScoreQueryBuilder functionScoreQueryBuilder = \n    QueryBuilders.functionScoreQuery(\n        QueryBuilders.matchQuery(\"name\", \"外滩\"),\n        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{\n            new FunctionScoreQueryBuilder.FilterFunctionBuilder(\n                QueryBuilders.termQuery(\"brand\", \"如家\"), \n                ScoreFunctionBuilders.weightFactorFunction(5)\n            )\n        }\n	);\nsourceBuilder.query(functionScoreQueryBuilder);\n```\n\n我们可以将之前写的 boolean 查询作为**原始查询**条件放到 query 中，接下来就是添加过滤条件、算分函数、加权模式了。所以原来的代码依然可以沿用。\n\n修改 `cn.itcast.hotel.service.impl` 包下的 `HotelService` 类中的 `getQueryBuilder` 方法，添加算分函数查询：\n\n```java\nprivate FunctionScoreQueryBuilder getQueryBuilder(RequestParams params) {\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    String key = params.getKey();\n    if (key == null || \"\".equals(key)) {\n        boolQuery.must(QueryBuilders.matchAllQuery());\n    } else {\n        boolQuery.must(QueryBuilders.matchQuery(\"all\", key));\n    }\n    // 条件过滤\n    // 城市条件\n    if (params.getCity() != null && !params.getCity().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"city\", params.getCity()));\n    }\n    // 品牌条件\n    if (params.getBrand() != null && !params.getBrand().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"brand\", params.getBrand()));\n    }\n    // 星级\n    if (params.getStarName() != null && !params.getStarName().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"starName\", params.getStarName()));\n    }\n    // 价格\n    if (params.getMinPrice() != null && params.getMaxPrice() != null) {\n        boolQuery.filter(QueryBuilders.rangeQuery(\"price\")\n                         .gte(params.getMinPrice()).lte(params.getMaxPrice()));\n    }\n\n    // 算分控制\n    FunctionScoreQueryBuilder functionScoreQueryBuilder =\n        QueryBuilders.functionScoreQuery(\n        // 原始查询，相关性算分\n        boolQuery,\n        // function score\n        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{\n            // 一个 function score 元素\n            new FunctionScoreQueryBuilder.FilterFunctionBuilder(\n                // 过滤条件\n                QueryBuilders.termQuery(\"isAD\", true),\n                // 算分函数\n                ScoreFunctionBuilders.weightFactorFunction(10)\n            )\n        });\n\n    return functionScoreQueryBuilder;\n}\n```\n\n## 数据聚合\n\n[聚合](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html)（aggregation） 可以让我们极其方便的实现对数据的统计、分析、运算。例如：\n\n- 什么品牌的手机最受欢迎？\n- 这些手机的平均价格、最高价格、最低价格？\n- 这些手机每月的销售情况如何？\n\n实现这些统计功能的比数据库的 SQL 要方便的多，而且查询速度非常快，可以实现近实时搜索效果。\n\n### 聚合的种类\n\n聚合常见的有三类：\n\n- 桶（Bucket）聚合：用来对文档做分组\n  - TermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组\n  - Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组\n\n- 度量（Metric）聚合：用以计算一些值，比如：最大值、最小值、平均值等\n  - Avg：求平均值\n  - Max：求最大值\n  - Min：求最小值\n  - Stats：同时求 max、min、avg、sum 等\n- 管道（pipeline）聚合：其它聚合的结果为基础做聚合\n\n> **注意：**参加聚合的字段必须是 keyword、日期、数值、布尔类型\n\n### DSL 实现聚合\n\n现在，我们要统计所有数据中的酒店品牌有几种，其实就是按照品牌对数据分组。\n\n此时可以根据酒店品牌的名称做聚合，也就是 Bucket 聚合。\n\n#### Bucket 聚合语法\n\n语法如下：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0,  // 设置 size 为 0，结果中不包含文档，只包含聚合结果\n  \"aggs\": { // 定义聚合\n    \"brandAgg\": { //给聚合起个名字\n      \"terms\": { // 聚合的类型，按照品牌值聚合，所以选择term\n        \"field\": \"brand\", // 参与聚合的字段\n        \"size\": 5 // 希望获取的聚合结果数量\n      }\n    }\n  }\n}\n```\n\n结果如下：\n\n```json\n{\n  \"took\" : 36,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 201,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : null,\n    \"hits\" : [ ]\n  },\n  \"aggregations\" : {\n    \"brandAgg\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 96,\n      \"buckets\" : [\n        {\n          \"key\" : \"7天酒店\",\n          \"doc_count\" : 30\n        },\n        {\n          \"key\" : \"如家\",\n          \"doc_count\" : 30\n        },\n        {\n          \"key\" : \"皇冠假日\",\n          \"doc_count\" : 17\n        },\n        {\n          \"key\" : \"速8\",\n          \"doc_count\" : 15\n        },\n        {\n          \"key\" : \"万怡\",\n          \"doc_count\" : 13\n        }\n      ]\n    }\n  }\n}\n```\n\n#### 聚合结果排序\n\n默认情况下，Bucket 聚合会统计 Bucket 内的文档数量，记为 `_count`，并且按照 `_count` 降序排序。\n\n我们可以指定 order 属性，自定义聚合的排序方式：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"order\": {\n          \"_count\": \"asc\" // 按照 _count 升序排列\n        }, \n        \"size\": 5\n      }\n    }\n  }\n}\n```\n\n#### 限定聚合范围\n\n默认情况下，Bucket 聚合是对索引库的所有文档做聚合，但真实场景下，用户会输入搜索条件，因此聚合必须是对搜索结果聚合。那么聚合必须添加限定条件。\n\n我们可以限定要聚合的文档范围，只要添加 query 条件即可：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"lte\": 200 // 只对200元以下的文档聚合\n      }\n    }\n  }, \n  \"size\": 0,\n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"size\": 5\n      }\n    }\n  }\n}\n```\n\n#### Metric 聚合语法\n\n现在我们需要对桶内的酒店做运算，获取每个品牌的用户评分的 min、max、avg 等值。\n\n这就要用到 Metric 聚合了，例如 stats 聚合：就可以获取 min、max、avg 等结果。\n\n语法如下：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0, \n  \"aggs\": {\n    \"brandAgg\": { \n      \"terms\": { \n        \"field\": \"brand\", \n        \"size\": 5\n      },\n      \"aggs\": { // 是brands聚合的子聚合，也就是分组后对每组分别计算\n        \"score_stats\": { // 聚合名称\n          \"stats\": { // 聚合类型，这里stats可以计算min、max、avg等\n            \"field\": \"score\" // 聚合字段，这里是score\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n这次的 score_stats 聚合是在 brandAgg 的聚合内部嵌套的子聚合。因为我们需要在每个桶分别计算。\n\n另外，我们还可以给聚合结果做个排序：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"size\": 5,\n        \"order\": {\n          \"scoreAgg.avg\": \"desc\"\n        }\n      },\n      \"aggs\": {\n        \"scoreAgg\": {\n          \"stats\": {\n            \"field\": \"score\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n#### DSL 实现聚合小结\n\naggs 代表聚合，与 query 同级，此时 query 的作用是？\n\n- 限定聚合的的文档范围\n\n聚合必须的三要素：\n\n- 聚合名称\n- 聚合类型\n- 聚合字段\n\n聚合可配置属性有：\n\n- size：指定聚合结果数量\n- order：指定聚合结果排序方式\n- field：指定聚合字段\n\n### Rest Client 实现聚合\n\n#### API 语法\n\n聚合条件与 query 条件同级别，因此需要使用 `request.source()` 来指定聚合条件。\n\n聚合条件的语法：\n\n```java\nrequest.source().size(0);\nrequest.source().aggregation(\n    AggregationBuilders\n    .terms(\"brand_agg\")\n    .field(\"brand\")\n    .size(20)\n);\n```\n\n聚合的结果也与查询结果不同，API 也比较特殊。不过同样是 JSON 逐层解析：\n\n```java\n// 4. 解析结果\n// 4.1 获取 aggregations\nAggregations aggregations = response.getAggregations();\n// 4.2 根据名称获取聚合结果\nTerms brandTerms = aggregations.get(\"brandAgg\");\n// 4.3 获取 buckets 并遍历\nfor (Terms.Bucket bucket : brandTerms.getBuckets()) {\n    // 获取 key\n    String key = bucket.getKeyAsString();\n    System.out.println(key);\n}\n```\n\n#### 业务需求\n\n需求：搜索页面的品牌、城市等信息不应该是在页面写死，而是通过聚合索引库中的酒店数据得来的\n\n分析：目前，页面的城市列表、星级列表、品牌列表都是写死的，并不会随着搜索结果的变化而变化。但是用户搜索条件改变时，搜索结果会跟着变化。\n\n例如：用户搜索“东方明珠”，那搜索的酒店肯定是在上海东方明珠附近，因此，城市只能是上海，此时城市列表中就不应该显示北京、深圳、杭州这些信息了。也就是说，搜索结果中包含哪些城市，页面就应该列出哪些城市；搜索结果中包含哪些品牌，页面就应该列出哪些品牌。\n\n如何得知搜索结果中包含哪些品牌？如何得知搜索结果中包含哪些城市？\n\n使用聚合功能，利用 Bucket 聚合，对搜索结果中的文档基于品牌分组、基于城市分组，就能得知包含哪些品牌、哪些城市了。\n\n因为是对搜索结果聚合，因此聚合是限定范围的聚合，也就是说聚合的限定条件跟搜索文档的条件一致。\n\n返回结果是一个 Map 结构：\n\n- key 是字符串，城市、星级、品牌、价格\n- value 是集合，例如多个城市的名称\n\n#### 业务实现\n\n在 `cn.itcast.hotel.web` 包的 `HotelController` 中添加一个方法，遵循下面的要求：\n\n- 请求方式：`POST`\n- 请求路径：`/hotel/filters`\n- 请求参数：`RequestParams`，与搜索文档的参数一致\n- 返回值类型：`Map<String, List<String>>`\n\n代码：\n\n```java\n@PostMapping(\"filters\")\npublic Map<String, List<String>> getFilters(@RequestBody RequestParams params){\n    return hotelService.getFilters(params);\n}\n```\n\n这里调用了 IHotelService 中的 getFilters 方法，尚未实现。\n\n在 `cn.itcast.hotel.service.IHotelService` 中定义新方法：\n\n```java\nMap<String, List<String>> filters(RequestParams params);\n```\n\n在 `cn.itcast.hotel.service.impl.HotelService` 中实现该方法：\n\n```java\n@Override\npublic Map<String, List<String>> getFilters(RequestParams params) {\n    try {\n        // 1. 准备 request\n        SearchRequest request = new SearchRequest(\"hotel\");\n\n        // 2. 准备 DSL\n        // query\n        FunctionScoreQueryBuilder query = getQueryBuilder(params);\n        request.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false));\n        request.source().query(query);\n        // 2.1 设置 size = 0\n        request.source().size(0);\n        // 2.2 聚合\n        HashMap<String, String> items = new HashMap<>();\n        items.put(\"brand\", \"品牌\");\n        items.put(\"city\", \"城市\");\n        items.put(\"starName\", \"星级\");\n        for (String item : items.keySet()) {\n            request.source().aggregation(AggregationBuilders\n                                         .terms(item + \"Agg\")\n                                         .field(item)\n                                         .size(100));\n        }\n        // 3. 发出请求\n        SearchResponse response = null;\n\n        response = client.search(request, RequestOptions.DEFAULT);\n\n\n        // 4. 解析结果\n        // 4.1 获取 aggregations\n        Aggregations aggregations = response.getAggregations();\n\n        HashMap<String, List<String>> itemListHashMap = new HashMap<>();\n\n        for (String item : items.keySet()) {\n            // 4.2 根据名称获取聚合结果\n            Terms brandTerms = aggregations.get(item + \"Agg\");\n            // 4.3 获取 buckets 并遍历\n            ArrayList<String> itemList = new ArrayList<>();\n            for (Terms.Bucket bucket : brandTerms.getBuckets()) {\n                // 获取 key\n                itemList.add(bucket.getKeyAsString());\n            }\n            itemListHashMap.put(item, itemList);\n        }\n        return itemListHashMap;\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n## 自动补全\n\n当用户在搜索框输入字符时，我们应该提示出与该字符有关的搜索项，这种根据用户输入的字母，提示完整词条的功能，就是自动补全了。\n\n因为需要根据拼音字母来推断，因此要用到拼音分词功能。\n\n### 拼音分词器\n\n要实现根据字母做补全，就必须对文档按照拼音分词。在 GitHub 上有 ElasticSearch的拼音分词插件。地址：https://github.com/medcl/elasticsearch-analysis-pinyin\n\n安装方式与 IK 分词器一样，分三步：\n\n1. 解压\n2. 上传到虚拟机中，ElasticSearch 的 plugin 目录\n3. 重启 ElasticSearch\n4. 测试\n\n详细安装步骤可以参考 IK 分词器的安装过程。\n\n测试用法如下：\n\n```json\nPOST /_analyze\n{\n  \"text\": \"如家酒店还不错\",\n  \"analyzer\": \"pinyin\"\n}\n```\n\n结果如下：\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"ru\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"rjjdhbc\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"jia\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"jiu\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"dian\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"hai\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"bu\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 5\n    },\n    {\n      \"token\" : \"cuo\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 6\n    }\n  ]\n}\n```\n\n### 自定义分词器\n\n默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。\n\nElasticSearch 中分词器（analyzer）的组成包含三部分：\n\n- character filters：在 tokenizer 之前对文本进行处理。例如删除字符、替换字符\n- tokenizer：将文本按照一定的规则切割成词条（term）。例如 keyword，就是不分词；还有 ik_smart\n- tokenizer filter：将 tokenizer 输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等\n\n声明自定义分词器的语法如下：\n\n```json\nPUT /test\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"ik_max_word\",\n          \"filter\": \"py\"\n        }\n      },\n      \"filter\": {\n        \"py\": {\n          \"type\": \"pinyin\",\n          \"keep_full_pinyin\": false,\n          \"keep_joined_full_pinyin\": true,\n          \"keep_original\": true,\n          \"limit_first_letter_length\": 16,\n          \"remove_duplicated_term\": true,\n          \"none_chinese_pinyin_tokenize\": false\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\",\n        \"search_analyzer\": \"ik_smart\"\n      }\n    }\n  }\n}\n```\n\n总结：\n\n如何使用拼音分词器？\n\n- 下载 pinyin 分词器\n\n- 解压并放到 ElasticSearch 的 plugin 目录\n\n- 重启即可\n\n如何自定义分词器？\n\n- 创建索引库时，在 settings 中配置，可以包含三部分：character filter、tokenizer、filter\n\n\n拼音分词器注意事项？\n\n- 为了避免搜索到同音字，搜索时不要使用拼音分词器\n\n### 自动补全查询\n\nElasticSearch 提供了 [Completion Suggester](https://www.elastic.co/guide/en/elasticsearch/reference/7.6/search-suggesters.html) 查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：\n\n- 参与补全查询的字段必须是 completion 类型。\n\n- 字段的内容一般是用来补全的多个词条形成的数组。\n\n比如，一个这样的索引库：\n\n```json\nPUT /test2\n{\n  \"mappings\": {\n    \"properties\": {\n      \"title\":{\n        \"type\": \"completion\"\n      }\n    }\n  }\n}\n```\n\n然后插入下面的数据：\n\n```json\nPOST /test2/_doc\n{\n  \"title\": [\"Sony\", \"WH-1000XM3\"]\n}\nPOST /test2/_doc\n{\n  \"title\": [\"SK-II\", \"PITERA\"]\n}\nPOST /test2/_doc\n{\n  \"title\": [\"Nintendo\", \"switch\"]\n}\n```\n\n查询的 DSL 语句如下：\n\n```json\nPOST /test2/_search\n{\n  \"suggest\": {\n    \"title_suggest\": {\n      \"text\": \"s\", \n      \"completion\": {\n        \"field\": \"title\", \n        \"skip_duplicates\": true, \n        \"size\": 10 \n      }\n    }\n  }\n}\n```\n\n### 实现酒店搜索框自动补全\n\n现在，我们的 hotel 索引库还没有设置拼音分词器，需要修改索引库中的配置。但是我们知道索引库是无法修改的，只能删除然后重新创建。\n\n另外，我们需要添加一个字段，用来做自动补全，将 brand、suggestion、city 等都放进去，作为自动补全的提示。\n\n因此，总结一下，我们需要做的事情包括：\n\n1. 修改 hotel 索引库结构，设置自定义拼音分词器\n\n2. 修改索引库的 name、all 字段，使用自定义分词器\n\n3. 索引库添加一个新字段 suggestion，类型为 completion 类型，使用自定义的分词器\n\n4. 给 HotelDoc 类添加 suggestion 字段，内容包含 brand、business\n\n5. 重新导入数据到 hotel 库\n\n#### 修改酒店映射结构\n\n代码如下：\n\n```json\n// 酒店数据索引库\nPUT /hotel\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"text_anlyzer\": {\n          \"tokenizer\": \"ik_max_word\",\n          \"filter\": \"py\"\n        },\n        \"completion_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": \"py\"\n        }\n      },\n      \"filter\": {\n        \"py\": {\n          \"type\": \"pinyin\",\n          \"keep_full_pinyin\": false,\n          \"keep_joined_full_pinyin\": true,\n          \"keep_original\": true,\n          \"limit_first_letter_length\": 16,\n          \"remove_duplicated_term\": true,\n          \"none_chinese_pinyin_tokenize\": false\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"id\":{\n        \"type\": \"keyword\"\n      },\n      \"name\":{\n        \"type\": \"text\",\n        \"analyzer\": \"text_anlyzer\",\n        \"search_analyzer\": \"ik_smart\",\n        \"copy_to\": \"all\"\n      },\n      \"address\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"price\":{\n        \"type\": \"integer\"\n      },\n      \"score\":{\n        \"type\": \"integer\"\n      },\n      \"brand\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"city\":{\n        \"type\": \"keyword\"\n      },\n      \"starName\":{\n        \"type\": \"keyword\"\n      },\n      \"business\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"location\":{\n        \"type\": \"geo_point\"\n      },\n      \"pic\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"all\":{\n        \"type\": \"text\",\n        \"analyzer\": \"text_anlyzer\",\n        \"search_analyzer\": \"ik_smart\"\n      },\n      \"suggestion\":{\n          \"type\": \"completion\",\n          \"analyzer\": \"completion_analyzer\"\n      }\n    }\n  }\n}\n```\n\n#### 修改 HotelDoc 实体\n\nHotelDoc 中要添加一个字段，用来做自动补全，内容可以是酒店品牌、城市、商圈等信息。按照自动补全字段的要求，最好是这些字段的数组。\n\n因此我们在 HotelDoc 中添加一个 suggestion 字段，类型为 `List<String>`，然后将 brand、city、business 等信息放到里面。\n\n代码如下：\n\n```java\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n    private Object distance;\n    private Boolean isAD;\n    private List<String> suggestion;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n        // 组装suggestion\n        if (this.business.contains(\"/\")) {\n            // business有多个值，需要切割\n            String[] arr = this.business.split(\"/\");\n            // 添加元素\n            this.suggestion = new ArrayList<>();\n            this.suggestion.add(this.brand);\n            Collections.addAll(this.suggestion, arr);\n        } else {\n            this.suggestion = Arrays.asList(this.brand, this.business);\n        }\n    }\n}\n```\n\n#### 重新导入并测试\n\n重新执行之前编写的导入数据功能 `testBulkRequest()`，并搜索测试\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n可以看到新的酒店数据中包含了 suggestion，接下来测试自动补全功能\n\n```json\nGET /hotel/_search\n{\n  \"suggest\": {\n    \"suggestions\": {\n      \"text\": \"sd\",\n      \"completion\": {\n        \"field\": \"suggestion\",\n        \"skip_duplicates\": true, \n        \"size\": 10 \n      }\n    }\n  }\n}\n```\n\n#### 自动补全查询的 Java API\n\n```java\n// 1.准备请求\nSearchRequest request = new SearchRequest(\"hotel\");\n// 2.请求参数\nrequest.source().suggest(new SuggestBuilder().addSuggestion(\n    \"mySuggestion\",\n    SuggestBuilders\n    .completionSuggestion(\"title\")\n    .prefix(\"h\")\n    .skipDuplicates(true)\n    .size(10)\n));\n// 3.发送请求\nclient.search(request, RequestOptions.DEFAULT);\n```\n\n而自动补全的结果也比较特殊，解析的代码如下：\n\n```java\n// 4.处理结果\nSuggest suggest = response.getSuggest();\n// 4.1.根据名称获取补全结果\nCompletionSuggestion suggestion = suggest.getSuggestion(\"mySuggestion\");\n// 4.2.获取options并遍历\nfor (CompletionSuggestion.Entry.Option option : suggestion.getOptions()) {\n    // 4.3.获取一个option中的text，也就是补全的词条\n    String text = option.getText().string();\n    System.out.println(text);\n}\n```\n\n#### 实现搜索框自动补全\n\n在 `cn.itcast.hotel.web` 包下的 `HotelController` 中添加新接口，接收新的请求：\n\n```java\n@GetMapping(\"suggestion\")\npublic List<String> getSuggestions(@RequestParam(\"key\") String prefix) {\n    return hotelService.getSuggestions(prefix);\n}\n```\n\n在 `cn.itcast.hotel.service` 包下的 `IhotelService` 中添加方法：\n\n```java\nList<String> getSuggestions(String prefix);\n```\n\n在 `cn.itcast.hotel.service.impl.HotelService` 中实现该方法：\n\n```java\n@Override\npublic List<String> getSuggestions(String prefix) {\n    try {\n        // 1.准备请求\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.请求参数\n        request.source().suggest(new SuggestBuilder().addSuggestion(\n            \"suggestions\",\n            SuggestBuilders\n            .completionSuggestion(\"suggestion\")\n            .prefix(prefix)\n            .skipDuplicates(true)\n            .size(10)\n        ));\n        // 3.发送请求\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.处理结果\n        Suggest suggest = response.getSuggest();\n        // 4.1.根据名称获取补全结果\n        CompletionSuggestion suggestion = suggest.getSuggestion(\"suggestions\");\n        // 4.2.获取options并遍历\n        ArrayList<String> result = new ArrayList<>();\n        for (CompletionSuggestion.Entry.Option option : suggestion.getOptions()) {\n            // 4.3.获取一个option中的text，也就是补全的词条\n            String text = option.getText().string();\n            result.add(text);\n        }\n        return result;\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n## 数据同步\n\nElasticSearch 中的酒店数据来自于 MySQL 数据库，因此 MySQL 数据发生改变时，ElasticSearch 也必须跟着改变，这个就是 ElasticSearch 与 MySQL 之间的数据同步。\n\n### 思路分析\n\n常见的数据同步方案有三种：\n\n- 同步调用\n- 异步通知\n- 监听 binlog\n\n#### 同步调用\n\n![同步调用](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/同步调用.i2rj0d3cpwg.svg)\n\n基本步骤如下：\n\n- hotel-demo 对外提供接口，用来修改 ElasticSearch 中的数据\n- 酒店管理服务在完成数据库操作后，直接调用 hotel-demo 提供的接口\n\n#### 异步通知\n\n![异步通知](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/异步通知.1p2ptlc5nrs0.svg)\n\n流程如下：\n\n- hotel-admin 对 MySQL 数据库数据完成增、删、改后，发送 MQ 消息\n- hotel-demo 监听 MQ，接收到消息后完成 ElasticSearch 数据修改\n\n#### 监听 binlog\n\n![监听binlog](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/监听binlog.1n6hcbad4pb4.svg)\n\n流程如下：\n\n- 给 MySQL 开启 binlog 功能\n- MySQL 完成增、删、改操作都会记录在 binlog 中\n- hotel-demo 基于 canal 监听 binlog 变化，实时更新 ElasticSearch 中的内容\n\n#### 不同数据同步方案优缺点\n\n方式一：同步调用\n\n- 优点：实现简单，粗暴\n- 缺点：业务耦合度高\n\n方式二：异步通知\n\n- 优点：低耦合，实现难度一般\n- 缺点：依赖 MQ 的可靠性\n\n方式三：监听 binlog\n\n- 优点：完全解除服务间耦合\n- 缺点：开启 binlog 增加数据库负担、实现复杂度高\n\n### 实现数据同步\n\n#### 基于 MQ 的实现思路\n\n利用提供的 hotel-admin 项目作为酒店管理的微服务。当酒店数据发生增、删、改时，要求对 ElasticSearch 中数据也要完成相同操作。\n\n步骤：\n\n- 导入 hotel-admin 项目，启动并测试酒店数据的 CRUD\n\n- 声明 exchange、queue、RoutingKey\n\n- 在 hotel-admin 中的增、删、改业务中完成消息发送\n\n- 在 hotel-demo 中完成消息监听，并更新 ElasticSearch 中数据\n\n- 启动并测试数据同步功能\n\n### 导入 demo\n\n代码链接：[GitHub](https://github.com/Lanqilu/HaloElasticSearch/commit/b9d7c724b44d6ea8e307ac5d54778bba635bd314)\n\n运行后，访问 http://localhost:8099\n\n### 声明交换机、队列\n\nMQ 结构如图：\n\n![MQ结构](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/MQ结构.lv1ecla6gvk.svg)\n\n#### 引入依赖并修改配置文件 \n\n在 hotel-admin、hotel-demo 中引入 rabbitmq 的依赖：\n\n```xml\n<!--amqp-->\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n\n```yaml\nspring:\n  rabbitmq:\n    host: rabbitmq\n    port: 5672\n    username: halo\n    password: halo\n    virtual-host: /\n```\n\n#### 声明交换机、队列\n\n在 hotel-admin 和 hotel-demo 中的 `cn.itcast.hotel.constatnts` 包下新建一个类 `MqConstants`：\n\n```java\npublic class MqConstants {\n    /**\n     * 交换机\n     */\n    public final static String HOTEL_EXCHANGE = \"hotel.topic\";\n    /**\n     * 监听新增和修改的队列\n     */\n    public final static String HOTEL_INSERT_QUEUE = \"hotel.insert.queue\";\n    /**\n     * 监听删除的队列\n     */\n    public final static String HOTEL_DELETE_QUEUE = \"hotel.delete.queue\";\n    /**\n     * 新增或修改的RoutingKey\n     */\n    public final static String HOTEL_INSERT_KEY = \"hotel.insert\";\n    /**\n     * 删除的RoutingKey\n     */\n    public final static String HOTEL_DELETE_KEY = \"hotel.delete\";\n}\n```\n\n在 hotel-demo 中，定义配置类，声明队列、交换机：\n\n```java\n@Configuration\npublic class MqConfig {\n    @Bean\n    public TopicExchange topicExchange(){\n        return new TopicExchange(MqConstants.HOTEL_EXCHANGE, true, false);\n    }\n\n    @Bean\n    public Queue insertQueue(){\n        return new Queue(MqConstants.HOTEL_INSERT_QUEUE, true);\n    }\n\n    @Bean\n    public Queue deleteQueue(){\n        return new Queue(MqConstants.HOTEL_DELETE_QUEUE, true);\n    }\n\n    @Bean\n    public Binding insertQueueBinding(){\n        return BindingBuilder.bind(insertQueue()).to(topicExchange()).with(MqConstants.HOTEL_INSERT_KEY);\n    }\n\n    @Bean\n    public Binding deleteQueueBinding(){\n        return BindingBuilder.bind(deleteQueue()).to(topicExchange()).with(MqConstants.HOTEL_DELETE_KEY);\n    }\n}\n```\n\n### 发送 MQ 消息\n\n在 hotel-admin 中的增、删、改业务中分别发送 MQ 消息：\n\n```java\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n@PostMapping\npublic void saveHotel(@RequestBody Hotel hotel){\n    hotelService.save(hotel);\n    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE,MqConstants.HOTEL_INSERT_KEY,hotel.getId());\n}\n\n@PutMapping()\npublic void updateById(@RequestBody Hotel hotel){\n    if (hotel.getId() == null) {\n        throw new InvalidParameterException(\"id不能为空\");\n    }\n    hotelService.updateById(hotel);\n    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE,MqConstants.HOTEL_INSERT_KEY,hotel.getId());\n}\n\n@DeleteMapping(\"/{id}\")\npublic void deleteById(@PathVariable(\"id\") Long id) {\n    hotelService.removeById(id);\n    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE,MqConstants.HOTEL_DELETE_KEY,id);\n}\n```\n\n### 接收 MQ 消息\n\nhotel-demo 接收到 MQ 消息要做的事情包括：\n\n- 新增消息：根据传递的 hotel 的 id 查询 hotel 信息，然后新增一条数据到索引库\n- 删除消息：根据传递的 hotel 的 id 删除索引库中的一条数据\n\n首先在 hotel-demo 的 `cn.itcast.hotel.service` 包下的 `IHotelService` 中新增新增、删除业务\n\n```java\nvoid deleteById(Long id);\n\nvoid insertById(Long id);\n```\n\n给 hotel-demo 中的 `cn.itcast.hotel.service.impl` 包下的 HotelService 中实现业务：\n\n```java\n@Override\npublic void deleteById(Long id) {\n    try {\n        // 1.准备Request\n        DeleteRequest request = new DeleteRequest(\"hotel\", id.toString());\n        // 2.发送请求\n        client.delete(request, RequestOptions.DEFAULT);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\n@Override\npublic void insertById(Long id) {\n    try {\n        // 0.根据id查询酒店数据\n        Hotel hotel = getById(id);\n        // 转换为文档类型\n        HotelDoc hotelDoc = new HotelDoc(hotel);\n\n        // 1.准备Request对象\n        IndexRequest request = new IndexRequest(\"hotel\").id(hotel.getId().toString());\n        // 2.准备Json文档\n        request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);\n        // 3.发送请求\n        client.index(request, RequestOptions.DEFAULT);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n编写监听器，在 hotel-demo 中的 `cn.itcast.hotel.mq` 包新增一个类：\n\n```java\n@Component\npublic class HotelListener {\n\n    @Autowired\n    private IHotelService hotelService;\n\n    /**\n     * 监听酒店新增或修改的业务\n     * @param id 酒店id\n     */\n    @RabbitListener(queues = MqConstants.HOTEL_INSERT_QUEUE)\n    public void listenHotelInsertOrUpdate(Long id){\n        hotelService.insertById(id);\n    }\n\n    /**\n     * 监听酒店删除的业务\n     * @param id 酒店id\n     */\n    @RabbitListener(queues = MqConstants.HOTEL_DELETE_QUEUE)\n    public void listenHotelDelete(Long id){\n        hotelService.deleteById(id);\n    }\n}\n```\n\n## ElasticSearch 集群\n\n单机的 ElasticSearch 做数据存储，必然面临两个问题：海量数据存储问题、单点故障问题。\n\n- 海量数据存储问题：将索引库从逻辑上拆分为 N 个分片（shard），存储到多个节点\n- 单点故障问题：将分片数据在不同节点备份（replica）\n\nES 集群相关概念:\n\n* 集群（cluster）：一组拥有共同的 cluster name 的 节点。\n* 节点（node)   ：集群中的一个 Elasticearch 实例\n* 分片（shard）：索引可以被拆分为不同的部分进行存储，称为分片。在集群环境下，一个索引的不同分片可以拆分到不同的节点中\n\n解决问题：数据量太大，单点存储量有限的问题。\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.4pwzs1lq4540.png)\n\n此处，我们把数据分成 3 片：shard0、shard1、shard2\n\n* 主分片（Primary shard）：相对于副本分片的定义。\n\n* 副本分片（Replica shard）每个主分片可以有一个或者多个副本，数据和主分片一样。\n\n数据备份可以保证高可用，但是每个分片备份一份，所需要的节点数量就会翻一倍，成本实在是太高了！\n\n为了在高可用和成本间寻求平衡，我们可以这样做：\n\n- 首先对数据分片，存储到不同节点\n- 然后对每个分片进行备份，放到对方节点，完成互相备份\n\n这样可以大大减少所需要的服务节点数量，如图，我们以 3 分片，每个分片备份一份为例：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3jlk46u66q60.png)\n\n现在，每个分片都有 1 个备份，存储在 3 个节点：\n\n- node0：保存了分片 0 和 1\n- node1：保存了分片 0 和 2\n- node2：保存了分片 1 和 2\n\n### 部署 ElasticSearch 集群\n\n我们会在单机上利用 docker 容器运行多个 ElasticSearch 实例来模拟 ElasticSearch 集群。不过生产环境推荐大家每一台服务节点仅部署一个 ElasticSearch 的实例。\n\n部署 ElasticSearch 集群可以直接使用 docker-compose 来完成，但这要求你的 Linux 虚拟机至少有 4G 的内存空间\n\n#### 创建 ElasticSearch 集群\n\n首先编写一个 docker-compose 文件，内容如下：\n\n```sh\nversion: \'2.2\'\nservices:\n  es01:\n    image: elasticsearch:7.12.1\n    container_name: es01\n    environment:\n      - node.name=es01\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es02,es03\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data01:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n    networks:\n      - elastic\n  es02:\n    image: elasticsearch:7.12.1\n    container_name: es02\n    environment:\n      - node.name=es02\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es01,es03\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data02:/usr/share/elasticsearch/data\n    ports:\n      - 9201:9200\n    networks:\n      - elastic\n  es03:\n    image: elasticsearch:7.12.1\n    container_name: es03\n    environment:\n      - node.name=es03\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es01,es02\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data03:/usr/share/elasticsearch/data\n    networks:\n      - elastic\n    ports:\n      - 9202:9200\nvolumes:\n  data01:\n    driver: local\n  data02:\n    driver: local\n  data03:\n    driver: local\n\nnetworks:\n  elastic:\n    driver: bridge\n```\n\nElasticSearch  运行需要修改一些 Linux 系统权限，修改 `/etc/sysctl.conf` 文件\n\n```sh\nvi /etc/sysctl.conf\n```\n\n添加下面的内容：\n\n```sh\nvm.max_map_count=262144\n```\n\n然后执行命令，让配置生效：\n\n```sh\nsysctl -p\n```\n\n通过 docker-compose 启动集群：\n\n```sh\ndocker-compose up -d\n```\n\n#### 集群状态监控\n\nkibana 可以监控 ElasticSearch  集群，不过新版本需要依赖 ElasticSearch  的 x-pack 功能，配置比较复杂。\n\n这里推荐使用 cerebro 来监控 ElasticSearch  集群状态，官方网址：https://github.com/lmenezes/cerebro\n\n双击其中的 cerebro.bat 文件即可启动服务。访问 http://localhost:9000 即可进入管理界面：\n\n输入你的 ElasticSearch 的任意节点的地址和端口，点击 connect 即可\n\n#### 创建索引库\n\n利用 kibana 的 DevTools 创建索引库，在 DevTools 中输入指令：\n\n```json\nPUT /test\n{\n  \"settings\": {\n    \"number_of_shards\": 3, // 分片数量\n    \"number_of_replicas\": 1 // 副本数量\n  },\n  \"mappings\": {\n    \"properties\": {\n      // mapping映射定义 ...\n    }\n  }\n}\n```\n\n或利用 cerebro 创建索引库\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.29xen9tqfmvw.png)\n\n查看分片效果，回到首页，即可查看索引库分片效果：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.2jn8zaht2280.png)\n\n### 集群脑裂问题\n\n#### 集群职责划分\n\nElasticSearch 中集群节点有不同的职责划分：\n\n| 节点类型         | 配置参数                                       | 默认值 | 节点职责                                                     |\n| ---------------- | ---------------------------------------------- | ------ | ------------------------------------------------------------ |\n| master  eligible | node.master                                    | true   | 备选主节点：主节点可以管理和记录集群状态、决定分片在哪个节点、处理创建和删除索引库的请求 |\n| data             | node.data                                      | true   | 数据节点：存储数据、搜索、聚合、CRUD                         |\n| ingest           | node.ingest                                    | true   | 数据存储之前的预处理                                         |\n| coordinating     | 上面 3 个参数都为 false 则为 coordinating 节点 | 无     | 路由请求到其它节点  合并其它节点处理的结果，返回给用户       |\n\n默认情况下，集群中的任何一个节点都同时具备上述四种角色。\n\n但是真实的集群一定要将集群职责分离：\n\n- master 节点：对 CPU 要求高，但是内存要求低\n- data 节点：对 CPU 和内存要求都高\n- coordinating 节点：对网络带宽、CPU 要求高\n\n职责分离可以让我们根据不同节点的需求分配不同的硬件去部署。而且避免业务之间的互相干扰。\n\n一个典型的 ElasticSearch 集群职责划分如图：\n\n![ES集群](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/ES集群.2rrl7g78cxs0.svg)\n\n#### 脑裂问题\n\n脑裂是因为集群中的节点失联导致的。\n\n例如一个集群中，主节点与其它节点失联，\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.6ry0qp2sxiw0.png)\n\n此时 node2 和 node3 认为 node1 宕机，就会重新选主：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5qon8j1rbak0.png)\n\n当 node3 当选后，集群继续对外提供服务，node2 和 node3 自成集群，node1 自成集群，两个集群数据不同步，出现数据差异。\n\n当网络恢复后，因为集群中有两个 master 节点，集群状态的不一致，出现脑裂的情况：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.wmlcqz00rls.png)\n\n解决脑裂的方案是，要求选票超过 ( eligible节点数量 + 1 ）/ 2 才能当选为主，因此 eligible 节点数量最好是奇数。对应配置项是 discovery.zen.minimum_master_nodes，在 ElasticSearch 7.0 以后，已经成为默认配置，因此一般不会发生脑裂问题\n\n例如：3 个节点形成的集群，选票必须超过 （3 + 1） / 2 ，也就是 2 票。node3 得到 node2 和 node3 的选票，当选为主。node1 只有自己 1 票，没有当选。集群中依然只有 1 个主节点，没有出现脑裂。\n\n### 集群分布式存储\n\n当新增文档时，应该保存到不同分片，保证数据均衡，那么 coordinating node 如何确定数据该存储到哪个分片呢？\n\n#### 分片存储测试\n\n在一个节点中加入数据，后可以通过 explain 命令查询\n\n```json\nPOST /test/_search\n{\n  \"explain\": true,\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n发现数据在不同的节点中，形成分片存储\n\n#### 分片存储原理\n\nElasticSearch 会通过 hash 算法来计算文档应该存储到哪个分片：`shard = hash(_routing) % number_of_shards`\n\n说明：\n\n- `_routing` 默认是文档的id\n- 算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！\n\n新增文档的流程如下：\n\n![ES集群](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/ES集群.akvhs79fwq0.svg)\n\n解读：\n\n- 新增一个 id=1 的文档\n- 对 id 做 hash 运算，假如得到的是 2，则应该存储到 P-2\n- P-2 的主分片在 node3 节点，将数据路由到 node3\n- 保存文档\n- 同步给 P-2 的副本 R-2，在 node2 节点\n- 返回结果给 coordinating-node 节点\n\n#### 集群分布式查询\n\nElasticSearch 的查询分成两个阶段：\n\n- scatter phase：分散阶段，coordinating node 会把请求分发到每一个分片\n\n- gather phase：聚集阶段，coordinating node 汇总 data node 的搜索结果，并处理为最终结果集返回给用户\n\n#### 集群故障转移\n\n集群的 master 节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。\n\n+ 假如，node1 发生了故障\n+ 宕机后的第一件事，需要重新选主，例如选中了 node2，\n+ node2 成为主节点后，会检测集群监控状态，发现：shard-1、shard-0 没有副本节点。因此需要将 node1 上的数据迁移到 node2、node3\n+ 但 node1 恢复，此时 node1 不在是主节点，但数据会重新平衡\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n', '2021-09-26 12:22:18', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 2, '2021-09-26 12:22:18', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (13, 1, 'ElasticaSeach 入门', 'ElasticaSeach 入门', '\n## 初识 ElasticSearch\n\n### 了解 ElasticSearch\n\n#### ElasticSearch 的作用\n\nElasticSearch 是一款非常强大的开源搜索引擎，具备非常多强大功能，可以帮助我们从海量数据中快速找到需要的内容\n\n#### ELK 技术栈\n\nElasticSearch 结合 Kibana、Logstash、Beats，也就是 Elastic stack（ELK）。被广泛应用在日志数据分析、实时监控等领域。\n\n#### ElasticSearch 和 Lucene\n\nElasticSearch 底层是基于 Lucene 来实现的。\n\nLucene 是一个 Java 语言的搜索引擎类库，是 Apache 公司的顶级项目，由 DougCutting 于 1999 年研发。\n\nLucene 官网地址：https://lucene.apache.org/ 。\n\nLucene 的优势：易扩展、高性能（基于倒排索引）\n\nLucene 的缺点：只限于 Java 语言开发、学习曲线陡峭、不支持水平扩展\n\nElasticSearch 的发展历史：\n\n- 2004 年 Shay Banon 基于 Lucene 开发了 Compass\n- 2010 年 Shay Banon 重写了 Compass，取名为 ElasticSearch。\n\nElasticSearch 官网地址: https://www.elastic.co/cn/\n\n相比与 Lucene ，ElasticSearch 具备下列优势：\n\n+ 支持分布式，可水平扩展\n+ 提供 Restful 接口，可被任何语言调用\n\n### 倒排索引\n\n倒排索引的概念是基于 MySQL 这样的正向索引而言的。\n\n#### 正向索引\n\n如果是根据 id 查询，那么直接走索引，查询速度非常快。\n\n但如果是基于 title 做模糊查询，只能是逐行扫描数据，流程如下：\n\n1. 用户搜索数据，条件是 title 符合 `\"%手机%\"`\n2. 逐行获取数据，比如 id 为 1 的数据\n3. 判断数据中的 title 是否符合用户搜索条件\n4. 如果符合则放入结果集，不符合则丢弃。回到步骤 1\n\n逐行扫描，也就是全表扫描，随着数据量增加，其查询效率也会越来越低。当数据量达到数百万时，就是一场灾难。\n\n#### 倒排索引\n\n倒排索引中有两个非常重要的概念：\n\n- 文档（Document）：用来搜索的数据，其中的每一条数据就是一个文档。例如一个网页、一个商品信息\n- 词条（Term）：对文档数据或用户搜索数据，利用某种算法分词，得到的具备含义的词语就是词条。例如：我是中国人，就可以分为：我、是、中国人、中国、国人这样的几个词条\n\n创建倒排索引是对正向索引的一种特殊处理，流程如下：\n\n- 将每一个文档的数据利用算法分词，得到一个个词条\n- 创建表，每行数据包括词条、词条所在文档 id、位置等信息\n- 因为词条唯一性，可以给词条创建索引，例如 hash 表结构索引\n\n如图：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5jp2imzxno00.png)\n\n倒排索引的搜索流程如下（以搜索“华为手机”为例）：\n\n1. 用户输入条件 `\"华为手机\"` 进行搜索。\n2. 对用户输入内容分词，得到词条：`华为`、`手机`。\n3. 拿着词条在倒排索引中查找，可以得到包含词条的文档 id：1、2、3。\n4. 拿着文档 id 到正向索引中查找具体文档。\n\n虽然要先查询倒排索引，再查询倒排索引，但是无论是词条、还是文档 id 都建立了索引，查询速度非常快！无需全表扫描。\n\n#### 正向和倒排\n\n那么为什么一个叫做正向索引，一个叫做倒排索引呢？\n\n- 正向索引是最传统的，根据id索引的方式。但根据词条查询时，必须先逐条获取每个文档，然后判断文档中是否包含所需要的词条，是根据文档找词条的过程。\n\n- 倒排索引则相反，是先找到用户要搜索的词条，根据词条得到保护词条的文档的 id，然后根据 id 获取文档。是根据词条找文档的过程。\n\n正向索引\n\n+ 优点：可以给多个字段创建索引、根据索引字段搜索、排序速度非常快\n\n- 缺点：根据非索引字段，或者索引字段中的部分词条查找时，只能全表扫描。\n\n倒排索引：\n\n- 优点：根据词条搜索、模糊搜索时，速度非常快\n- 缺点：只能给词条创建索引，而不是字段、无法根据字段做排序\n\n### ElasticSearch 中的一些概念\n\nElasticSearch 中有很多独有的概念，与 MySQL 中略有差别，但也有相似之处。\n\n#### 文档和字段\n\nElasticSearch 是面向文档（Document）存储的，可以是数据库中的一条商品数据，一个订单信息。文档数据会被序列化为 JSON 格式后存储在 ElasticSearch 中：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.lwpnpfcxvds.png)\n\n而 JSON 文档中往往包含很多的字段（Field），类似于数据库中的列。\n\n#### 索引和映射\n\n索引（Index），就是相同类型的文档的集合。例如：\n\n- 所有用户文档，就可以组织在一起，称为用户的索引；\n- 所有商品的文档，可以组织在一起，称为商品的索引；\n- 所有订单的文档，可以组织在一起，称为订单的索引；\n\n![索引](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/索引.67l5ib0vvgo0.svg)\n\n因此，我们可以把索引当做是数据库中的表。\n\n数据库的表会有约束信息，用来定义表的结构、字段的名称、类型等信息。因此，索引库中就有映射（mapping），是索引中文档的字段约束信息，类似表的结构约束。\n\n#### MySQL 与 ElasticSearch\n\n我们统一的把 MySQL 与 ElasticSearch 的概念做一下对比：\n\n| MySQL  | Elasticsearch | **说明**                                                     |\n| ------ | ------------- | ------------------------------------------------------------ |\n| Table  | Index         | 索引（index），就是文档的集合，类似数据库的表（table）       |\n| Row    | Document      | 文档（Document），就是一条条的数据，类似数据库中的行（Row），文档都是JSON格式 |\n| Column | Field         | 字段（Field），就是 JSON 文档中的字段，类似数据库中的列（Column） |\n| Schema | Mapping       | Mapping（映射）是索引中文档的约束，例如字段类型约束。类似数据库的表结构（Schema） |\n| SQL    | DSL           | DSL是 ElasticSearch 提供的 JSON 风格的请求语句，用来操作 ElasticSearch，实现 CRUD |\n\n- MySQL ：擅长事务类型操作，可以确保数据的安全和一致性\n\n- ElasticSearch：擅长海量数据的搜索、分析、计算\n\n因此在企业中，往往是两者结合使用：\n\n- 对安全性要求较高的写操作，使用 MySQL 实现\n- 对查询性能要求较高的搜索需求，使用 ElasticSearch 实现\n- 两者再基于某种方式，实现数据的同步，保证一致性\n\n![ElasticSearch](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/ElasticSearch.4koj7qwgqge0.svg)\n\n### 安装 ElasticSearch 、Kibana\n\n#### 创建网络\n\n因为我们还需要部署 Kibana 容器，因此需要让 ElasticSearch 和 Kibana 容器互联。这里先创建一个网络：\n\n```sh\ndocker network create halo-es-net\n```\n\n#### 拉取或加载镜像\n\n```sh\ndocker pull elasticsearch:7.14.1\n```\n\n```sh\ndocker pull kibana:7.14.1\n```\n\n#### 运行（单点）\n\n运行 docker 命令，部署单点 ElasticSearch ：\n\n```sh\ndocker run -d \\\n	--name halo-es \\\n    -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n    -e \"discovery.type=single-node\" \\\n    -v es-data:/usr/share/elasticsearch/data \\\n    -v es-plugins:/usr/share/elasticsearch/plugins \\\n    --privileged \\\n    --network halo-es-net \\\n    -p 9200:9200 \\\n    -p 9300:9300 \\\nelasticsearch:7.14.1\n```\n\n命令解释：\n\n- `-e \"cluster.name=es-docker-cluster\"`：设置集群名称\n- `-e \"http.host=0.0.0.0\"`：监听的地址，可以外网访问\n- `-e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"`：内存大小\n- `-e \"discovery.type=single-node\"`：非集群模式\n- `-v es-data:/usr/share/elasticsearch/data`：挂载逻辑卷，绑定 ElasticSearch 的数据目录\n- `-v es-logs:/usr/share/elasticsearch/logs`：挂载逻辑卷，绑定 ElasticSearch 的日志目录\n- `-v es-plugins:/usr/share/elasticsearch/plugins`：挂载逻辑卷，绑定 ElasticSearch 的插件目录\n- `--privileged`：授予逻辑卷访问权\n- `--network halo-es-net` ：加入一个名为 halo-es-net 的网络中\n- `-p 9200:9200`：端口映射配置\n\n在浏览器中输入：http://halo:9200 即可看到 ElasticSearch 的响应结果：\n\n运行 docker 命令，部署 Kibana\n\n```sh\ndocker run -d \\\n--name halo-kibana \\\n-e ELASTICSEARCH_HOSTS=http://halo-es:9200 \\\n--network halo-es-net \\\n-p 5601:5601  \\\nkibana:7.14.1\n```\n\n- `--network es-net` ：加入一个名为es-net的网络中，与 elasticsearch 在同一个网络中\n- `-e ELASTICSEARCH_HOSTS=http://halo-es:9200\"`：设置 elasticsearch 的地址，因为 kibana 已经与elasticsearch 在一个网络，因此可以用容器名（halo-es）直接访问 elasticsearch\n- `-p 5601:5601`：端口映射配置\n\nkibana 启动一般比较慢，需要多等待一会，可以通过命令查看日志：\n\n```sh\ndocker logs -f kibana\n```\n\n在浏览器输入地址访问：http://halo:5601，即可看到结果\n\n### 安装 IK 分词器\n\nElasticSearch 在创建倒排索引时需要对文档分词；在搜索时，需要对用户输入内容分词。但默认的分词规则对中文处理并不友好。\n\n我们在 Kibana 的 DevTools 中测试：\n\n```json\nPOST /_analyze\n{\n  \"analyzer\": \"standard\",\n  \"text\": \"你好,世界! Hello,World!\"\n}\n```\n\n语法说明：\n\n+ POST：请求方式\n+ /_analyze：请求路径，这里省略了 http://halo:9200，有 kibana 帮我们补充\n+ 请求参数，JSON 风格：`analyzer`：分词器类型，这里是默认的 standard 分词器；`text`：要分词的内容\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"你\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 1,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"好\",\n      \"start_offset\" : 1,\n      \"end_offset\" : 2,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"世\",\n      \"start_offset\" : 3,\n      \"end_offset\" : 4,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"界\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 5,\n      \"type\" : \"<IDEOGRAPHIC>\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"hello\",\n      \"start_offset\" : 7,\n      \"end_offset\" : 12,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"world\",\n      \"start_offset\" : 13,\n      \"end_offset\" : 18,\n      \"type\" : \"<ALPHANUM>\",\n      \"position\" : 5\n    }\n  ]\n}\n```\n\n处理中文分词，一般会使用 IK 分词器。https://github.com/medcl/elasticsearch-analysis-ik\n\n#### 在线安装 IK 插件\n\n```sh\n# 进入容器内部\ndocker exec -it elasticsearch /bin/bash\n\n# 在线下载并安装\n./bin/elasticsearch-plugin install https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v7.14.1/elasticsearch-analysis-ik-7.14.1.zip\n\n#退出\nexit\n#重启容器\ndocker restart elasticsearch\n```\n\n#### 离线安装 IK 插件\n\n查看数据卷目录\n\n安装插件需要知道 elasticsearch 的 plugins 目录位置，而我们用了数据卷挂载，因此需要查看 elasticsearch 的数据卷目录，通过下面命令查看:\n\n```sh\ndocker volume inspect es-plugins\n```\n\n显示结果：\n\n```\n[\n    {\n        \"CreatedAt\": \"2021-09-11T12:50:57+08:00\",\n        \"Driver\": \"local\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker/volumes/es-plugins/_data\",\n        \"Name\": \"es-plugins\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n```\n\n说明 plugins 目录被挂载到了：`/var/lib/docker/volumes/es-plugins/_data ` 这个目录中。\n\n将 ik 分词器解压缩，重命名为 ik，上传到 es 容器的插件数据卷中后重启容器\n\n```sh\ndocker restart halo-es\n```\n\n#### 测试分词器\n\nIK 分词器包含两种模式：\n\n* `ik_smart` ：最少切分，粗粒度\n\n* `ik_max_word` ：最细切分，细粒度\n\n```json\nPOST /_analyze\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"你好,我的世界! Hello,World!\"\n}\n```\n\n结果：\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"你好\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 2,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"我\",\n      \"start_offset\" : 3,\n      \"end_offset\" : 4,\n      \"type\" : \"CN_CHAR\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"的\",\n      \"start_offset\" : 4,\n      \"end_offset\" : 5,\n      \"type\" : \"CN_CHAR\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"世界\",\n      \"start_offset\" : 5,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"hello\",\n      \"start_offset\" : 9,\n      \"end_offset\" : 14,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"world\",\n      \"start_offset\" : 15,\n      \"end_offset\" : 20,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 5\n    }\n  ]\n}\n```\n\n#### 扩展和停用词词典\n\n随着互联网的发展，“造词运动”也越发的频繁。出现了很多新的词语，在原有的词汇列表中并不存在。\n\n所以我们的词汇也需要不断的更新，IK 分词器提供了扩展词汇的功能。\n\n打开 IK 分词器 config 目录：\n\n```sh\ncd /var/lib/docker/volumes/es-plugins/_data/ik/config\n```\n\n在 IKAnalyzer.cfg.xml 配置文件内容添加：\n\n```xml\n<!DOCTYPE properties SYSTEM \"http://java.sun.com/dtd/properties.dtd\">\n<properties>\n        <comment>IK Analyzer 扩展配置</comment>\n        <!--用户可以在这里配置自己的扩展字典 -->\n        <entry key=\"ext_dict\">ext.dic</entry>\n         <!--用户可以在这里配置自己的扩展停止词字典-->\n        <entry key=\"ext_stopwords\">stopwort.dic</entry>\n        <!--用户可以在这里配置远程扩展字典 -->\n        <!-- <entry key=\"remote_ext_dict\">words_location</entry> -->\n        <!--用户可以在这里配置远程扩展停止词字典-->\n        <!-- <entry key=\"remote_ext_stopwords\">words_location</entry> -->\n</properties>\n```\n\n新建一个 ext.dic，可以参考 config 目录下复制一个配置文件进行修改\n\n```properties\n我的世界\n```\n\nstopwort.dic 添加\n\n```properties\n的\n```\n\n重启 ElasticSearch \n\n```sh\ndocker restart es\n\n# 查看 日志\ndocker logs -f elasticsearch\n```\n\n日志中已经成功加载 ext.dic 配置文件\n\n测试\n\n```json\nPOST /_analyze\n{\n  \"analyzer\": \"ik_max_word\",\n  \"text\": \"你好,我的世界! Hello,World!\"\n}\n```\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"你好\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 2,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"我的世界\",\n      \"start_offset\" : 3,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"世界\",\n      \"start_offset\" : 5,\n      \"end_offset\" : 7,\n      \"type\" : \"CN_WORD\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"hello\",\n      \"start_offset\" : 9,\n      \"end_offset\" : 14,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"world\",\n      \"start_offset\" : 15,\n      \"end_offset\" : 20,\n      \"type\" : \"ENGLISH\",\n      \"position\" : 4\n    }\n  ]\n}\n```\n\n> 注意当前文件的编码必须是 UTF-8 格式，严禁使用 Windows 记事本编辑\n\n## DSL 索引库操作\n\n索引库就类似数据库表，mapping 映射就类似表的结构。我们要向 es 中存储数据，必须先创建“库”和“表”。\n\n### mapping 映射属性\n\nmapping 是对索引库中文档的约束，常见的mapping属性包括：\n\n- type：字段数据类型，常见的简单类型有：\n  - 字符串：text（可分词的文本）、keyword（精确值，例如：品牌、国家、ip 地址）\n  - 数值：long、integer、short、byte、double、float、\n  - 布尔：boolean\n  - 日期：date\n  - 对象：object\n- index：是否创建索引，默认为 true\n- analyzer：使用哪种分词器\n- properties：该字段的子字段\n\n例如下面的 JSON 文档：\n\n```json\n{\n    \"age\": 21,\n    \"weight\": 52.1,\n    \"isMarried\": false,\n    \"info\": \"黑马程序员Java讲师\",\n    \"email\": \"zy@itcast.cn\",\n    \"score\": [99.1, 99.5, 98.9],\n    \"name\": {\n        \"firstName\": \"云\",\n        \"lastName\": \"赵\"\n    }\n}\n```\n\n对应的每个字段映射（mapping）：\n\n- age：类型为 integer；参与搜索，因此需要 index 为 true；无需分词器\n- weight：类型为 float；参与搜索，因此需要 index 为 true；无需分词器\n- isMarried：类型为 boolean；参与搜索，因此需要 index 为 true；无需分词器\n- info：类型为字符串，需要分词，因此是 text；参与搜索，因此需要 index 为 true；分词器可以用 ik_smart\n- email：类型为字符串，但是不需要分词，因此是 keyword；不参与搜索，因此需要 index 为 false；无需分词器\n- score：虽然是数组，但是我们只看元素的类型，类型为 float；参与搜索，因此需要 index 为 true；无需分词器\n- name：类型为 object，需要定义多个子属性\n  - name.firstName：类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为 true；无需分词器\n  - name.lastName：类型为字符串，但是不需要分词，因此是 keyword；参与搜索，因此需要 index 为 true；无需分词器\n\n### 索引库的 CRUD\n\n这里统一使用 Kibana 编写 DSL 的方式来演示。\n\n#### 创建索引库和映射\n\n基本语法：\n\n+ 请求方式：PUT\n+ 请求路径：/索引库名，可以自定义\n+ 请求参数：mapping 映射\n\n```json\nPUT /索引库名称\n{\n  \"mappings\": {\n    \"properties\": {\n      \"字段名\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_smart\"\n      },\n      \"字段名2\":{\n        \"type\": \"keyword\",\n        \"index\": \"false\"\n      },\n      \"字段名3\":{\n        \"properties\": {\n          \"子字段\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      // ...略\n    }\n  }\n}\n```\n\n示例：\n\n```json\nPUT /heima\n{\n  \"mappings\": {\n    \"properties\": {\n      \"info\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_smart\"\n      },\n      \"email\":{\n        \"type\": \"keyword\",\n        \"index\": \"falsae\"\n      },\n      \"name\":{\n        \"properties\": {\n          \"firstName\": {\n            \"type\": \"keyword\"\n          }\n        }\n      },\n      // ... 略\n    }\n  }\n}\n```\n\n#### 查询索引库\n\n基本语法：\n\n- 请求方式：GET\n\n- 请求路径：/索引库名\n\n- 请求参数：无\n\n```\nGET /索引库名\n```\n\n#### 删除索引库\n\n语法：\n\n- 请求方式：DELETE\n\n- 请求路径：/索引库名\n\n- 请求参数：无\n\n```\nDELETE /索引库名\n```\n\n#### 修改索引库\n\n倒排索引结构虽然不复杂，但是一旦数据结构改变（比如改变了分词器），就需要重新创建倒排索引，这简直是灾难。因此索引库一旦创建，无法修改 mapping。\n\n虽然无法修改 mapping 中已有的字段，但是却允许添加新的字段到 mapping 中，因为不会对倒排索引产生影响。\n\n语法说明：\n\n```json\nPUT /索引库名/_mapping\n{\n  \"properties\": {\n    \"新字段名\": {\n      \"type\": \"xxxx\"\n    }\n  }\n}\n```\n\n#### 索引库的 CRUD 小结\n\n- 创建索引库：PUT /索引库名\n- 查询索引库：GET /索引库名\n- 删除索引库：DELETE /索引库名\n- 添加字段：PUT /索引库名/_mapping\n\n## DSL 文档操作\n\n### 新增文档\n\n 语法：\n\n```json\nPOST /索引库名/_doc/文档id\n{\n    \"字段1\": \"值1\",\n    \"字段2\": \"值2\",\n    \"字段3\": {\n        \"子属性1\": \"值3\",\n        \"子属性2\": \"值4\"\n    },\n    // ...\n}\n```\n\n示例：\n\n```json\nPOST /halo/_doc/1\n{\n  \"info\": \"黑马程序员Java讲师\",\n  \"email\": \"zy@itcast.cn\",\n  \"name\": {\n    \"firstName\": \"云\",\n    \"lastName\": \"赵\"\n  }\n}\n```\n\n### 查询文档\n\n根据 rest 风格，新增是 post，查询应该是 get，不过查询一般都需要条件，这里我们把文档 id 带上。\n\n语法：\n\n```\nGET /{索引库名称}/_doc/{id}\n```\n\n通过 kibana 查看数据：\n\n```\nGET /halo/_doc/1\n```\n\n### 删除文档\n\n删除使用 DELETE 请求，同样，需要根据 id 进行删除：\n\n语法：\n\n```\nDELETE /{索引库名}/_doc/id值\n```\n\n示例：\n\n```\nDELETE /halo/_doc/1\n```\n\n### 修改文档\n\n修改有两种方式：\n\n- 全量修改：直接覆盖原来的文档\n- 增量修改：修改文档中的部分字段\n\n#### 全量修改\n\n全量修改是覆盖原来的文档，其本质是：\n\n- 根据指定的 id 删除文档\n- 新增一个相同 id 的文档\n\n> 注意：如果根据 id 删除时，id 不存在，第二步的新增也会执行，也就从修改变成了新增操作了。\n\n语法：\n\n```json\nPUT /{索引库名}/_doc/文档id\n{\n    \"字段1\": \"值1\",\n    \"字段2\": \"值2\",\n    // ... 略\n}\n```\n\n示例：\n\n```json\nPUT /halo/_doc/1\n{\n  \"info\": \"黑马程序员高级Java讲师2\",\n  \"email\": \"zy@itcast.cn\",\n  \"name\": {\n    \"firstName\": \"云\",\n    \"lastName\": \"赵\"\n  }\n}\n```\n\n#### 增量修改\n\n增量修改是只修改指定 id 匹配的文档中的部分字段。\n\n语法：\n\n```json\nPOST /{索引库名}/_update/文档id\n{\n    \"doc\": {\n         \"字段名\": \"新的值\",\n    }\n}\n```\n\n示例：\n\n```\nPOST /halo/_update/1\n{\n  \"doc\": {\n    \"email\": \"ZhaoYun@itcast.cn\"\n  }\n}\n```\n\n### 文档操作总结\n\n- 创建文档：POST /{索引库名}/_doc/文档id   { JSON 文档 }\n- 查询文档：GET /{索引库名}/_doc/文档id\n- 删除文档：DELETE /{索引库名}/_doc/文档id\n- 修改文档：\n  - 全量修改：PUT /{索引库名}/_doc/文档id { JSON 文档 }\n  - 增量修改：POST /{索引库名}/_update/文档id { \"doc\": {字段}}\n\n## Rest Client 索引库操作\n\nElasticSearch 官方提供了各种不同语言的客户端，用来操作 ElasticSearch。这些客户端的本质就是组装 DSL 语句，通过 http 请求发送给 ElasticSearch。官方文档地址：https://www.elastic.co/guide/en/elasticsearch/client/index.html\n\n其中的 Java Rest Client 又包括两种：\n\n- Java Low Level Rest Client\n- Java High Level Rest Client\n\n我们学习的是 Java HighLevel Rest Client 客户端 API\n\n### 创建测试环境\n\n#### 初始化项目\n\n创建数据库，建立数据表\n\n```sql\nCREATE TABLE `tb_hotel`  (\n    `id` bigint(20) NOT NULL COMMENT \'酒店id\',\n    `name` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'酒店名称\',\n    `address` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'酒店地址\',\n    `price` int(10) NOT NULL COMMENT \'酒店价格\',\n    `score` int(2) NOT NULL COMMENT \'酒店评分\',\n    `brand` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'酒店品牌\',\n    `city` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'所在城市\',\n    `star_name` varchar(16) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT \'酒店星级，1星到5星，1钻到5钻\',\n    `business` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT \'商圈\',\n    `latitude` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'纬度\',\n    `longitude` varchar(32) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NOT NULL COMMENT \'经度\',\n    `pic` varchar(255) CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci NULL DEFAULT NULL COMMENT \'酒店图片\',\n    PRIMARY KEY (`id`) USING BTREE\n) ENGINE = InnoDB CHARACTER SET = utf8mb4 COLLATE = utf8mb4_general_ci ROW_FORMAT = Compact;\n```\n\n导入数据库数据：[链接](https://github.com/Lanqilu/HaloElasticSearch/blob/master/doc/database/tb_hotel.sql)\n\n初始项目代码：[链接](https://github.com/Lanqilu/HaloElasticSearch/commit/d64b305ccf9ca67b8a18bafee3df7163e7dd8246)\n\n#### mapping 映射分析\n\n创建索引库，最关键的是 mapping 映射，而 mapping 映射要考虑的信息包括：\n\n- 字段名\n- 字段数据类型\n- 是否参与搜索\n- 是否需要分词\n- 如果分词，分词器是什么？\n\n其中：\n\n- 字段名、字段数据类型，可以参考数据表结构的名称和类型\n- 是否参与搜索要分析业务来判断，例如图片地址，就无需参与搜索\n- 是否分词呢要看内容，内容如果是一个整体就无需分词，反之则要分词\n- 分词器，我们可以统一使用 ik_max_word\n\n来看下酒店数据的索引库结构：\n\n```json\nPUT /hotel\n{\n  \"mappings\": {\n    \"properties\": {\n      \"id\": {\n        \"type\": \"keyword\"\n      },\n      \"name\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\",\n        \"copy_to\": \"all\"\n      },\n      \"address\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"price\":{\n        \"type\": \"integer\"\n      },\n      \"score\":{\n        \"type\": \"integer\"\n      },\n      \"brand\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"city\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"starName\":{\n        \"type\": \"keyword\"\n      },\n      \"business\":{\n        \"type\": \"keyword\"\n      },\n      \"location\":{\n        \"type\": \"geo_point\"\n      },\n      \"pic\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"all\":{\n        \"type\": \"text\",\n        \"analyzer\": \"ik_max_word\"\n      }\n    }\n  }\n}\n```\n\n几个特殊字段说明：\n\n- location：地理坐标，里面包含精度、纬度\n- all：一个组合字段，其目的是将多字段的值 利用 copy_to 合并，提供给用户搜索\n\n ES 中支持两种地理坐标数据类型：\n\n•geo_point：由纬度（latitude）和经度（longitude）确定的一个点。例如：\"32.8752345, 120.2981576\"\n\n•geo_shape：有多个geo_point组成的复杂几何图形。例如一条直线，\"LINESTRING (-77.03653 38.897676, -77.009051 38.889939)\"\n\n字段拷贝可以使用 copy_to 属性将当前字段拷贝到指定字段。示例：\n\n```json\n\"all\": {\n  \"type\": \"text\",\n  \"analyzer\": \"ik_max_word\"\n},\n\"brand\": {\n  \"type\": \"keyword\",\n  \"copy_to\": \"all\"\n}\n```\n\n#### 初始化 RestClient\n\n在 ElasticSearch 提供的 API 中，与 ElasticSearch 一切交互都封装在一个名为 RestHighLevelClient 的类中，必须先完成这个对象的初始化，建立与 ElasticSearch 的连接。\n\n分为三步：\n\n① 引入 ElasticSearch 的 RestHighLevelClient 依赖：\n\n```xml\n<dependency>\n    <groupId>org.elasticsearch.client</groupId>\n    <artifactId>elasticsearch-rest-high-level-client</artifactId>\n</dependency>\n```\n\n② 因为 SpringBoot 默认的 ElasticSearch 版本是 7.6.2，所以我们需要覆盖默认的 ElasticSearch 版本，与 ElasticSearch 版本保持一致\n\n```xml\n<properties>\n    <java.version>1.8</java.version>\n    <elasticsearch.version>7.14.1</elasticsearch.version>\n</properties>\n```\n\n③ 初始化 RestHighLevelClient：\n\n初始化的代码如下：\n\n```java\nRestHighLevelClient client = new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n```\n\n这里为了单元测试方便，我们创建一个测试类 HotelIndexTest，然后将初始化的代码编写在 `@BeforeEach` 方法中：\n\n```java\npublic class HotelIndexTest {\n\n    private RestHighLevelClient client;\n\n    @Test\n    void testInit() {\n        System.out.println(\"client = \" + client);\n    }\n\n    @BeforeEach\n    void setUp() {\n        this.client = new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n    }\n\n    @AfterEach\n    void tearDown() throws IOException {\n        this.client.close();\n    }\n}\n```\n\n### 创建索引库\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.zlx2xrhd54w.png)\n\n代码分为三步：\n\n1. 创建 Request 对象。因为是创建索引库的操作，因此 Request 是 CreateIndexRequest\n2. 添加请求参数，其实就是 DSL 的 JSON 参数部分。因为 JSON 字符串很长，这里是定义了静态字符串常量 MAPPING_TEMPLATE，让代码看起来更加优雅。\n3. 发送请求，`client.indices()` 方法的返回值是 IndicesClient 类型，封装了所有与索引库操作有关的方法。\n\n在 hotel-demo 中的 HotelIndexTest 测试类中，编写单元测试，实现创建索引：\n\n```java\n@Test\nvoid createHotelIndex() throws IOException {\n    // 1.创建Request对象\n    CreateIndexRequest request = new CreateIndexRequest(\"hotel\");\n    // 2.准备请求的参数：DSL语句\n    request.source(MAPPING_TEMPLATE, XContentType.JSON);\n    // 3.发送请求\n    client.indices().create(request, RequestOptions.DEFAULT);\n}\n```\n\n### 删除索引库\n\n删除索引库的 DSL 语句非常简单：\n\n```json\nDELETE /hotel\n```\n\n与创建索引库相比：\n\n- 请求方式从 PUT 变为 DELTE\n- 请求路径不变\n- 无请求参数\n\n所以代码的差异，注意体现在 Request 对象上。依然是三步走：\n\n- 创建 Request 对象。这次是 DeleteIndexRequest 对象\n- 准备参数。这里是无参\n- 发送请求。改用 delete 方法\n\n在 hotel-demo 中的 HotelIndexTest 测试类中，编写单元测试，实现删除索引：\n\n```java\n@Test\nvoid testDeleteHotelIndex() throws IOException {\n    // 1.创建Request对象\n    DeleteIndexRequest request = new DeleteIndexRequest(\"hotel\");\n    // 2.发送请求\n    client.indices().delete(request, RequestOptions.DEFAULT);\n}\n```\n\n### 判断索引库是否存在\n\n判断索引库是否存在，本质就是查询，对应的DSL是：\n\n```json\nGET /hotel\n```\n\n因此与删除的 Java 代码流程是类似的。依然是三步走：\n\n- 创建 Request 对象。这次是 GetIndexRequest 对象\n- 准备参数。这里是无参\n- 发送请求。改用 exists 方法\n\n```java\n@Test\nvoid testExistsHotelIndex() throws IOException {\n    // 1.创建Request对象\n    GetIndexRequest request = new GetIndexRequest(\"hotel\");\n    // 2.发送请求\n    boolean exists = client.indices().exists(request, RequestOptions.DEFAULT);\n    // 3.输出\n    System.err.println(exists ? \"索引库已经存在！\" : \"索引库不存在！\");\n}\n```\n\n### RestAPI 小结\n\nJavaRestClient 操作 ElasticSearch 的流程基本类似。核心是 `client.indices()` 方法来获取索引库的操作对象。\n\n索引库操作的基本步骤：\n\n- 初始化 RestHighLevelClient\n- 创建 XxxIndexRequest。Xxx 是Create、Get、Delete\n- 准备 DSL（ Create时需要，其它是无参）\n- 发送请求。调用 `RestHighLevelClient#indices().xxx()` 方法，xxx 是  create、exists、delete\n\n## Rest Client 文档操作\n\n去数据库查询酒店数据，导入到 hotel 索引库，实现酒店数据的 CRUD。基本步骤如下：\n\n+ 初始化 JavaRestClient\n+ 利用 JavaRestClient 新增酒店数据\n+ 利用 JavaRestClient 根据id查询酒店数据\n+ 利用 JavaRestClient 删除酒店数据\n+ 利用 JavaRestClient 修改酒店数据\n\n### 初始化 JavaRestClient\n\n为了与索引库操作分离，我们再次参加一个测试类，做两件事情：\n\n- 初始化 RestHighLevelClient，同上\n- 我们的酒店数据在数据库，需要利用 IHotelService 去查询，所以注入这个接口\n\n```java\n@SpringBootTest\npublic class HotelDocumentTest {\n    @Autowired\n    private IHotelService hotelService;\n\n    private RestHighLevelClient client;\n\n    @BeforeEach\n    void setUp() {\n        this.client = new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n    }\n\n    @AfterEach\n    void tearDown() throws IOException {\n        this.client.close();\n    }\n}\n```\n\n### 新增文档\n\n我们要将数据库的酒店数据查询出来，写入 ElasticSearch 中。\n\n#### 索引库实体类\n\n数据库查询后的结果是一个 Hotel 类型的对象。结构如下：\n\n```java\n@Data\n@TableName(\"tb_hotel\")\npublic class Hotel {\n    @TableId(type = IdType.INPUT)\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String longitude;\n    private String latitude;\n    private String pic;\n}\n```\n\n与我们的索引库结构存在差异：\n\n- longitude 和 latitude 需要合并为 location\n\n因此，我们需要定义一个新的类型，与索引库结构吻合：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n\n#### 语法说明\n\n新增文档的 DSL 语句如下：\n\n```json\nPOST /{索引库名}/_doc/1\n{\n    \"name\": \"Jack\",\n    \"age\": 21\n}\n```\n\n对应的 Java 代码如下：\n\n```java\n@Test\nvoid testIndexDocument() throws IOException {\n    // 1.创建request对象\n    IndexRequest request = new IndexRequest(\"indexName\").id(\"1\");\n    // 2.准备JSON文档\n    request.source(\"{\\\"name\\\": \\\"Jack\\\", \\\"age\\\": 21}\", XContentType.JSON);\n    // 3.发送请求\n    client.index(request, RequestOptions.DEFAULT);\n}\n```\n\n可以看到与创建索引库类似，同样是三步走：\n\n- 创建 Request 对象\n- 准备请求参数，也就是 DSL 中的 JSON 文档\n- 发送请求\n\n变化的地方在于，这里直接使用 `client.xxx()` 的 API，不再需要 `client.indices()` 了。\n\n#### 完整代码\n\n我们导入酒店数据，基本流程一致，但是需要考虑几点变化：\n\n- 酒店数据来自于数据库，我们需要先查询出来，得到 Hotel 对象\n- Hotel 对象需要转为 HotelDoc对象\n- HotelDoc 需要序列化为 JSON 格式\n\n因此，代码整体步骤如下：\n\n- 根据 id 查询酒店数据 Hotel\n- 将 Hotel 封装为 HotelDoc\n- 将 HotelDoc 序列化为 JSON\n- 创建 IndexRequest，指定索引库名和 id\n- 准备请求参数，也就是 JSON 文档\n- 发送请求\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testAddDocument() throws IOException {\n    // 1.根据id查询酒店数据\n    Hotel hotel = hotelService.getById(61083L);\n    // 2.转换为文档类型\n    HotelDoc hotelDoc = new HotelDoc(hotel);\n    // 3.将HotelDoc转json\n    String json = JSON.toJSONString(hotelDoc);\n\n    // 1.准备Request对象\n    IndexRequest request = new IndexRequest(\"hotel\").id(hotelDoc.getId().toString());\n    // 2.准备Json文档\n    request.source(json, XContentType.JSON);\n    // 3.发送请求\n    client.index(request, RequestOptions.DEFAULT);\n}\n```\n\n### 查询文档\n\n#### 语法说明\n\n查询的 DSL 语句如下：\n\n```json\nGET /hotel/_doc/{id}\n```\n\n非常简单，因此代码大概分两步：\n\n- 准备 Request 对象\n- 发送请求\n\n不过查询的目的是得到结果，解析为 HotelDoc，因此难点是结果的解析。示例代码如下：\n\n```java\n@Test\nvoid testGetDocumentById() throws IOException {\n    // 1.创建request对象\n    GetRequest request = new GetRequest(\"indexName\", \"1\");\n    // 2.发送请求，得到结果\n    GetResponse response = client.get(request, RequestOptions.DEFAULT);\n    // 3.解析结果\n    String json = response.getSourceAsString();\n    System.out.println(json);\n}\n```\n\n可以看到，结果是一个 JSON，其中文档放在一个 `_source` 属性中，因此解析就是拿到 `_source`，反序列化为 Java 对象即可。\n\n与之前类似，也是三步走：\n\n- 准备 Request 对象。这次是查询，所以是 GetRequest\n- 发送请求，得到结果。因为是查询，这里调用 `client.get()` 方法\n- 解析结果，就是对 JSON 做反序列化\n\n#### 完整代码\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testGetDocumentById() throws IOException {\n    // 1.准备Request\n    GetRequest request = new GetRequest(\"hotel\", \"61083\");\n    // 2.发送请求，得到响应\n    GetResponse response = client.get(request, RequestOptions.DEFAULT);\n    // 3.解析响应结果\n    String json = response.getSourceAsString();\n    HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n    System.out.println(hotelDoc);\n}\n```\n\n### 修改文档\n\n#### 语法说明\n\n修改我们讲过两种方式：\n\n- 全量修改：本质是先根据id删除，再新增\n- 增量修改：修改文档中的指定字段值\n\n在 RestClient 的 API 中，全量修改与新增的 API 完全一致，判断依据是 ID：\n\n- 如果新增时，ID 已经存在，则修改\n- 如果新增时，ID 不存在，则新增\n\n这里不再赘述，我们主要关注增量修改。\n\n```java\n@Test\nvoid testUpdateDocumentById() throws IOException {\n    // 1.创建request对象\n    UpdateRequest request = new UpdateRequest(\"indexName\", \"1\");\n    // 2.准备参数，每2个参数为一对 key value    \n    request.doc(\"age\", 18, \"name\", \"Rose\");\n    // 3.更新文档\n    client.update(request, RequestOptions.DEFAULT);\n}\n```\n\n与之前类似，也是三步走：\n\n- 准备 Request 对象。这次是修改，所以是 UpdateRequest\n- 准备参数。也就是 JSON 文档，里面包含要修改的字段\n- 更新文档。这里调用 `client.update()` 方法\n\n#### 完整代码\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testUpdateDocument() throws IOException {\n    // 1.准备Request\n    UpdateRequest request = new UpdateRequest(\"hotel\", \"61083\");\n    // 2.准备请求参数\n    request.doc(\n        \"price\", \"952\",\n        \"starName\", \"四钻\"\n    );\n    // 3.发送请求\n    client.update(request, RequestOptions.DEFAULT);\n}\n```\n\n### 删除文档\n\n删除的 DSL 为是这样的：\n\n```json\nDELETE /hotel/_doc/{id}\n```\n\n与查询相比，仅仅是请求方式从 DELETE 变成 GET，可以想象 Java 代码应该依然是三步走：\n\n- 准备 Request 对象，因为是删除，这次是 DeleteRequest 对象。要指定索引库名和 id\n- 准备参数，无参\n- 发送请求。因为是删除，所以是 `client.delete()` 方法\n\n```java\n@Test\nvoid testDeleteDocument() throws IOException {\n    // 1.准备Request\n    DeleteRequest request = new DeleteRequest(\"hotel\", \"61083\");\n    // 2.发送请求\n    client.delete(request, RequestOptions.DEFAULT);\n}\n```\n\n### 批量导入文档\n\n案例需求：利用 BulkRequest 批量将数据库数据导入到索引库中。\n\n步骤如下：\n\n- 利用 mybatis-plus 查询酒店数据\n\n- 将查询到的酒店数据（Hotel）转换为文档类型数据（HotelDoc）\n\n- 利用 JavaRestClient 中的 BulkRequest 批处理，实现批量新增文档\n\n#### 语法说明\n\n批量处理 BulkRequest，其本质就是将多个普通的 CRUD 请求组合在一起发送。\n\n其中提供了一个 add 方法，用来添加其他请求：\n\n- IndexRequest，也就是新增\n- UpdateRequest，也就是修改\n- DeleteRequest，也就是删除\n\n因此 Bulk 中添加了多个 IndexRequest，就是批量新增功能了。示例：\n\n```java\n@Test\nvoid testBulk() throws IOException {\n    // 1.创建Bulk请求\n    BulkRequest request = new BulkRequest();\n    // 2.添加要批量提交的请求：这里添加了两个新增文档的请求\n    request.add(new IndexRequest(\"hotel\")\n                .id(\"101\").source(\"json source\", XContentType.JSON));\n    request.add(new IndexRequest(\"hotel\")\n                .id(\"102\").source(\"json source2\", XContentType.JSON));\n    // 3.发起bulk请求\n    client.bulk(request, RequestOptions.DEFAULT);\n}\n```\n\n其实还是三步走：\n\n- 创建 Request 对象。这里是 BulkRequest\n- 准备参数。批处理的参数，就是其它 Request 对象，这里就是多个 IndexRequest\n- 发起请求。这里是批处理，调用的方法为 `client.bulk()` 方法\n\n我们在导入酒店数据时，将上述代码改造成 for 循环处理即可。\n\n#### 完整代码\n\n在 hotel-demo 的 HotelDocumentTest 测试类中，编写单元测试：\n\n```java\n@Test\nvoid testBulkRequest() throws IOException {\n    // 批量查询酒店数据\n    List<Hotel> hotels = hotelService.list();\n\n    // 1.创建 Request\n    BulkRequest request = new BulkRequest();\n    // 2.准备参数，添加多个新增的 Request\n    for (Hotel hotel : hotels) {\n        // 2.1.转换为文档类型 HotelDoc\n        HotelDoc hotelDoc = new HotelDoc(hotel);\n        // 2.2.创建新增文档的 Request 对象\n        request.add(new IndexRequest(\"hotel\")\n                    .id(hotelDoc.getId().toString())\n                    .source(JSON.toJSONString(hotelDoc), XContentType.JSON));\n    }\n    // 3.发送请求\n    client.bulk(request, RequestOptions.DEFAULT);\n}\n```\n\n测试，批量查询\n\n```\nGET /hotel/_search\n```\n\n### Rest Client 文档操作小结\n\n文档操作的基本步骤：\n\n- 初始化 RestHighLevelClient\n- 创建 XxxRequest。Xxx 是 Index、Get、Update、Delete、Bulk\n- 准备参数（Index、Update、Bulk时需要）\n- 发送请求。调用 `RestHighLevelClient#.xxx()` 方法，xxx 是 index、get、update、delete、bulk\n- 解析结果（Get时需要）\n\n## DSL 查询文档\n\nElasticSearch 的查询依然是基于 JSON 风格的 DSL 来实现的。\n\n### DSL 查询分类\n\nElasticSearch 提供了基于 JSON 的 DSL（[Domain Specific Language](https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html)）来定义查询。常见的查询类型包括：\n\n- 查询所有：查询出所有数据，一般测试用。例如：match_all\n\n- 全文检索查询：利用分词器对用户输入内容分词，然后去倒排索引库中匹配。例如：\n  - match_query\n  - multi_match_query\n- 精确查询：根据精确词条值查找数据，一般是查找 keyword、数值、日期、boolean 等类型字段。例如：\n  - ids\n  - range\n  - term\n- 地理（geo）查询：根据经纬度查询。例如：\n  - geo_distance\n  - geo_bounding_box\n- 复合（compound）查询：复合查询可以将上述各种查询条件组合起来，合并查询条件。例如：\n  - bool\n  - function_score\n\n查询的语法基本一致：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"查询类型\": {\n      \"查询条件\": \"条件值\"\n    }\n  }\n}\n```\n\n 我们以查询所有为例，其中：\n\n- 查询类型为 match_all\n- 没有查询条件\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n其它查询无非就是查询类型、查询条件的变化。\n\n### 全文检索查询\n\n#### 使用场景\n\n全文检索查询的基本流程如下：\n\n- 对用户搜索的内容做分词，得到词条\n- 根据词条去倒排索引库中匹配，得到文档 id\n- 根据文档 id 找到文档，返回给用户\n\n比较常用的场景包括：\n\n- 商城的输入框搜索\n- 百度输入框搜索\n\n因为是拿着词条去匹配，因此参与搜索的字段也必须是可分词的 text 类型的字段。\n\n#### 基本语法\n\n常见的全文检索查询包括：\n\n- match 查询：单字段查询\n- multi_match 查询：多字段查询，任意一个字段符合条件就算符合查询条件\n\nmatch 查询语法如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match\": {\n      \"FIELD\": \"TEXT\"\n    }\n  }\n}\n```\n\nmulit_match 语法如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"TEXT\",\n      \"fields\": [\"FIELD1\", \" FIELD12\"]\n    }\n  }\n}\n```\n\n#### 使用示例\n\nmatch 查询示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家外滩\"\n    }\n  }\n}\n```\n\nmulti_match 查询示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"如家外滩\",\n      \"fields\": [\"brand\",\"name\",\"business\"]\n    }\n  }\n}\n```\n\n可以看到，两种查询结果是一样的，为什么？\n\n因为我们将 brand、name、business 值都利用 copy_to 复制到了 all 字段中。因此你根据三个字段搜索，和根据 all 字段搜索效果当然一样了。\n\n但是，搜索字段越多，对查询性能影响越大，因此建议采用 copy_to，然后单字段查询的方式。\n\nmatch 和 multi_match 的区别是什么？\n\n- match：根据一个字段查询\n- multi_match：根据多个字段查询，参与查询字段越多，查询性能越差\n\n### 精准查询\n\n精确查询一般是查找 keyword、数值、日期、boolean 等类型字段。所以不会对搜索条件分词。常见的有：\n\n- term：根据词条精确值查询\n- range：根据值的范围查询\n\n#### term 查询\n\n因为精确查询的字段搜是不分词的字段，因此查询的条件也必须是**不分词**的词条。查询时，用户输入的内容跟自动值完全匹配时才认为符合条件。如果用户输入的内容过多，反而搜索不到数据。\n\n语法说明：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"term\": {\n      \"FIELD\": {\n        \"value\": \"VALUE\"\n      }\n    }\n  }\n}\n```\n\n示例：\n\n当我搜索的是精确词条时，能正确查询出结果：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"city\": {\n        \"value\": \"上海\"\n      }\n    }\n  }\n}\n```\n\n但是，当我搜索的内容不是词条，而是多个词语形成的短语时，反而搜索不到：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"city\": {\n        \"value\": \"上海杭州\"\n      }\n    }\n  }\n}\n```\n\n#### range 查询\n\n范围查询，一般应用在对数值类型做范围过滤的时候。比如做价格范围过滤。\n\n基本语法：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"range\": {\n      \"FIELD\": {\n        \"gte\": 10,\n        \"lte\": 20\n      }\n    }\n  }\n}\n```\n\n+ gte 代表大于等于，gt 则代表大于\n+ lte 代表小于等于，lt 则代表小于\n\n示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"gte\": 1000,\n        \"lte\": 3000\n      }\n    }\n  }\n}\n```\n\n#### 精准查询小结\n\n精确查询常见的有哪些？\n\n- term 查询：根据词条精确匹配，一般搜索 keyword 类型、数值类型、布尔类型、日期类型字段\n- range 查询：根据数值范围查询，可以是数值、日期的范围\n\n### 地理坐标查询\n\n所谓的地理坐标查询，其实就是根据经纬度查询，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/geo-queries.html)\n\n常见的使用场景包括：\n\n- 携程：搜索我附近的酒店\n- 滴滴：搜索我附近的出租车\n- 微信：搜索我附近的人\n\n#### 矩形范围查询\n\n矩形范围查询，也就是 geo_bounding_box 查询，查询坐标落在某个矩形范围的所有文档：\n\n查询时，需要指定矩形的**左上**、**右下**两个点的坐标，然后画出一个矩形，落在该矩形内的都是符合条件的点。\n\n语法如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"geo_bounding_box\": {\n      \"FIELD\": {\n        \"top_left\": {\n          \"lat\": 31.1,\n          \"lon\": 121.5\n        },\n        \"bottom_right\": {\n          \"lat\": 30.9,\n          \"lon\": 121.7\n        }\n      }\n    }\n  }\n}\n```\n\n#### 附近查询\n\n附近查询，也叫做距离查询（geo_distance）：查询到指定中心点小于某个距离值的所有文档。\n\n换句话来说，在地图上找一个点作为圆心，以指定距离为半径，画一个圆，落在圆内的坐标都算符合条件：\n\n语法说明：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"15km\",\n      \"FIELD\": \"31.21,121.5\"\n    }\n  }\n}\n```\n\n我们先搜索陆家嘴附近 15km 的酒店：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"geo_distance\": {\n      \"distance\": \"2km\",\n      \"location\": \"31.21,121.5\"\n    }\n  }\n}\n```\n\n### 复合查询\n\n复合（compound）查询：复合查询可以将其它简单查询组合起来，实现更复杂的搜索逻辑。常见的有两种：\n\n- fuction score：算分函数查询，可以控制文档相关性算分，控制文档排名\n- bool query：布尔查询，利用逻辑关系组合多个其它的查询，实现复杂搜索\n\n#### 相关性算分\n\n当我们利用 match 查询时，文档结果会根据与搜索词条的关联度打分（_score），返回结果时按照分值降序排列。\n\n例如，我们搜索 \"虹桥如家\"，结果如下：\n\n```json\n[\n  {\n    \"_score\" : 17.850193,\n    \"_source\" : {\n      \"name\" : \"虹桥如家酒店真不错\",\n    }\n  },\n  {\n    \"_score\" : 12.259849,\n    \"_source\" : {\n      \"name\" : \"外滩如家酒店真不错\",\n    }\n  },\n  {\n    \"_score\" : 11.91091,\n    \"_source\" : {\n      \"name\" : \"迪士尼如家酒店真不错\",\n    }\n  }\n]\n```\n\n在 ElasticSearch 中，早期使用的打分算法是 [TF-IDF 算法](https://www.ruanyifeng.com/blog/2013/03/tf-idf.html)，在后来的 5.1 版本升级中，ElasticSearch 将算法改进为 [BM25 算法](https://www.jianshu.com/p/1e498888f505)\n\nTF-IDF 算法有一各缺陷，就是词条频率越高，文档得分也会越高，单个词条对文档影响较大。而 BM25 则会让单个词条的算分有一个上限，曲线更加平滑：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.32gad6dlyzu0.png)\n\n#### 算分函数查询\n\n根据相关度打分是比较合理的需求，但合理的不一定是产品经理需要的。\n\n以百度为例，你搜索的结果中，并不是相关度越高排名越靠前，而是谁掏的钱多排名就越靠前。要想认为控制相关性算分，就需要利用 ElasticSearch 中的 function score 查询了。\n\n语法说明：\n\n![算分函数查询](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/算分函数查询.epggagjz1ts.svg)\n\nfunction score 查询中包含四部分内容：\n\n- 原始查询条件：query 部分，基于这个条件搜索文档，并且基于 BM25 算法给文档打分，原始算分（query score)\n- 过滤条件：filter 部分，符合该条件的文档才会重新算分\n- 算分函数：符合 filter 条件的文档要根据这个函数做运算，得到的函数算分（function score），有四种函数\n  - weight：函数结果是常量\n  - field_value_factor：以文档中的某个字段值作为函数结果\n  - random_score：以随机数作为函数结果\n  - script_score：自定义算分函数算法\n- 运算模式：算分函数的结果、原始查询的相关性算分，两者之间的运算方式，包括：\n  - multiply：相乘\n  - replace：用 function score 替换 query score\n  - 其它，例如：sum、avg、max、min\n\nfunction score 的运行流程如下：\n\n- 根据原始条件查询搜索文档，并且计算相关性算分，称为原始算分（query score）\n- 根据过滤条件，过滤文档\n- 符合**过滤条件**的文档，基于算分函数运算，得到函数算分（function score）\n- 将原始算分（query score）和函数算分（function score）基于运算模式做运算，得到最终结果，作为相关性算分。\n\n因此，其中的关键点是：\n\n- 过滤条件：决定哪些文档的算分被修改\n- 算分函数：决定函数算分的算法\n- 运算模式：决定最终算分结果\n\n示例\n\n需求：给“如家”这个品牌的酒店排名靠前一些。翻译一下这个需求，转换为之前说的四个要点：\n\n- 原始条件：不确定，可以任意变化\n- 过滤条件：brand = \"如家\"\n- 算分函数：可以简单粗暴，直接给固定的算分结果，weight\n- 运算模式：比如求和\n\n因此最终的 DSL 语句如下：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": {\n          \"all\": \"外滩\"\n        }\n      },\n      \"functions\": [\n        {\n          \"filter\": {\n            \"term\": {\n              \"brand\": \"如家\"\n            }\n          },\n          \"weight\": 10\n        }\n      ],\n      \"boost_mode\": \"sum\"\n    }\n  }\n}\n```\n\n#### 布尔查询\n\n布尔查询是一个或多个查询子句的组合，每一个子句就是一个子查询。子查询的组合方式有：\n\n- must：必须匹配每个子查询，类似“与”\n- should：选择性匹配子查询，类似“或”\n- must_not：必须不匹配，**不参与算分**，类似“非”\n- filter：必须匹配，不参与算分\n\n比如在搜索酒店时，除了关键字搜索外，我们还可能根据品牌、价格、城市等字段做过滤。\n\n每一个不同的字段，其查询的条件、方式都不一样，必须是多个不同的查询，而要组合这些查询，就必须用 bool 查询了。\n\n需要注意的是，搜索时，参与打分的字段越多，查询的性能也越差。因此这种多条件查询时，建议这样做：\n\n- 搜索框的关键字搜索，是全文检索查询，使用 must 查询，参与算分\n- 其它过滤条件，采用 filter 查询。不参与算分\n\n语法示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": {\n            \"city\": \"上海\"\n          }\n        }\n      ],\n      \"should\": [\n        {\n          \"term\": {\n            \"brand\": \"皇冠假日\"\n          }\n        },\n        {\n          \"term\": {\n            \"brand\": \"华美达\"\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"range\": {\n            \"price\": {\n              \"lte\": 500\n            }\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"range\": {\n            \"score\": {\n              \"gte\": 45\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n案例示例：\n\n需求：搜索名字包含“如家”，价格不高于 400，在坐标 31.21,121.5 周围 10km 范围内的酒店。\n\n分析：\n\n- 名称搜索，属于全文检索查询，应该参与算分。放到 must 中\n- 价格不高于 400，用 range 查询，属于过滤条件，不参与算分。放到 must_not 中\n- 周围 10km 范围内，用 geo_distance 查询，属于过滤条件，不参与算分。放到 filter 中\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"match\": {\n            \"name\": \"如家\"\n          }\n        }\n      ],\n      \"must_not\": [\n        {\n          \"range\": {\n            \"price\": {\n              \"gt\": 400\n            }\n          }\n        }\n      ],\n      \"filter\": [\n        {\n          \"geo_distance\": {\n            \"distance\": \"10km\",\n            \"location\": {\n              \"lat\": 31.21,\n              \"lon\": 121.5\n            }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\nbool 查询有几种逻辑关系？\n\n- must：必须匹配的条件，可以理解为“与”\n- should：选择性匹配的条件，可以理解为“或”\n- must_not：必须不匹配的条件，不参与打分\n- filter：必须匹配的条件，不参与打分\n\n## DSL 搜索结果处理\n\n搜索的结果可以按照用户指定的方式去处理或展示。\n\n### 排序\n\nElasticSearch默认是根据相关度算分（_score）来排序，但是也支持自定义方式对搜索[结果排序](https://www.elastic.co/guide/en/elasticsearch/reference/current/sort-search-results.html)。可以排序字段类型有：keyword 类型、数值类型、地理坐标类型、日期类型等。\n\n#### 普通字段排序\n\nkeyword、数值、日期类型排序的语法基本一致。\n\n**语法**：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"FIELD\": \"desc\"  // 排序字段、排序方式ASC、DESC\n    }\n  ]\n}\n```\n\n排序条件是一个数组，也就是可以写多个排序条件。按照声明的顺序，当第一个条件相等时，再按照第二个条件排序，以此类推\n\n**示例**：\n\n需求描述：酒店数据按照用户评价（score）降序排序，评价相同的按照价格（price）升序排序\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"score\": \"desc\"\n    },\n    {\n      \"price\": \"asc\"\n    }\n  ]\n}\n```\n\n#### 地理坐标排序\n\n地理坐标排序略有不同。\n\n**语法说明**：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"_geo_distance\" : {\n          \"FIELD\" : \"纬度，经度\", // 文档中geo_point类型的字段名、目标坐标点\n          \"order\" : \"asc\", // 排序方式\n          \"unit\" : \"km\" // 排序的距离单位\n      }\n    }\n  ]\n}\n```\n\n这个查询的含义是：\n\n- 指定一个坐标，作为目标点\n- 计算每一个文档中，指定字段（必须是 geo_point 类型）的坐标到目标点的距离是多少\n- 根据距离排序\n\n**示例：**\n\n需求描述：实现对酒店数据按照到你的位置坐标的距离升序排序\n\n提示：获取经纬度的方式：https://lbs.amap.com/demo/jsapi-v2/example/map/click-to-get-lnglat/\n\n假设我的位置是：31.034661，121.612282，寻找我周围距离最近的酒店。\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"_geo_distance\": {\n        \"location\": {\n          \"lat\": 31.034661,\n          \"lon\": 121.612282\n        },\n        \"order\": \"asc\",\n        \"unit\": \"km\"\n      }\n    }\n  ]\n}\n```\n\n### 分页\n\nElasticSearch 默认情况下只返回 top10 的数据。而如果要查询更多数据就需要修改分页参数了。ElasticSearch中通过修改 from、size 参数来控制要返回的分页结果：\n\n- from：从第几个文档开始\n- size：总共查询几个文档\n\n类似于 MySQL 中的 `limit ?, ?`\n\n#### 基本的分页\n\n分页的基本语法如下：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"price\": {\n        \"order\": \"asc\"\n      }\n    }\n  ],\n  \"from\": 0,\n  \"size\": 5\n}\n```\n\n#### 深度分页问题\n\n现在，我要查询 990~1000 的数据，查询逻辑要这么写：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"from\": 990, // 分页开始的位置，默认为0\n  \"size\": 10, // 期望获取的文档总数\n  \"sort\": [\n    {\"price\": \"asc\"}\n  ]\n}\n```\n\n这里是查询 990 开始的数据，也就是 第 990~1000 条 数据。\n\n不过，ElasticSearch 内部分页时，必须先查询 0~1000 条，然后截取其中的 990 ~ 1000 的这 10 条：\n\n查询 top 1000，如果 ElasticSearch 是单点模式，这并无太大影响。\n\n但是 ElasticSearch 将来一定是集群，例如我集群有 5 个节点，我要查询 top 1000 的数据，并不是每个节点查询 200 条就可以了。\n\n因为节点 A 的 top 200，在另一个节点可能排到 10000 名以外了。\n\n因此要想获取整个集群的 top 1000，必须先查询出每个节点的 top 1000，汇总结果后，重新排名，重新截取 top 1000。\n\n那如果我要查询 9900~10000 的数据呢？是不是要先查询 top 10000呢？那每个节点都要查询 10000 条？汇总到内存中？\n\n当查询分页深度较大时，汇总数据过多，对内存和 CPU 会产生非常大的压力，因此 ElasticSearch 会禁止 from + size 超过 10000 的请求。\n\n针对深度分页，ElasticSearch 提供了两种解决方案，[官方文档](https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html)：\n\n- search after：分页时需要排序，原理是从上一次的排序值开始，查询下一页数据。官方推荐使用的方式。\n- scroll：原理将排序后的文档 id 形成快照，保存在内存。官方已经不推荐使用。\n\n#### 分页小结\n\n分页查询的常见实现方案以及优缺点：\n\n- `from + size`：\n  - 优点：支持随机翻页\n  - 缺点：深度分页问题，默认查询上限（from + size）是 10000\n  - 场景：百度、京东、谷歌、淘宝这样的随机翻页搜索\n- `after search`：\n  - 优点：没有查询上限（单次查询的 size 不超过 10000）\n  - 缺点：只能向后逐页查询，不支持随机翻页\n  - 场景：没有随机翻页需求的搜索，例如手机向下滚动翻页\n\n- `scroll`：\n  - 优点：没有查询上限（单次查询的 size 不超过 10000）\n  - 缺点：会有额外内存消耗，并且搜索结果是非实时的\n  - 场景：海量数据的获取和迁移。从 ES 7.1开始不推荐，建议用 after search 方案。\n\n### 高亮\n\n高亮显示的实现分为两步：\n\n- 给文档中的所有关键字都添加一个标签，例如 `<em>` 标签\n- 页面给 `<em>` 标签编写 CSS 样式\n\n高亮的语法：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"FIELD\": \"TEXT\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"FIELD\": {\n        \"pre_tags\": \"<em>\",\n        \"post_tags\": \"</em>\"\n      }\n    }\n  }\n}\n```\n\n**注意：**\n\n- 高亮是对关键字高亮，因此搜索条件必须带有关键字，而不能是范围这样的查询。\n- 默认情况下，高亮的字段，必须与搜索指定的字段一致，否则无法高亮\n- 如果要对非搜索字段高亮，则需要添加一个属性： `\"require_field_match\": \"false\"`\n\n示例：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"name\": {\n        \"require_field_match\": \"false\"\n      }\n    }\n  }\n}\n```\n\n### 搜索结果处理小结\n\n查询的 DSL 是一个大的 JSON 对象，包含下列属性：\n\n- query：查询条件\n- from 和 size：分页条件\n- sort：排序条件\n- highlight：高亮条件\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"name\": \"如家\"\n    }\n  },\n  \"from\": 0, // 分页开始的位置\n  \"size\": 20, // 期望获取的文档总数\n  \"sort\": [ \n    {  \"price\": \"asc\" }, // 普通排序\n    {\n      \"_geo_distance\" : { // 距离排序\n          \"location\" : \"31.040699,121.618075\", \n          \"order\" : \"asc\",\n          \"unit\" : \"km\"\n      }\n    }\n  ],\n  \"highlight\": {\n    \"fields\": { // 高亮字段\n      \"name\": {\n        \"pre_tags\": \"<em>\",  // 用来标记高亮字段的前置标签\n        \"post_tags\": \"</em>\" // 用来标记高亮字段的后置标签\n      }\n    }\n  }\n}\n```\n\n## Rest Client 查询文档\n\n文档的查询同样适用 RestHighLevelClient 对象，基本步骤包括：\n\n- 准备 Request 对象\n- 准备请求参数\n- 发起请求\n- 解析响应\n\n### 快速入门\n\n我们以 match_all 查询为例\n\n#### 发起查询请求\n\n```java\n@Test\nvoid testMatchAll() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.组织DSL参数\n    request.source().query(QueryBuilders.matchAllQuery());\n    // 3.发送请求，得到响应结果\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // ...解析响应结果\n}\n```\n\n代码解读：\n\n- 第一步，创建 `SearchRequest` 对象，指定索引库名\n\n- 第二步，利用 `request.source()` 构建 DSL，DSL 中可以包含查询、分页、排序、高亮等\n  - `query()`：代表查询条件，利用 `QueryBuilders.matchAllQuery()` 构建一个 match_all 查询的 DSL\n- 第三步，利用 `client.search()` 发送请求，得到响应\n\n这里关键的 API 有两个：\n\n+ 一个是 `request.source()`，其中包含了查询、排序、分页、高亮等所有功能。\n+ 另一个是 `QueryBuilders`，其中包含 match、term、function_score、bool 等各种查询：\n\n#### 解析响应\n\nElasticSearch 返回的结果是一个 JSON 字符串，结构包含：\n\n```json\n{\n   \"took\" : 0,\n   \"timed_out\" : false,\n   \"hits\" : {\n    \"total\" : {\n      \"value\" : 2,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : 1.0,\n    \"hits\" : [\n      {\n        \"_index\" : \"heima\",\n        \"_type\" : \"_doc\",\n        \"_id\" : \"1\",\n        \"_score\" : 1.0,\n        \"_source\" : {\n          \"info\" : \"Java讲师\", 	\"name\" : \"赵云\",\n       }\n      },\n      // ...\n    ]\n  }\n}\n```\n\n- `hits`：命中的结果\n  - `total`：总条数，其中的 value 是具体的总条数值\n  - `max_score`：所有结果中得分最高的文档的相关性算分\n  - `hits`：搜索结果的文档数组，其中的每个文档都是一个 JSON 对象\n    - `_source`：文档中的原始数据，也是 JSON 对象\n\n因此，我们解析响应结果，就是逐层解析 JSON 字符串，流程如下：\n\n```java\n@Test\nvoid testMatchAll() throws IOException {\n    // ... 略\n    // 4.解析结果\n    SearchHits searchHits = response.getHits();\n    // 4.1.查询的总条数\n    long total = searchHits.getTotalHits().value;\n    // 4.2.查询的结果数组\n    SearchHit[] hits = searchHits.getHits();\n    for (SearchHit hit : hits) {\n        // 4.3.得到source\n        String json = hit.getSourceAsString();\n        // 4.4.打印\n        System.out.println(json);\n    }\n}\n```\n\n- `SearchHits`：通过 `response.getHits()` 获取，就是 JSON 中的最外层的hits，代表命中的结果\n  - `SearchHits#getTotalHits().value`：获取总条数信息\n  - `SearchHits#getHits()`：获取 SearchHit 数组，也就是文档数组\n    - `SearchHit#getSourceAsString()`：获取文档结果中的_source，也就是原始的 JSON 文档数据\n\n#### 完整代码\n\n```java\n    @Test\n    void testMatchAll() throws IOException {\n        // 1.准备 Request\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.组织 DSL 参数\n        request.source().query(QueryBuilders.matchAllQuery());\n        // 3.发送请求，得到响应结果\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.解析结果\n        SearchHits searchHits = response.getHits();\n        // 4.1.查询的总条数\n        long total = searchHits.getTotalHits().value;\n        System.err.println(\"total = \" + total);\n        // 4.2.查询的结果数组\n        SearchHit[] hits = searchHits.getHits();\n        for (SearchHit hit : hits) {\n            // 4.3.得到source\n            String json = hit.getSourceAsString();\n            // 反序列化\n            HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n            // 4.4.打印\n            System.out.println(hotelDoc);\n        }\n    }\n```\n\n#### 快速入门小结\n\n查询的基本步骤是：\n\n1. 创建 SearchRequest 对象\n2. 准备 `Request.source()`，也就是 DSL。\n   + QueryBuilders 来构建查询条件\n   + 传入 `Request.source()` 的 `query()` 方法\n3. 发送请求，得到结果\n4. 解析结果（参考 JSON 结果，从外到内，逐层解析）\n\n### match 查询\n\n全文检索的 match 和 multi_match 查询与 match_all 的 API 基本一致。差别是查询条件，也就是 query 的部分。\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家\"\n    }\n  }\n}\n\nGET /hotel/_search\n{\n  \"query\": {\n    \"multi_match\": {\n      \"query\": \"如家\",\n      \"fields\": [\"brand\", \"name\"]\n    }\n  }\n}\n```\n\n因此，Java 代码上的差异主要是 `request.source().query()` 中的参数了。同样是利用 QueryBuilders 提供的方法：\n\n```java\n// 单字段查询\nQueryBuilders.matchQuery(\"all\", \"如家\");\n// 多字段查询\nQueryBuilders.multiMatchQuery(\"如家\", \"name\", \"business\");\n```\n\n而结果解析代码则完全一致，可以抽取并共享。\n\n完整代码如下：\n\n```java\n@Test\nvoid testMatch() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    request.source().query(QueryBuilders.matchQuery(\"all\", \"如家\"));\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n> IDEA 代码抽取 Ctrl + Alt + M\n\n### 精确查询\n\n精确查询主要是两者：\n\n- term：词条精确匹配\n- range：范围查询\n\n与之前的查询相比，差异同样在查询条件，其它都一样。\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"term\": {\n      \"city\": \"杭州\"\n    }\n  }\n}\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": { \"gte\": 100, \"lte\": 150 }\n    }\n  }\n}\n```\n\n查询条件构造的 API 如下：\n\n```java\n// 词条查询\nQueryBuilders.termQuery(\"city\", \"杭州\"); \n// 范围查询\nQueryBuilders.rangeQuery(\"price\").gte(100).lte(150);\n```\n\n### 布尔查询\n\n布尔查询是用 must、must_not、filter 等方式组合其它查询，代码示例如下：\n\n```java\n// 创建布尔查询\nBoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n// 添加must条件\nboolQuery.must(QueryBuilders.termQuery(\"city\", \"杭州\")); \n// 添加filter条件\nboolQuery.filter(QueryBuilders.rangeQuery(\"price\").lte(250));\n```\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"bool\": {\n      \"must\": [\n        {\n          \"term\": { \"city\": \"杭州\" }\n        }\n      ],\n      \"filter\": [\n        {\n          \"range\": {\n            \"price\": { \"lte\": 250 }\n          }\n        }\n      ]\n    }\n  }\n}\n```\n\n可以看到，API 与其它查询的差别同样是在查询条件的构建，QueryBuilders，结果解析等其他代码完全不变。\n\n示例代码：\n\n```java\n@Test\nvoid testBool() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    \n    // 2.准备DSL\n    // 2.1.准备BooleanQuery\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    // 2.2.添加term\n    boolQuery.must(QueryBuilders.termQuery(\"city\", \"上海\"));\n    // 2.3.添加range\n    boolQuery.filter(QueryBuilders.rangeQuery(\"price\").lte(250));\n    \n    request.source().query(boolQuery);\n    \n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    \n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n\n\n## Rest Client 搜索结果处理\n\n### 排序与分页\n\n搜索结果的排序和分页是与 query 同级的参数，因此同样是使用 `request.source()` 来设置。\n\n对应的 API 如下：\n\n```java\n// 查询 \nrequest.source().query(QueryBuilders.matchAllQuery());\n// 排序\nrequest.source().sort(\"price\", SortOrder.ASC);\n// 分页\nrequest.source().from(0).size(5);\n```\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"from\": 0,\n  \"size\": 5, \n  \"sort\": [\n    {\n      \"FIELD\": \"desc\"  \n    },\n  ]\n}\n```\n\n代码示例：\n\n```java\n@Test\nvoid testPageAndSort() throws IOException {\n    // 页码，每页大小\n    int page = 1, size = 5;\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    // 2.1.query\n    request.source().query(QueryBuilders.matchAllQuery());\n    // 2.2.排序 sort\n    request.source().sort(\"price\", SortOrder.ASC);\n    // 2.3.分页 from、size\n    request.source().from((page - 1) * size).size(size);\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n### 高亮\n\n高亮的代码与之前代码差异较大，有两点：\n\n- 查询的 DSL：其中除了查询条件，还需要添加高亮条件，同样是与 query 同级。\n- 结果解析：结果除了要解析 _source 文档数据，还要解析高亮结果\n\n#### 高亮请求构建\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match\": {\n      \"all\": \"如家\"\n    }\n  },\n  \"highlight\": {\n    \"fields\": {\n      \"name\": {\n        \"require_field_match\": \"false\"\n      }\n    }\n  }\n}\n```\n\n高亮请求的构建 API 如下：\n\n```java\nrequest.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false));\n```\n\n上述代码省略了查询条件部分，但是大家不要忘了：高亮查询必须使用全文检索查询，并且要有搜索关键字，将来才可以对关键字高亮。\n\n示例代码如下：\n\n```java\n@Test\nvoid testHighlight() throws IOException {\n    // 1.准备Request\n    SearchRequest request = new SearchRequest(\"hotel\");\n    // 2.准备DSL\n    // 2.1.query\n    request.source().query(QueryBuilders.matchQuery(\"all\", \"如家\"));\n    // 2.2.高亮\n    request.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false));\n    // 3.发送请求\n    SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n    // 4.解析响应\n    handleResponse(response);\n}\n```\n\n#### 高亮结果解析\n\n高亮的结果与查询的文档结果默认是分离的，并不在一起。\n\n```json\n{\n  \"_index\" : \"hotel\",\n  \"_type\" : \"_doc\",\n  \"_id\" : \"339952837\",\n  \"_score\" : 2.8947515,\n  \"_source\" : {\n    \"id\" : 339952837,\n    \"name\" : \"如家酒店(北京良乡西路店)\",\n    \"price\" : 159,\n    \"score\" : 46,\n    \"brand\" : \"如家\",\n    \"city\" : \"北京\",\n    \"location\" : \"39.73167, 116.132482\",\n    \"pic\" : \"t0.jpg\"\n  },\n  \"highlight\" : {\n    \"name\" : [\n      \"<em>如家</em>酒店(北京良乡西路店)\",\n    ]\n  }\n}\n```\n\n因此解析高亮的代码需要额外处理：\n\n```java\n// 获取source\nHotelDoc hotelDoc = JSON.parseObject(hit.getSourceAsString(), HotelDoc.class);\n// 处理高亮\nMap<String, HighlightField> highlightFields = hit.getHighlightFields();\nif (!CollectionUtils.isEmpty(highlightFields)) {\n    // 获取高亮字段结果\n    HighlightField highlightField = highlightFields.get(\"name\");\n    if (highlightField != null) {\n        // 取出高亮结果数组中的第一个，就是酒店名称\n        String name = highlightField.getFragments()[0].string();\n        hotelDoc.setName(name);\n    }\n}\n```\n\n代码解读：\n\n- 第一步：从结果中获取 source。`hit.getSourceAsString()`，这部分是非高亮结果，JSON 字符串。还需要反序列为 HotelDoc 对象\n- 第二步：获取高亮结果。`hit.getHighlightFields()`，返回值是一个 Map，key 是高亮字段名称，值是 HighlightField 对象，代表高亮值\n- 第三步：从 Map 中根据高亮字段名称，获取高亮字段值对象HighlightField\n- 第四步：从HighlightField 中获取 Fragments，并且转为字符串。这部分就是真正的高亮字符串了\n- 第五步：用高亮的结果替换 HotelDoc 中的非高亮结果\n\n## 酒店搜索案例\n\n下面，我们通过酒店搜索案例来实战演练下之前学习的知识。\n\n我们实现四部分功能：\n\n- 酒店搜索和分页\n- 酒店结果过滤\n- 我周边的酒店\n- 酒店竞价排名\n\n启动 hotel-demo 项目，其默认端口是 8089，访问 http://localhost:8090，就能看到项目页面了。\n\n### 酒店搜索和分页\n\n案例需求：实现黑马旅游的酒店搜索功能，完成关键字搜索和分页\n\n#### 需求分析\n\n- 请求方式：POST\n- 请求路径：/hotel/list\n- 请求参数：JSON 对象，包含4个字段：\n  - key：搜索关键字\n  - page：页码\n  - size：每页大小\n  - sortBy：排序，目前暂不实现\n- 返回值：分页查询，需要返回分页结果 PageResult，包含两个属性：\n  - `total`：总条数\n  - `List<HotelDoc>`：当前页的数据\n\n因此，我们实现业务的流程如下：\n\n- 步骤一：定义实体类，接收请求参数的 JSON 对象\n- 步骤二：编写 controller，接收页面的请求\n- 步骤三：编写业务实现，利用 RestHighLevelClient 实现搜索、分页\n\n#### 定义实体类\n\n实体类有两个，一个是前端的请求参数实体，一个是服务端应该返回的响应结果实体。\n\n① 请求参数，前端请求的 JSON 结构如下：\n\n```json\n{\n    \"key\": \"搜索关键字\",\n    \"page\": 1,\n    \"size\": 3,\n    \"sortBy\": \"default\"\n}\n```\n\n因此，我们在 `cn.itcast.hotel.pojo` 包下定义一个实体类：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\n\n@Data\npublic class RequestParams {\n    private String key;\n    private Integer page;\n    private Integer size;\n    private String sortBy;\n}\n```\n\n② 返回值，分页查询，需要返回分页结果 PageResult，包含两个属性：\n\n- `total` ：总条数\n- `List<HotelDoc>` ：当前页的数据\n\n因此，我们在 `cn.itcast.hotel.pojo` 中定义返回结果：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\n\nimport java.util.List;\n\n@Data\npublic class PageResult {\n    private Long total;\n    private List<HotelDoc> hotels;\n\n    public PageResult() {\n    }\n\n    public PageResult(Long total, List<HotelDoc> hotels) {\n        this.total = total;\n        this.hotels = hotels;\n    }\n}\n```\n\n#### 定义 controller\n\n定义一个 HotelController，声明查询接口，满足下列要求：\n\n- 请求方式：Post\n- 请求路径：/hotel/list\n- 请求参数：对象，类型为 RequestParam\n- 返回值：PageResult，包含两个属性\n  - `Long total`：总条数\n  - `List<HotelDoc> hotels`：酒店数据\n\n因此，我们在 `cn.itcast.hotel.web` 中定义 HotelController：\n\n```java\n@RestController\n@RequestMapping(\"/hotel\")\npublic class HotelController {\n\n    @Autowired\n    private IHotelService hotelService;\n	// 搜索酒店数据\n    @PostMapping(\"/list\")\n    public PageResult search(@RequestBody RequestParams params){\n        return hotelService.search(params);\n    }\n}\n```\n\n#### 实现搜索业务\n\n我们在 controller 调用了 IHotelService，并没有实现该方法，因此下面我们就在 IHotelService 中定义方法，并且去实现业务逻辑。\n\n① 在 `cn.itcast.hotel.service` 中的 `IHotelService` 接口中定义一个方法：\n\n```java\n/**\n * 根据关键字搜索酒店信息\n * @param params 请求参数对象，包含用户输入的关键字 \n * @return 酒店文档列表\n */\nPageResult search(RequestParams params);\n```\n\n② 实现搜索业务，肯定离不开 RestHighLevelClient，我们需要把它注册到 Spring 中作为一个 Bean。在 `cn.itcast.hotel` 中的 `HotelDemoApplication` 中声明这个 Bean：\n\n```java\n@Bean\npublic RestHighLevelClient client() {\n    return new RestHighLevelClient(RestClient.builder(HttpHost.create(\"http://halo:9200\")));\n}\n```\n\n③ 在 `cn.itcast.hotel.service.impl` 中的 `HotelService` 中实现 search 方法：\n\n```java\n@Autowired\nprivate RestHighLevelClient client;\n\n@Override\npublic PageResult search(RequestParams params) {\n    try {\n        // 1.准备Request\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.准备DSL\n        // 2.1.query\n        String key = params.getKey();\n        if (key == null || \"\".equals(key)) {\n            request.source().query(QueryBuilders.matchAllQuery());\n        } else {\n            request.source().query(QueryBuilders.matchQuery(\"all\", key));\n        }\n\n        // 2.2.分页\n        int page = params.getPage();\n        int size = params.getSize();\n        request.source().from((page - 1) * size).size(size);\n\n        // 3.发送请求\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.解析响应\n        return handleResponse(response);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\n// 结果解析\nprivate PageResult handleResponse(SearchResponse response) {\n    // 4.解析响应\n    SearchHits searchHits = response.getHits();\n    // 4.1.获取总条数\n    long total = searchHits.getTotalHits().value;\n    // 4.2.文档数组\n    SearchHit[] hits = searchHits.getHits();\n    // 4.3.遍历\n    List<HotelDoc> hotels = new ArrayList<>();\n    for (SearchHit hit : hits) {\n        // 获取文档source\n        String json = hit.getSourceAsString();\n        // 反序列化\n        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n        // 放入集合\n        hotels.add(hotelDoc);\n    }\n    // 4.4.封装返回\n    return new PageResult(total, hotels);\n}\n```\n\n### 酒店结果过滤\n\n需求：添加品牌、城市、星级、价格等过滤功能\n\n#### 需求分析\n\n包含的过滤条件有：\n\n- brand：品牌值\n- city：城市\n- minPrice~maxPrice：价格范围\n- starName：星级\n\n我们需要做两件事情：\n\n- 修改请求参数的对象 RequestParams，接收上述参数\n- 修改业务逻辑，在搜索条件之外，添加一些过滤条件\n\n#### 修改实体类\n\n修改在 `cn.itcast.hotel.pojo` 包下的实体类 RequestParams：\n\n```java\n@Data\npublic class RequestParams {\n    private String key;\n    private Integer page;\n    private Integer size;\n    private String sortBy;\n    // 下面是新增的过滤条件参数\n    private String city;\n    private String brand;\n    private String starName;\n    private Integer minPrice;\n    private Integer maxPrice;\n}\n```\n\n#### 修改搜索业务\n\n在 HotelService 的 search 方法中，只有一个地方需要修改：`requet.source().query( ... )` 其中的查询条件。\n\n在之前的业务中，只有 match 查询，根据关键字搜索，现在要添加条件过滤，包括：\n\n- 品牌过滤：是 keyword 类型，用 term 查询\n- 星级过滤：是 keyword 类型，用 term 查询\n- 价格过滤：是数值类型，用 range 查询\n- 城市过滤：是 keyword 类型，用 term 查询\n\n多个查询条件组合，肯定是 boolean 查询来组合：\n\n- 关键字搜索放到 must 中，参与算分\n- 其它过滤条件放到 filter 中，不参与算分\n\n因为条件构建的逻辑比较复杂，这里封装为一个函数，getBoolQueryBuilder 的代码如下：\n\n```java\nprivate BoolQueryBuilder getBoolQueryBuilder(RequestParams params) {\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    String key = params.getKey();\n    if (key == null || \"\".equals(key)) {\n        boolQuery.must(QueryBuilders.matchAllQuery());\n    } else {\n        boolQuery.must(QueryBuilders.matchQuery(\"all\", key));\n    }\n    // 条件过滤\n    // 城市条件\n    if (params.getCity() != null && !params.getCity().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"city\", params.getCity()));\n    }\n    // 品牌条件\n    if (params.getBrand() != null && !params.getBrand().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"brand\", params.getBrand()));\n    }\n    // 星级\n    if (params.getStarName() != null && !params.getStarName().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"starName\", params.getStarName()));\n    }\n    // 价格\n    if (params.getMinPrice() != null && params.getMaxPrice() != null) {\n        boolQuery.filter(QueryBuilders.rangeQuery(\"price\")\n                         .gte(params.getMinPrice()).lte(params.getMaxPrice()));\n    }\n    return boolQuery;\n}\n```\n\n### 我周边的酒店\n\n需求：我附近的酒店\n\n#### 需求分析\n\n在酒店列表页的右侧，有一个小地图，点击地图的定位按钮，地图会找到你所在的位置，并且，在前端会发起查询请求，将你的坐标发送到服务端。\n\n我们要做的事情就是基于这个 location 坐标，然后按照距离对周围酒店排序。实现思路如下：\n\n- 修改 RequestParams 参数，接收 location 字段\n- 修改 search 方法业务逻辑，如果 location 有值，添加根据 geo_distance 排序的功能\n\n#### 修改实体类\n\n修改在 `cn.itcast.hotel.pojo` 包下的实体类 RequestParams：\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\n\n@Data\npublic class RequestParams {\n    private String key;\n    private Integer page;\n    private Integer size;\n    private String sortBy;\n    private String city;\n    private String brand;\n    private String starName;\n    private Integer minPrice;\n    private Integer maxPrice;\n    // 我当前的地理坐标\n    private String location;\n}\n```\n\n#### 距离排序 API\n\n我们以前学习过排序功能，包括两种：\n\n- 普通字段排序\n- 地理坐标排序\n\n我们只讲了普通字段排序对应的 Java 写法。地理坐标排序只学过 DSL 语法，如下：\n\n```json\nGET /indexName/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  },\n  \"sort\": [\n    {\n      \"price\": \"asc\"  \n    },\n    {\n      \"_geo_distance\" : {\n          \"FIELD\" : \"纬度，经度\",\n          \"order\" : \"asc\",\n          \"unit\" : \"km\"\n      }\n    }\n  ]\n}\n```\n\n对应 Java 代码\n\n```java\n// 价格排序\nrequest.source().sort(\"price\", SortOrder.ASC);\n// 距离排序\nrequest.source().sort(SortBuilders.geoDistanceSort(\"location\", new GeoPoint(\"31.21, 121.5\"))\n                      .order(SortOrder.ASC).unit(DistanceUnit.KILOMETERS));\n```\n\n#### 添加距离排序\n\n在 `cn.itcast.hotel.service.impl` 的 `HotelService` 的 `search` 方法中，添加一个排序功能：\n\n```java\n@Override\npublic PageResult search(RequestParams params) {\n    try {\n        // 1.准备Request\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.准备DSL\n        // 2.1.query\n        // 构建 boolQuery\n        BoolQueryBuilder boolQuery = getBoolQueryBuilder(params);\n        request.source().query(boolQuery);\n\n        // 2.2.分页\n        int page = params.getPage();\n        int size = params.getSize();\n        request.source().from((page - 1) * size).size(size);\n\n        // 排序\n        String location = params.getLocation();\n        if (location != null && !location.equals(\"\")) {\n            request.source().sort(SortBuilders\n                                  .geoDistanceSort(\"location\", new GeoPoint(location))\n                                  .order(SortOrder.ASC)\n                                  .unit(DistanceUnit.KILOMETERS));\n        }\n\n        // 3.发送请求\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.解析响应\n        return handleResponse(response);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n#### 排序距离显示\n\n排序完成后，页面还要获取我附近每个酒店的具体**距离**值，这个值在响应结果中是独立的：\n\n因此，我们在结果解析阶段，除了解析 source 部分以外，还要得到 sort 部分，也就是排序的距离，然后放到响应结果中。\n\n我们要做两件事：\n\n- 修改 HotelDoc，添加排序距离字段，用于页面显示\n- 修改 HotelService 类中的 handleResponse 方法，添加对 sort 值的获取\n\n① 修改HotelDoc类，添加距离字段\n\n```java\npackage cn.itcast.hotel.pojo;\n\nimport lombok.Data;\nimport lombok.NoArgsConstructor;\n\n\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n    // 排序时的 距离值\n    private Object distance;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n\n② 修改 HotelService 中的 handleResponse 方法\n\n```java\n// 结果解析\nprivate PageResult handleResponse(SearchResponse response) {\n    // 4.解析响应\n    SearchHits searchHits = response.getHits();\n    // 4.1.获取总条数\n    long total = searchHits.getTotalHits().value;\n    // 4.2.文档数组\n    SearchHit[] hits = searchHits.getHits();\n    // 4.3.遍历\n    List<HotelDoc> hotels = new ArrayList<>();\n    for (SearchHit hit : hits) {\n        // 获取文档source\n        String json = hit.getSourceAsString();\n        // 反序列化\n        HotelDoc hotelDoc = JSON.parseObject(json, HotelDoc.class);\n        // 获取排序值 - location\n        Object[] sortValues = hit.getSortValues();\n        if (sortValues.length > 0) {\n            Object sortValue = sortValues[0];\n            hotelDoc.setDistance(sortValue);\n        }\n\n        // 放入集合\n        hotels.add(hotelDoc);\n    }\n    // 4.4.封装返回\n    return new PageResult(total, hotels);\n}\n```\n\n### 酒店竞价排名\n\n需求：让指定的酒店在搜索结果中排名置顶\n\n#### 需求分析\n\n要让指定酒店在搜索结果中排名置顶，页面会给指定的酒店添加**广告**标记。\n\n我们之前学习过的 function_score 查询可以影响算分，算分高了，自然排名也就高了。而 function_score 包含 3 个要素：\n\n- 过滤条件：哪些文档要加分\n- 算分函数：如何计算 function score\n- 加权方式：function score 与 query score 如何运算\n\n这里的需求是：让**指定酒店**排名靠前。因此我们需要给这些酒店添加一个标记，这样在过滤条件中就可以根据这个标记来判断，是否要提高算分。\n\n比如，我们给酒店添加一个字段：isAD，Boolean 类型：\n\n- true：是广告\n- false：不是广告\n\n这样 function_score 包含 3 个要素就很好确定了：\n\n- 过滤条件：判断 isAD 是否为 true\n- 算分函数：我们可以用最简单暴力的 weight，固定加权值\n- 加权方式：可以用默认的相乘，大大提高算分\n\n因此，业务的实现步骤包括：\n\n1. 给 HotelDoc 类添加 isAD 字段，Boolean 类型\n\n2. 挑选几个你喜欢的酒店，给它的文档数据添加 isAD 字段，值为 true\n\n3. 修改 search方法，添加 function score 功能，给 isAD 值为 true 的酒店增加权重\n\n#### 修改 HotelDoc 实体\n\n给 `cn.itcast.hotel.pojo` 包下的 HotelDoc 类添加 isAD 字段：\n\n```java\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n    // 排序时的距离值\n    private Object distance;\n    private Boolean isAD;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n    }\n}\n```\n\n#### 添加广告标记\n\n用 DSL 添加酒店广告标记\n\n```java\nPOST /hotel/_update/36934\n{\n  \"doc\": {\n    \"isAD\": true\n  }\n}\n```\n\n#### 添加算分函数查询\n\n接下来我们就要修改查询条件了。之前是用的 boolean 查询，现在要改成 function_socre 查询。\n\nfunction_score 查询结构如下：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"function_score\": {\n      \"query\": {\n        \"match\": {\n          \"name\": \"外滩\"\n        }\n      },\n      \"functions\": [ \n        {\n          \"filter\": {\n            \"term\": {\n              \"brand\": \"如家\"\n            }\n          },\n          \"weight\": 5\n        }\n      ]\n    }\n  }\n}\n```\n\n对应的 JavaAPI 如下\n\n```java\nFunctionScoreQueryBuilder functionScoreQueryBuilder = \n    QueryBuilders.functionScoreQuery(\n        QueryBuilders.matchQuery(\"name\", \"外滩\"),\n        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{\n            new FunctionScoreQueryBuilder.FilterFunctionBuilder(\n                QueryBuilders.termQuery(\"brand\", \"如家\"), \n                ScoreFunctionBuilders.weightFactorFunction(5)\n            )\n        }\n	);\nsourceBuilder.query(functionScoreQueryBuilder);\n```\n\n我们可以将之前写的 boolean 查询作为**原始查询**条件放到 query 中，接下来就是添加过滤条件、算分函数、加权模式了。所以原来的代码依然可以沿用。\n\n修改 `cn.itcast.hotel.service.impl` 包下的 `HotelService` 类中的 `getQueryBuilder` 方法，添加算分函数查询：\n\n```java\nprivate FunctionScoreQueryBuilder getQueryBuilder(RequestParams params) {\n    BoolQueryBuilder boolQuery = QueryBuilders.boolQuery();\n    String key = params.getKey();\n    if (key == null || \"\".equals(key)) {\n        boolQuery.must(QueryBuilders.matchAllQuery());\n    } else {\n        boolQuery.must(QueryBuilders.matchQuery(\"all\", key));\n    }\n    // 条件过滤\n    // 城市条件\n    if (params.getCity() != null && !params.getCity().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"city\", params.getCity()));\n    }\n    // 品牌条件\n    if (params.getBrand() != null && !params.getBrand().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"brand\", params.getBrand()));\n    }\n    // 星级\n    if (params.getStarName() != null && !params.getStarName().equals(\"\")) {\n        boolQuery.filter(QueryBuilders.termQuery(\"starName\", params.getStarName()));\n    }\n    // 价格\n    if (params.getMinPrice() != null && params.getMaxPrice() != null) {\n        boolQuery.filter(QueryBuilders.rangeQuery(\"price\")\n                         .gte(params.getMinPrice()).lte(params.getMaxPrice()));\n    }\n\n    // 算分控制\n    FunctionScoreQueryBuilder functionScoreQueryBuilder =\n        QueryBuilders.functionScoreQuery(\n        // 原始查询，相关性算分\n        boolQuery,\n        // function score\n        new FunctionScoreQueryBuilder.FilterFunctionBuilder[]{\n            // 一个 function score 元素\n            new FunctionScoreQueryBuilder.FilterFunctionBuilder(\n                // 过滤条件\n                QueryBuilders.termQuery(\"isAD\", true),\n                // 算分函数\n                ScoreFunctionBuilders.weightFactorFunction(10)\n            )\n        });\n\n    return functionScoreQueryBuilder;\n}\n```\n\n## 数据聚合\n\n[聚合](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations.html)（aggregation） 可以让我们极其方便的实现对数据的统计、分析、运算。例如：\n\n- 什么品牌的手机最受欢迎？\n- 这些手机的平均价格、最高价格、最低价格？\n- 这些手机每月的销售情况如何？\n\n实现这些统计功能的比数据库的 SQL 要方便的多，而且查询速度非常快，可以实现近实时搜索效果。\n\n### 聚合的种类\n\n聚合常见的有三类：\n\n- 桶（Bucket）聚合：用来对文档做分组\n  - TermAggregation：按照文档字段值分组，例如按照品牌值分组、按照国家分组\n  - Date Histogram：按照日期阶梯分组，例如一周为一组，或者一月为一组\n\n- 度量（Metric）聚合：用以计算一些值，比如：最大值、最小值、平均值等\n  - Avg：求平均值\n  - Max：求最大值\n  - Min：求最小值\n  - Stats：同时求 max、min、avg、sum 等\n- 管道（pipeline）聚合：其它聚合的结果为基础做聚合\n\n> **注意：**参加聚合的字段必须是 keyword、日期、数值、布尔类型\n\n### DSL 实现聚合\n\n现在，我们要统计所有数据中的酒店品牌有几种，其实就是按照品牌对数据分组。\n\n此时可以根据酒店品牌的名称做聚合，也就是 Bucket 聚合。\n\n#### Bucket 聚合语法\n\n语法如下：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0,  // 设置 size 为 0，结果中不包含文档，只包含聚合结果\n  \"aggs\": { // 定义聚合\n    \"brandAgg\": { //给聚合起个名字\n      \"terms\": { // 聚合的类型，按照品牌值聚合，所以选择term\n        \"field\": \"brand\", // 参与聚合的字段\n        \"size\": 5 // 希望获取的聚合结果数量\n      }\n    }\n  }\n}\n```\n\n结果如下：\n\n```json\n{\n  \"took\" : 36,\n  \"timed_out\" : false,\n  \"_shards\" : {\n    \"total\" : 1,\n    \"successful\" : 1,\n    \"skipped\" : 0,\n    \"failed\" : 0\n  },\n  \"hits\" : {\n    \"total\" : {\n      \"value\" : 201,\n      \"relation\" : \"eq\"\n    },\n    \"max_score\" : null,\n    \"hits\" : [ ]\n  },\n  \"aggregations\" : {\n    \"brandAgg\" : {\n      \"doc_count_error_upper_bound\" : 0,\n      \"sum_other_doc_count\" : 96,\n      \"buckets\" : [\n        {\n          \"key\" : \"7天酒店\",\n          \"doc_count\" : 30\n        },\n        {\n          \"key\" : \"如家\",\n          \"doc_count\" : 30\n        },\n        {\n          \"key\" : \"皇冠假日\",\n          \"doc_count\" : 17\n        },\n        {\n          \"key\" : \"速8\",\n          \"doc_count\" : 15\n        },\n        {\n          \"key\" : \"万怡\",\n          \"doc_count\" : 13\n        }\n      ]\n    }\n  }\n}\n```\n\n#### 聚合结果排序\n\n默认情况下，Bucket 聚合会统计 Bucket 内的文档数量，记为 `_count`，并且按照 `_count` 降序排序。\n\n我们可以指定 order 属性，自定义聚合的排序方式：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"order\": {\n          \"_count\": \"asc\" // 按照 _count 升序排列\n        }, \n        \"size\": 5\n      }\n    }\n  }\n}\n```\n\n#### 限定聚合范围\n\n默认情况下，Bucket 聚合是对索引库的所有文档做聚合，但真实场景下，用户会输入搜索条件，因此聚合必须是对搜索结果聚合。那么聚合必须添加限定条件。\n\n我们可以限定要聚合的文档范围，只要添加 query 条件即可：\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"range\": {\n      \"price\": {\n        \"lte\": 200 // 只对200元以下的文档聚合\n      }\n    }\n  }, \n  \"size\": 0,\n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"size\": 5\n      }\n    }\n  }\n}\n```\n\n#### Metric 聚合语法\n\n现在我们需要对桶内的酒店做运算，获取每个品牌的用户评分的 min、max、avg 等值。\n\n这就要用到 Metric 聚合了，例如 stats 聚合：就可以获取 min、max、avg 等结果。\n\n语法如下：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0, \n  \"aggs\": {\n    \"brandAgg\": { \n      \"terms\": { \n        \"field\": \"brand\", \n        \"size\": 5\n      },\n      \"aggs\": { // 是brands聚合的子聚合，也就是分组后对每组分别计算\n        \"score_stats\": { // 聚合名称\n          \"stats\": { // 聚合类型，这里stats可以计算min、max、avg等\n            \"field\": \"score\" // 聚合字段，这里是score\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n这次的 score_stats 聚合是在 brandAgg 的聚合内部嵌套的子聚合。因为我们需要在每个桶分别计算。\n\n另外，我们还可以给聚合结果做个排序：\n\n```json\nGET /hotel/_search\n{\n  \"size\": 0,\n  \"aggs\": {\n    \"brandAgg\": {\n      \"terms\": {\n        \"field\": \"brand\",\n        \"size\": 5,\n        \"order\": {\n          \"scoreAgg.avg\": \"desc\"\n        }\n      },\n      \"aggs\": {\n        \"scoreAgg\": {\n          \"stats\": {\n            \"field\": \"score\"\n          }\n        }\n      }\n    }\n  }\n}\n```\n\n#### DSL 实现聚合小结\n\naggs 代表聚合，与 query 同级，此时 query 的作用是？\n\n- 限定聚合的的文档范围\n\n聚合必须的三要素：\n\n- 聚合名称\n- 聚合类型\n- 聚合字段\n\n聚合可配置属性有：\n\n- size：指定聚合结果数量\n- order：指定聚合结果排序方式\n- field：指定聚合字段\n\n### Rest Client 实现聚合\n\n#### API 语法\n\n聚合条件与 query 条件同级别，因此需要使用 `request.source()` 来指定聚合条件。\n\n聚合条件的语法：\n\n```java\nrequest.source().size(0);\nrequest.source().aggregation(\n    AggregationBuilders\n    .terms(\"brand_agg\")\n    .field(\"brand\")\n    .size(20)\n);\n```\n\n聚合的结果也与查询结果不同，API 也比较特殊。不过同样是 JSON 逐层解析：\n\n```java\n// 4. 解析结果\n// 4.1 获取 aggregations\nAggregations aggregations = response.getAggregations();\n// 4.2 根据名称获取聚合结果\nTerms brandTerms = aggregations.get(\"brandAgg\");\n// 4.3 获取 buckets 并遍历\nfor (Terms.Bucket bucket : brandTerms.getBuckets()) {\n    // 获取 key\n    String key = bucket.getKeyAsString();\n    System.out.println(key);\n}\n```\n\n#### 业务需求\n\n需求：搜索页面的品牌、城市等信息不应该是在页面写死，而是通过聚合索引库中的酒店数据得来的\n\n分析：目前，页面的城市列表、星级列表、品牌列表都是写死的，并不会随着搜索结果的变化而变化。但是用户搜索条件改变时，搜索结果会跟着变化。\n\n例如：用户搜索“东方明珠”，那搜索的酒店肯定是在上海东方明珠附近，因此，城市只能是上海，此时城市列表中就不应该显示北京、深圳、杭州这些信息了。也就是说，搜索结果中包含哪些城市，页面就应该列出哪些城市；搜索结果中包含哪些品牌，页面就应该列出哪些品牌。\n\n如何得知搜索结果中包含哪些品牌？如何得知搜索结果中包含哪些城市？\n\n使用聚合功能，利用 Bucket 聚合，对搜索结果中的文档基于品牌分组、基于城市分组，就能得知包含哪些品牌、哪些城市了。\n\n因为是对搜索结果聚合，因此聚合是限定范围的聚合，也就是说聚合的限定条件跟搜索文档的条件一致。\n\n返回结果是一个 Map 结构：\n\n- key 是字符串，城市、星级、品牌、价格\n- value 是集合，例如多个城市的名称\n\n#### 业务实现\n\n在 `cn.itcast.hotel.web` 包的 `HotelController` 中添加一个方法，遵循下面的要求：\n\n- 请求方式：`POST`\n- 请求路径：`/hotel/filters`\n- 请求参数：`RequestParams`，与搜索文档的参数一致\n- 返回值类型：`Map<String, List<String>>`\n\n代码：\n\n```java\n@PostMapping(\"filters\")\npublic Map<String, List<String>> getFilters(@RequestBody RequestParams params){\n    return hotelService.getFilters(params);\n}\n```\n\n这里调用了 IHotelService 中的 getFilters 方法，尚未实现。\n\n在 `cn.itcast.hotel.service.IHotelService` 中定义新方法：\n\n```java\nMap<String, List<String>> filters(RequestParams params);\n```\n\n在 `cn.itcast.hotel.service.impl.HotelService` 中实现该方法：\n\n```java\n@Override\npublic Map<String, List<String>> getFilters(RequestParams params) {\n    try {\n        // 1. 准备 request\n        SearchRequest request = new SearchRequest(\"hotel\");\n\n        // 2. 准备 DSL\n        // query\n        FunctionScoreQueryBuilder query = getQueryBuilder(params);\n        request.source().highlighter(new HighlightBuilder().field(\"name\").requireFieldMatch(false));\n        request.source().query(query);\n        // 2.1 设置 size = 0\n        request.source().size(0);\n        // 2.2 聚合\n        HashMap<String, String> items = new HashMap<>();\n        items.put(\"brand\", \"品牌\");\n        items.put(\"city\", \"城市\");\n        items.put(\"starName\", \"星级\");\n        for (String item : items.keySet()) {\n            request.source().aggregation(AggregationBuilders\n                                         .terms(item + \"Agg\")\n                                         .field(item)\n                                         .size(100));\n        }\n        // 3. 发出请求\n        SearchResponse response = null;\n\n        response = client.search(request, RequestOptions.DEFAULT);\n\n\n        // 4. 解析结果\n        // 4.1 获取 aggregations\n        Aggregations aggregations = response.getAggregations();\n\n        HashMap<String, List<String>> itemListHashMap = new HashMap<>();\n\n        for (String item : items.keySet()) {\n            // 4.2 根据名称获取聚合结果\n            Terms brandTerms = aggregations.get(item + \"Agg\");\n            // 4.3 获取 buckets 并遍历\n            ArrayList<String> itemList = new ArrayList<>();\n            for (Terms.Bucket bucket : brandTerms.getBuckets()) {\n                // 获取 key\n                itemList.add(bucket.getKeyAsString());\n            }\n            itemListHashMap.put(item, itemList);\n        }\n        return itemListHashMap;\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n## 自动补全\n\n当用户在搜索框输入字符时，我们应该提示出与该字符有关的搜索项，这种根据用户输入的字母，提示完整词条的功能，就是自动补全了。\n\n因为需要根据拼音字母来推断，因此要用到拼音分词功能。\n\n### 拼音分词器\n\n要实现根据字母做补全，就必须对文档按照拼音分词。在 GitHub 上有 ElasticSearch的拼音分词插件。地址：https://github.com/medcl/elasticsearch-analysis-pinyin\n\n安装方式与 IK 分词器一样，分三步：\n\n1. 解压\n2. 上传到虚拟机中，ElasticSearch 的 plugin 目录\n3. 重启 ElasticSearch\n4. 测试\n\n详细安装步骤可以参考 IK 分词器的安装过程。\n\n测试用法如下：\n\n```json\nPOST /_analyze\n{\n  \"text\": \"如家酒店还不错\",\n  \"analyzer\": \"pinyin\"\n}\n```\n\n结果如下：\n\n```json\n{\n  \"tokens\" : [\n    {\n      \"token\" : \"ru\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"rjjdhbc\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 0\n    },\n    {\n      \"token\" : \"jia\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 1\n    },\n    {\n      \"token\" : \"jiu\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 2\n    },\n    {\n      \"token\" : \"dian\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 3\n    },\n    {\n      \"token\" : \"hai\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 4\n    },\n    {\n      \"token\" : \"bu\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 5\n    },\n    {\n      \"token\" : \"cuo\",\n      \"start_offset\" : 0,\n      \"end_offset\" : 0,\n      \"type\" : \"word\",\n      \"position\" : 6\n    }\n  ]\n}\n```\n\n### 自定义分词器\n\n默认的拼音分词器会将每个汉字单独分为拼音，而我们希望的是每个词条形成一组拼音，需要对拼音分词器做个性化定制，形成自定义分词器。\n\nElasticSearch 中分词器（analyzer）的组成包含三部分：\n\n- character filters：在 tokenizer 之前对文本进行处理。例如删除字符、替换字符\n- tokenizer：将文本按照一定的规则切割成词条（term）。例如 keyword，就是不分词；还有 ik_smart\n- tokenizer filter：将 tokenizer 输出的词条做进一步处理。例如大小写转换、同义词处理、拼音处理等\n\n声明自定义分词器的语法如下：\n\n```json\nPUT /test\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"my_analyzer\": {\n          \"tokenizer\": \"ik_max_word\",\n          \"filter\": \"py\"\n        }\n      },\n      \"filter\": {\n        \"py\": {\n          \"type\": \"pinyin\",\n          \"keep_full_pinyin\": false,\n          \"keep_joined_full_pinyin\": true,\n          \"keep_original\": true,\n          \"limit_first_letter_length\": 16,\n          \"remove_duplicated_term\": true,\n          \"none_chinese_pinyin_tokenize\": false\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"name\": {\n        \"type\": \"text\",\n        \"analyzer\": \"my_analyzer\",\n        \"search_analyzer\": \"ik_smart\"\n      }\n    }\n  }\n}\n```\n\n总结：\n\n如何使用拼音分词器？\n\n- 下载 pinyin 分词器\n\n- 解压并放到 ElasticSearch 的 plugin 目录\n\n- 重启即可\n\n如何自定义分词器？\n\n- 创建索引库时，在 settings 中配置，可以包含三部分：character filter、tokenizer、filter\n\n\n拼音分词器注意事项？\n\n- 为了避免搜索到同音字，搜索时不要使用拼音分词器\n\n### 自动补全查询\n\nElasticSearch 提供了 [Completion Suggester](https://www.elastic.co/guide/en/elasticsearch/reference/7.6/search-suggesters.html) 查询来实现自动补全功能。这个查询会匹配以用户输入内容开头的词条并返回。为了提高补全查询的效率，对于文档中字段的类型有一些约束：\n\n- 参与补全查询的字段必须是 completion 类型。\n\n- 字段的内容一般是用来补全的多个词条形成的数组。\n\n比如，一个这样的索引库：\n\n```json\nPUT /test2\n{\n  \"mappings\": {\n    \"properties\": {\n      \"title\":{\n        \"type\": \"completion\"\n      }\n    }\n  }\n}\n```\n\n然后插入下面的数据：\n\n```json\nPOST /test2/_doc\n{\n  \"title\": [\"Sony\", \"WH-1000XM3\"]\n}\nPOST /test2/_doc\n{\n  \"title\": [\"SK-II\", \"PITERA\"]\n}\nPOST /test2/_doc\n{\n  \"title\": [\"Nintendo\", \"switch\"]\n}\n```\n\n查询的 DSL 语句如下：\n\n```json\nPOST /test2/_search\n{\n  \"suggest\": {\n    \"title_suggest\": {\n      \"text\": \"s\", \n      \"completion\": {\n        \"field\": \"title\", \n        \"skip_duplicates\": true, \n        \"size\": 10 \n      }\n    }\n  }\n}\n```\n\n### 实现酒店搜索框自动补全\n\n现在，我们的 hotel 索引库还没有设置拼音分词器，需要修改索引库中的配置。但是我们知道索引库是无法修改的，只能删除然后重新创建。\n\n另外，我们需要添加一个字段，用来做自动补全，将 brand、suggestion、city 等都放进去，作为自动补全的提示。\n\n因此，总结一下，我们需要做的事情包括：\n\n1. 修改 hotel 索引库结构，设置自定义拼音分词器\n\n2. 修改索引库的 name、all 字段，使用自定义分词器\n\n3. 索引库添加一个新字段 suggestion，类型为 completion 类型，使用自定义的分词器\n\n4. 给 HotelDoc 类添加 suggestion 字段，内容包含 brand、business\n\n5. 重新导入数据到 hotel 库\n\n#### 修改酒店映射结构\n\n代码如下：\n\n```json\n// 酒店数据索引库\nPUT /hotel\n{\n  \"settings\": {\n    \"analysis\": {\n      \"analyzer\": {\n        \"text_anlyzer\": {\n          \"tokenizer\": \"ik_max_word\",\n          \"filter\": \"py\"\n        },\n        \"completion_analyzer\": {\n          \"tokenizer\": \"keyword\",\n          \"filter\": \"py\"\n        }\n      },\n      \"filter\": {\n        \"py\": {\n          \"type\": \"pinyin\",\n          \"keep_full_pinyin\": false,\n          \"keep_joined_full_pinyin\": true,\n          \"keep_original\": true,\n          \"limit_first_letter_length\": 16,\n          \"remove_duplicated_term\": true,\n          \"none_chinese_pinyin_tokenize\": false\n        }\n      }\n    }\n  },\n  \"mappings\": {\n    \"properties\": {\n      \"id\":{\n        \"type\": \"keyword\"\n      },\n      \"name\":{\n        \"type\": \"text\",\n        \"analyzer\": \"text_anlyzer\",\n        \"search_analyzer\": \"ik_smart\",\n        \"copy_to\": \"all\"\n      },\n      \"address\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"price\":{\n        \"type\": \"integer\"\n      },\n      \"score\":{\n        \"type\": \"integer\"\n      },\n      \"brand\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"city\":{\n        \"type\": \"keyword\"\n      },\n      \"starName\":{\n        \"type\": \"keyword\"\n      },\n      \"business\":{\n        \"type\": \"keyword\",\n        \"copy_to\": \"all\"\n      },\n      \"location\":{\n        \"type\": \"geo_point\"\n      },\n      \"pic\":{\n        \"type\": \"keyword\",\n        \"index\": false\n      },\n      \"all\":{\n        \"type\": \"text\",\n        \"analyzer\": \"text_anlyzer\",\n        \"search_analyzer\": \"ik_smart\"\n      },\n      \"suggestion\":{\n          \"type\": \"completion\",\n          \"analyzer\": \"completion_analyzer\"\n      }\n    }\n  }\n}\n```\n\n#### 修改 HotelDoc 实体\n\nHotelDoc 中要添加一个字段，用来做自动补全，内容可以是酒店品牌、城市、商圈等信息。按照自动补全字段的要求，最好是这些字段的数组。\n\n因此我们在 HotelDoc 中添加一个 suggestion 字段，类型为 `List<String>`，然后将 brand、city、business 等信息放到里面。\n\n代码如下：\n\n```java\n@Data\n@NoArgsConstructor\npublic class HotelDoc {\n    private Long id;\n    private String name;\n    private String address;\n    private Integer price;\n    private Integer score;\n    private String brand;\n    private String city;\n    private String starName;\n    private String business;\n    private String location;\n    private String pic;\n    private Object distance;\n    private Boolean isAD;\n    private List<String> suggestion;\n\n    public HotelDoc(Hotel hotel) {\n        this.id = hotel.getId();\n        this.name = hotel.getName();\n        this.address = hotel.getAddress();\n        this.price = hotel.getPrice();\n        this.score = hotel.getScore();\n        this.brand = hotel.getBrand();\n        this.city = hotel.getCity();\n        this.starName = hotel.getStarName();\n        this.business = hotel.getBusiness();\n        this.location = hotel.getLatitude() + \", \" + hotel.getLongitude();\n        this.pic = hotel.getPic();\n        // 组装suggestion\n        if (this.business.contains(\"/\")) {\n            // business有多个值，需要切割\n            String[] arr = this.business.split(\"/\");\n            // 添加元素\n            this.suggestion = new ArrayList<>();\n            this.suggestion.add(this.brand);\n            Collections.addAll(this.suggestion, arr);\n        } else {\n            this.suggestion = Arrays.asList(this.brand, this.business);\n        }\n    }\n}\n```\n\n#### 重新导入并测试\n\n重新执行之前编写的导入数据功能 `testBulkRequest()`，并搜索测试\n\n```json\nGET /hotel/_search\n{\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n可以看到新的酒店数据中包含了 suggestion，接下来测试自动补全功能\n\n```json\nGET /hotel/_search\n{\n  \"suggest\": {\n    \"suggestions\": {\n      \"text\": \"sd\",\n      \"completion\": {\n        \"field\": \"suggestion\",\n        \"skip_duplicates\": true, \n        \"size\": 10 \n      }\n    }\n  }\n}\n```\n\n#### 自动补全查询的 Java API\n\n```java\n// 1.准备请求\nSearchRequest request = new SearchRequest(\"hotel\");\n// 2.请求参数\nrequest.source().suggest(new SuggestBuilder().addSuggestion(\n    \"mySuggestion\",\n    SuggestBuilders\n    .completionSuggestion(\"title\")\n    .prefix(\"h\")\n    .skipDuplicates(true)\n    .size(10)\n));\n// 3.发送请求\nclient.search(request, RequestOptions.DEFAULT);\n```\n\n而自动补全的结果也比较特殊，解析的代码如下：\n\n```java\n// 4.处理结果\nSuggest suggest = response.getSuggest();\n// 4.1.根据名称获取补全结果\nCompletionSuggestion suggestion = suggest.getSuggestion(\"mySuggestion\");\n// 4.2.获取options并遍历\nfor (CompletionSuggestion.Entry.Option option : suggestion.getOptions()) {\n    // 4.3.获取一个option中的text，也就是补全的词条\n    String text = option.getText().string();\n    System.out.println(text);\n}\n```\n\n#### 实现搜索框自动补全\n\n在 `cn.itcast.hotel.web` 包下的 `HotelController` 中添加新接口，接收新的请求：\n\n```java\n@GetMapping(\"suggestion\")\npublic List<String> getSuggestions(@RequestParam(\"key\") String prefix) {\n    return hotelService.getSuggestions(prefix);\n}\n```\n\n在 `cn.itcast.hotel.service` 包下的 `IhotelService` 中添加方法：\n\n```java\nList<String> getSuggestions(String prefix);\n```\n\n在 `cn.itcast.hotel.service.impl.HotelService` 中实现该方法：\n\n```java\n@Override\npublic List<String> getSuggestions(String prefix) {\n    try {\n        // 1.准备请求\n        SearchRequest request = new SearchRequest(\"hotel\");\n        // 2.请求参数\n        request.source().suggest(new SuggestBuilder().addSuggestion(\n            \"suggestions\",\n            SuggestBuilders\n            .completionSuggestion(\"suggestion\")\n            .prefix(prefix)\n            .skipDuplicates(true)\n            .size(10)\n        ));\n        // 3.发送请求\n        SearchResponse response = client.search(request, RequestOptions.DEFAULT);\n        // 4.处理结果\n        Suggest suggest = response.getSuggest();\n        // 4.1.根据名称获取补全结果\n        CompletionSuggestion suggestion = suggest.getSuggestion(\"suggestions\");\n        // 4.2.获取options并遍历\n        ArrayList<String> result = new ArrayList<>();\n        for (CompletionSuggestion.Entry.Option option : suggestion.getOptions()) {\n            // 4.3.获取一个option中的text，也就是补全的词条\n            String text = option.getText().string();\n            result.add(text);\n        }\n        return result;\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n## 数据同步\n\nElasticSearch 中的酒店数据来自于 MySQL 数据库，因此 MySQL 数据发生改变时，ElasticSearch 也必须跟着改变，这个就是 ElasticSearch 与 MySQL 之间的数据同步。\n\n### 思路分析\n\n常见的数据同步方案有三种：\n\n- 同步调用\n- 异步通知\n- 监听 binlog\n\n#### 同步调用\n\n![同步调用](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/同步调用.i2rj0d3cpwg.svg)\n\n基本步骤如下：\n\n- hotel-demo 对外提供接口，用来修改 ElasticSearch 中的数据\n- 酒店管理服务在完成数据库操作后，直接调用 hotel-demo 提供的接口\n\n#### 异步通知\n\n![异步通知](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/异步通知.1p2ptlc5nrs0.svg)\n\n流程如下：\n\n- hotel-admin 对 MySQL 数据库数据完成增、删、改后，发送 MQ 消息\n- hotel-demo 监听 MQ，接收到消息后完成 ElasticSearch 数据修改\n\n#### 监听 binlog\n\n![监听binlog](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/监听binlog.1n6hcbad4pb4.svg)\n\n流程如下：\n\n- 给 MySQL 开启 binlog 功能\n- MySQL 完成增、删、改操作都会记录在 binlog 中\n- hotel-demo 基于 canal 监听 binlog 变化，实时更新 ElasticSearch 中的内容\n\n#### 不同数据同步方案优缺点\n\n方式一：同步调用\n\n- 优点：实现简单，粗暴\n- 缺点：业务耦合度高\n\n方式二：异步通知\n\n- 优点：低耦合，实现难度一般\n- 缺点：依赖 MQ 的可靠性\n\n方式三：监听 binlog\n\n- 优点：完全解除服务间耦合\n- 缺点：开启 binlog 增加数据库负担、实现复杂度高\n\n### 实现数据同步\n\n#### 基于 MQ 的实现思路\n\n利用提供的 hotel-admin 项目作为酒店管理的微服务。当酒店数据发生增、删、改时，要求对 ElasticSearch 中数据也要完成相同操作。\n\n步骤：\n\n- 导入 hotel-admin 项目，启动并测试酒店数据的 CRUD\n\n- 声明 exchange、queue、RoutingKey\n\n- 在 hotel-admin 中的增、删、改业务中完成消息发送\n\n- 在 hotel-demo 中完成消息监听，并更新 ElasticSearch 中数据\n\n- 启动并测试数据同步功能\n\n### 导入 demo\n\n代码链接：[GitHub](https://github.com/Lanqilu/HaloElasticSearch/commit/b9d7c724b44d6ea8e307ac5d54778bba635bd314)\n\n运行后，访问 http://localhost:8099\n\n### 声明交换机、队列\n\nMQ 结构如图：\n\n![MQ结构](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/MQ结构.lv1ecla6gvk.svg)\n\n#### 引入依赖并修改配置文件 \n\n在 hotel-admin、hotel-demo 中引入 rabbitmq 的依赖：\n\n```xml\n<!--amqp-->\n<dependency>\n    <groupId>org.springframework.boot</groupId>\n    <artifactId>spring-boot-starter-amqp</artifactId>\n</dependency>\n```\n\n```yaml\nspring:\n  rabbitmq:\n    host: rabbitmq\n    port: 5672\n    username: halo\n    password: halo\n    virtual-host: /\n```\n\n#### 声明交换机、队列\n\n在 hotel-admin 和 hotel-demo 中的 `cn.itcast.hotel.constatnts` 包下新建一个类 `MqConstants`：\n\n```java\npublic class MqConstants {\n    /**\n     * 交换机\n     */\n    public final static String HOTEL_EXCHANGE = \"hotel.topic\";\n    /**\n     * 监听新增和修改的队列\n     */\n    public final static String HOTEL_INSERT_QUEUE = \"hotel.insert.queue\";\n    /**\n     * 监听删除的队列\n     */\n    public final static String HOTEL_DELETE_QUEUE = \"hotel.delete.queue\";\n    /**\n     * 新增或修改的RoutingKey\n     */\n    public final static String HOTEL_INSERT_KEY = \"hotel.insert\";\n    /**\n     * 删除的RoutingKey\n     */\n    public final static String HOTEL_DELETE_KEY = \"hotel.delete\";\n}\n```\n\n在 hotel-demo 中，定义配置类，声明队列、交换机：\n\n```java\n@Configuration\npublic class MqConfig {\n    @Bean\n    public TopicExchange topicExchange(){\n        return new TopicExchange(MqConstants.HOTEL_EXCHANGE, true, false);\n    }\n\n    @Bean\n    public Queue insertQueue(){\n        return new Queue(MqConstants.HOTEL_INSERT_QUEUE, true);\n    }\n\n    @Bean\n    public Queue deleteQueue(){\n        return new Queue(MqConstants.HOTEL_DELETE_QUEUE, true);\n    }\n\n    @Bean\n    public Binding insertQueueBinding(){\n        return BindingBuilder.bind(insertQueue()).to(topicExchange()).with(MqConstants.HOTEL_INSERT_KEY);\n    }\n\n    @Bean\n    public Binding deleteQueueBinding(){\n        return BindingBuilder.bind(deleteQueue()).to(topicExchange()).with(MqConstants.HOTEL_DELETE_KEY);\n    }\n}\n```\n\n### 发送 MQ 消息\n\n在 hotel-admin 中的增、删、改业务中分别发送 MQ 消息：\n\n```java\n@Autowired\nprivate RabbitTemplate rabbitTemplate;\n\n@PostMapping\npublic void saveHotel(@RequestBody Hotel hotel){\n    hotelService.save(hotel);\n    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE,MqConstants.HOTEL_INSERT_KEY,hotel.getId());\n}\n\n@PutMapping()\npublic void updateById(@RequestBody Hotel hotel){\n    if (hotel.getId() == null) {\n        throw new InvalidParameterException(\"id不能为空\");\n    }\n    hotelService.updateById(hotel);\n    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE,MqConstants.HOTEL_INSERT_KEY,hotel.getId());\n}\n\n@DeleteMapping(\"/{id}\")\npublic void deleteById(@PathVariable(\"id\") Long id) {\n    hotelService.removeById(id);\n    rabbitTemplate.convertAndSend(MqConstants.HOTEL_EXCHANGE,MqConstants.HOTEL_DELETE_KEY,id);\n}\n```\n\n### 接收 MQ 消息\n\nhotel-demo 接收到 MQ 消息要做的事情包括：\n\n- 新增消息：根据传递的 hotel 的 id 查询 hotel 信息，然后新增一条数据到索引库\n- 删除消息：根据传递的 hotel 的 id 删除索引库中的一条数据\n\n首先在 hotel-demo 的 `cn.itcast.hotel.service` 包下的 `IHotelService` 中新增新增、删除业务\n\n```java\nvoid deleteById(Long id);\n\nvoid insertById(Long id);\n```\n\n给 hotel-demo 中的 `cn.itcast.hotel.service.impl` 包下的 HotelService 中实现业务：\n\n```java\n@Override\npublic void deleteById(Long id) {\n    try {\n        // 1.准备Request\n        DeleteRequest request = new DeleteRequest(\"hotel\", id.toString());\n        // 2.发送请求\n        client.delete(request, RequestOptions.DEFAULT);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n\n@Override\npublic void insertById(Long id) {\n    try {\n        // 0.根据id查询酒店数据\n        Hotel hotel = getById(id);\n        // 转换为文档类型\n        HotelDoc hotelDoc = new HotelDoc(hotel);\n\n        // 1.准备Request对象\n        IndexRequest request = new IndexRequest(\"hotel\").id(hotel.getId().toString());\n        // 2.准备Json文档\n        request.source(JSON.toJSONString(hotelDoc), XContentType.JSON);\n        // 3.发送请求\n        client.index(request, RequestOptions.DEFAULT);\n    } catch (IOException e) {\n        throw new RuntimeException(e);\n    }\n}\n```\n\n编写监听器，在 hotel-demo 中的 `cn.itcast.hotel.mq` 包新增一个类：\n\n```java\n@Component\npublic class HotelListener {\n\n    @Autowired\n    private IHotelService hotelService;\n\n    /**\n     * 监听酒店新增或修改的业务\n     * @param id 酒店id\n     */\n    @RabbitListener(queues = MqConstants.HOTEL_INSERT_QUEUE)\n    public void listenHotelInsertOrUpdate(Long id){\n        hotelService.insertById(id);\n    }\n\n    /**\n     * 监听酒店删除的业务\n     * @param id 酒店id\n     */\n    @RabbitListener(queues = MqConstants.HOTEL_DELETE_QUEUE)\n    public void listenHotelDelete(Long id){\n        hotelService.deleteById(id);\n    }\n}\n```\n\n## ElasticSearch 集群\n\n单机的 ElasticSearch 做数据存储，必然面临两个问题：海量数据存储问题、单点故障问题。\n\n- 海量数据存储问题：将索引库从逻辑上拆分为 N 个分片（shard），存储到多个节点\n- 单点故障问题：将分片数据在不同节点备份（replica）\n\nES 集群相关概念:\n\n* 集群（cluster）：一组拥有共同的 cluster name 的 节点。\n* 节点（node)   ：集群中的一个 Elasticearch 实例\n* 分片（shard）：索引可以被拆分为不同的部分进行存储，称为分片。在集群环境下，一个索引的不同分片可以拆分到不同的节点中\n\n解决问题：数据量太大，单点存储量有限的问题。\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.4pwzs1lq4540.png)\n\n此处，我们把数据分成 3 片：shard0、shard1、shard2\n\n* 主分片（Primary shard）：相对于副本分片的定义。\n\n* 副本分片（Replica shard）每个主分片可以有一个或者多个副本，数据和主分片一样。\n\n数据备份可以保证高可用，但是每个分片备份一份，所需要的节点数量就会翻一倍，成本实在是太高了！\n\n为了在高可用和成本间寻求平衡，我们可以这样做：\n\n- 首先对数据分片，存储到不同节点\n- 然后对每个分片进行备份，放到对方节点，完成互相备份\n\n这样可以大大减少所需要的服务节点数量，如图，我们以 3 分片，每个分片备份一份为例：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3jlk46u66q60.png)\n\n现在，每个分片都有 1 个备份，存储在 3 个节点：\n\n- node0：保存了分片 0 和 1\n- node1：保存了分片 0 和 2\n- node2：保存了分片 1 和 2\n\n### 部署 ElasticSearch 集群\n\n我们会在单机上利用 docker 容器运行多个 ElasticSearch 实例来模拟 ElasticSearch 集群。不过生产环境推荐大家每一台服务节点仅部署一个 ElasticSearch 的实例。\n\n部署 ElasticSearch 集群可以直接使用 docker-compose 来完成，但这要求你的 Linux 虚拟机至少有 4G 的内存空间\n\n#### 创建 ElasticSearch 集群\n\n首先编写一个 docker-compose 文件，内容如下：\n\n```sh\nversion: \'2.2\'\nservices:\n  es01:\n    image: elasticsearch:7.12.1\n    container_name: es01\n    environment:\n      - node.name=es01\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es02,es03\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data01:/usr/share/elasticsearch/data\n    ports:\n      - 9200:9200\n    networks:\n      - elastic\n  es02:\n    image: elasticsearch:7.12.1\n    container_name: es02\n    environment:\n      - node.name=es02\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es01,es03\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data02:/usr/share/elasticsearch/data\n    ports:\n      - 9201:9200\n    networks:\n      - elastic\n  es03:\n    image: elasticsearch:7.12.1\n    container_name: es03\n    environment:\n      - node.name=es03\n      - cluster.name=es-docker-cluster\n      - discovery.seed_hosts=es01,es02\n      - cluster.initial_master_nodes=es01,es02,es03\n      - \"ES_JAVA_OPTS=-Xms512m -Xmx512m\"\n    volumes:\n      - data03:/usr/share/elasticsearch/data\n    networks:\n      - elastic\n    ports:\n      - 9202:9200\nvolumes:\n  data01:\n    driver: local\n  data02:\n    driver: local\n  data03:\n    driver: local\n\nnetworks:\n  elastic:\n    driver: bridge\n```\n\nElasticSearch  运行需要修改一些 Linux 系统权限，修改 `/etc/sysctl.conf` 文件\n\n```sh\nvi /etc/sysctl.conf\n```\n\n添加下面的内容：\n\n```sh\nvm.max_map_count=262144\n```\n\n然后执行命令，让配置生效：\n\n```sh\nsysctl -p\n```\n\n通过 docker-compose 启动集群：\n\n```sh\ndocker-compose up -d\n```\n\n#### 集群状态监控\n\nkibana 可以监控 ElasticSearch  集群，不过新版本需要依赖 ElasticSearch  的 x-pack 功能，配置比较复杂。\n\n这里推荐使用 cerebro 来监控 ElasticSearch  集群状态，官方网址：https://github.com/lmenezes/cerebro\n\n双击其中的 cerebro.bat 文件即可启动服务。访问 http://localhost:9000 即可进入管理界面：\n\n输入你的 ElasticSearch 的任意节点的地址和端口，点击 connect 即可\n\n#### 创建索引库\n\n利用 kibana 的 DevTools 创建索引库，在 DevTools 中输入指令：\n\n```json\nPUT /test\n{\n  \"settings\": {\n    \"number_of_shards\": 3, // 分片数量\n    \"number_of_replicas\": 1 // 副本数量\n  },\n  \"mappings\": {\n    \"properties\": {\n      // mapping映射定义 ...\n    }\n  }\n}\n```\n\n或利用 cerebro 创建索引库\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.29xen9tqfmvw.png)\n\n查看分片效果，回到首页，即可查看索引库分片效果：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.2jn8zaht2280.png)\n\n### 集群脑裂问题\n\n#### 集群职责划分\n\nElasticSearch 中集群节点有不同的职责划分：\n\n| 节点类型         | 配置参数                                       | 默认值 | 节点职责                                                     |\n| ---------------- | ---------------------------------------------- | ------ | ------------------------------------------------------------ |\n| master  eligible | node.master                                    | true   | 备选主节点：主节点可以管理和记录集群状态、决定分片在哪个节点、处理创建和删除索引库的请求 |\n| data             | node.data                                      | true   | 数据节点：存储数据、搜索、聚合、CRUD                         |\n| ingest           | node.ingest                                    | true   | 数据存储之前的预处理                                         |\n| coordinating     | 上面 3 个参数都为 false 则为 coordinating 节点 | 无     | 路由请求到其它节点  合并其它节点处理的结果，返回给用户       |\n\n默认情况下，集群中的任何一个节点都同时具备上述四种角色。\n\n但是真实的集群一定要将集群职责分离：\n\n- master 节点：对 CPU 要求高，但是内存要求低\n- data 节点：对 CPU 和内存要求都高\n- coordinating 节点：对网络带宽、CPU 要求高\n\n职责分离可以让我们根据不同节点的需求分配不同的硬件去部署。而且避免业务之间的互相干扰。\n\n一个典型的 ElasticSearch 集群职责划分如图：\n\n![ES集群](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/ES集群.2rrl7g78cxs0.svg)\n\n#### 脑裂问题\n\n脑裂是因为集群中的节点失联导致的。\n\n例如一个集群中，主节点与其它节点失联，\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.6ry0qp2sxiw0.png)\n\n此时 node2 和 node3 认为 node1 宕机，就会重新选主：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5qon8j1rbak0.png)\n\n当 node3 当选后，集群继续对外提供服务，node2 和 node3 自成集群，node1 自成集群，两个集群数据不同步，出现数据差异。\n\n当网络恢复后，因为集群中有两个 master 节点，集群状态的不一致，出现脑裂的情况：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.wmlcqz00rls.png)\n\n解决脑裂的方案是，要求选票超过 ( eligible节点数量 + 1 ）/ 2 才能当选为主，因此 eligible 节点数量最好是奇数。对应配置项是 discovery.zen.minimum_master_nodes，在 ElasticSearch 7.0 以后，已经成为默认配置，因此一般不会发生脑裂问题\n\n例如：3 个节点形成的集群，选票必须超过 （3 + 1） / 2 ，也就是 2 票。node3 得到 node2 和 node3 的选票，当选为主。node1 只有自己 1 票，没有当选。集群中依然只有 1 个主节点，没有出现脑裂。\n\n### 集群分布式存储\n\n当新增文档时，应该保存到不同分片，保证数据均衡，那么 coordinating node 如何确定数据该存储到哪个分片呢？\n\n#### 分片存储测试\n\n在一个节点中加入数据，后可以通过 explain 命令查询\n\n```json\nPOST /test/_search\n{\n  \"explain\": true,\n  \"query\": {\n    \"match_all\": {}\n  }\n}\n```\n\n发现数据在不同的节点中，形成分片存储\n\n#### 分片存储原理\n\nElasticSearch 会通过 hash 算法来计算文档应该存储到哪个分片：`shard = hash(_routing) % number_of_shards`\n\n说明：\n\n- `_routing` 默认是文档的id\n- 算法与分片数量有关，因此索引库一旦创建，分片数量不能修改！\n\n新增文档的流程如下：\n\n![ES集群](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/ES集群.akvhs79fwq0.svg)\n\n解读：\n\n- 新增一个 id=1 的文档\n- 对 id 做 hash 运算，假如得到的是 2，则应该存储到 P-2\n- P-2 的主分片在 node3 节点，将数据路由到 node3\n- 保存文档\n- 同步给 P-2 的副本 R-2，在 node2 节点\n- 返回结果给 coordinating-node 节点\n\n#### 集群分布式查询\n\nElasticSearch 的查询分成两个阶段：\n\n- scatter phase：分散阶段，coordinating node 会把请求分发到每一个分片\n\n- gather phase：聚集阶段，coordinating node 汇总 data node 的搜索结果，并处理为最终结果集返回给用户\n\n#### 集群故障转移\n\n集群的 master 节点会监控集群中的节点状态，如果发现有节点宕机，会立即将宕机节点的分片数据迁移到其它节点，确保数据安全，这个叫做故障转移。\n\n+ 假如，node1 发生了故障\n+ 宕机后的第一件事，需要重新选主，例如选中了 node2，\n+ node2 成为主节点后，会检测集群监控状态，发现：shard-1、shard-0 没有副本节点。因此需要将 node1 上的数据迁移到 node2、node3\n+ 但 node1 恢复，此时 node1 不在是主节点，但数据会重新平衡\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n', '2021-09-26 12:22:18', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 5, '2021-09-26 12:22:18', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (14, 1, '111', '111', '111', '2021-09-26 21:39:22', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-09-26 21:39:22', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (15, 1, '微服务入门', '微服务入门', '## 认识微服务\n\n### 单体架构与分布式架构\n\n单体架构：将业务的所有功能集中在一个项目中开发，打成一个包部署。优点是架构简单、部署成本低，但耦合度高（维护困难、升级困难）\n\n分布式架构：根据业务功能对系统做拆分，每个业务功能模块作为独立项目开发，称为一个服务。降低了服务耦合，有利于服务升级和拓展，但服务调用关系错综复杂\n\n分布式架构虽然降低了服务耦合，但是服务拆分时也有很多问题需要思考：\n\n- 服务拆分的粒度如何界定？\n- 服务之间如何调用？\n- 服务的调用关系如何管理？\n\n人们需要制定一套行之有效的标准来约束分布式架构。\n\n### 微服务\n\n微服务的架构特征：\n\n- 单一职责：微服务拆分粒度更小，每一个服务都对应唯一的业务能力，做到单一职责\n- 自治：团队独立、技术独立、数据独立，独立部署和交付\n- 面向服务：服务提供统一标准的接口，与语言和技术无关\n- 隔离性强：服务调用做好隔离、容错、降级，避免出现级联问题\n\n微服务的上述特性其实是在给分布式架构制定一个标准，进一步降低服务之间的耦合度，提供服务的独立性和灵活性。做到高内聚，低耦合。\n\n因此，可以认为微服务是一种经过良好架构设计的分布式架构方案 。\n\n但方案该怎么落地？选用什么样的技术栈？全球的互联网公司都在积极尝试自己的微服务落地方案。\n\n其中在 Java 领域最引人注目的就是 Spring Cloud 提供的方案了。\n\n### Spring Cloud\n\nSpring Cloud 是目前国内使用最广泛的微服务框架。官网地址：https://spring.io/projects/spring-cloud。\n\nSpring Cloud 集成了各种微服务功能组件，并基于 Spring Boot 实现了这些组件的自动装配，从而提供了良好的开箱即用体验。\n\n其中常见的组件包括：\n\n![微服务组件](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/微服务组件.8239z8cveb0.svg)\n\n另外，Spring Cloud 底层是依赖于 Spring Boot 的，并且有版本的兼容关系，如下：\n\n![SpringBoot与SpringCloud](https://pic.imgdb.cn/item/6133818144eaada739d722b1.jpg)\n\n### 认识微服务小结\n\n- 单体架构：简单方便，高度耦合，扩展性差，适合小型项目。例如：学生管理系统\n- 分布式架构：松耦合，扩展性好，但架构复杂，难度大。适合大型互联网项目，例如：京东、淘宝\n- 微服务：一种良好的分布式架构方案\n  - 优点：拆分粒度更小、服务更独立、耦合度更低\n  - 缺点：架构非常复杂，运维、监控、部署难度提高\n- Spring Cloud 是微服务架构的一站式解决方案，集成了各种优秀微服务功能组件\n\n## 服务拆分和远程调用\n\n### 服务拆分原则\n\n微服务拆分时的几个原则：\n\n- 不同微服务，不要重复开发相同业务\n- 微服务数据独立，不要访问其它微服务的数据库\n- 微服务可以将自己的业务暴露为接口，供其它微服务调用\n\n### 服务拆分示例\n\n以 spring-cloud-demo 为例，其结构如下：\n\n```\nspring-cloud-demo\n ├── order-service\n └── user-service\n```\n\nspring-cloud-demo：父工程，管理依赖\n\n- order-service：订单微服务，负责订单相关业务\n- user-service：用户微服务，负责用户相关业务\n\n要求：\n\n- 订单微服务和用户微服务都必须有各自的数据库，相互独立\n- 订单服务和用户服务都对外暴露 Restful 的接口\n- 订单服务如果需要查询用户信息，只能调用用户服务的 Restful 接口，不能查询用户数据库\n\n初始项目代码：[链接](https://github.com/Lanqilu/HaloSpringCloud/releases/tag/v0.1)\n\n### 实现远程调用案例\n\n#### 案例需求\n\n修改 order-service 中的根据 id 查询订单业务，要求在查询订单的同时，根据订单中包含的 userId 查询出用户信息，一起返回。\n\n因此，我们需要在 order-service 中向 user-service 发起一个 http 的请求，调用 `http://localhost:8081/user/{userId}` 这个接口。\n\n大概的步骤是这样的：\n\n- 注册一个 RestTemplate 的实例到 Spring 容器\n- 修改 order-service 服务中的 OrderService 类中的 queryOrderById 方法，根据 Order 对象中的 userId 查询 User\n- 将查询的 User 填充到 Order 对象，一起返回\n\n#### 注册 RestTemplate\n\n首先，我们在 order-service 服务中的 OrderApplication 启动类中，注册 RestTemplate 实例：\n\n```java\npackage cn.itcast.order;\n\nimport org.mybatis.spring.annotation.MapperScan;\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.context.annotation.Bean;\nimport org.springframework.web.client.RestTemplate;\n\n@MapperScan(\"cn.itcast.order.mapper\")\n@SpringBootApplication\npublic class OrderApplication {\n\n    public static void main(String[] args) {\n        SpringApplication.run(OrderApplication.class, args);\n    }\n\n    @Bean\n    public RestTemplate restTemplate() {\n        return new RestTemplate();\n    }\n}\n```\n\n#### 实现远程调用\n\n修改 order-service 服务中的 cn.itcast.order.service 包下的 OrderService 类中的 queryOrderById 方法：\n\n```java\n@Autowired\nprivate RestTemplate restTemplate;\n\npublic Order queryOrderById(Long orderId) {\n    // 1.查询订单\n    Order order = orderMapper.findById(orderId);\n    // 2. 利用 RestTemplate 发起 http 请求，查询用户\n    String url = \"http://localhost:8081/user/\" + order.getUserId();\n    User user = restTemplate.getForObject(url, User.class);\n    // 3. 封装 user 到 Order\n    order.setUser(user);\n    // 4.返回\n    return order;\n}\n```\n\n代码：[链接](https://github.com/Lanqilu/HaloSpringCloud/tree/44482f1ec6618da6ee5805fbbdc5c0c2464725bb)\n\n### 提供者与消费者\n\n在服务调用关系中，会有两个不同的角色：\n\n+ 服务提供者：一次业务中，被其它微服务调用的服务。（提供接口给其它微服务）\n+ 服务消费者：一次业务中，调用其它微服务的服务。（调用其它微服务提供的接口）\n\n但是，服务提供者与服务消费者的角色并不是绝对的，而是相对于业务而言。如果服务 A 调用了服务 B，而服务 B 又调用了服务 C，服务 B 的角色是什么？\n\n- 对于 A 调用 B 的业务而言：A 是服务消费者，B 是服务提供者\n- 对于 B 调用 C 的业务而言：B 是服务消费者，C 是服务提供者\n\n因此，服务 B 既可以是服务提供者，也可以是服务消费者。\n\n## Eureka 注册中心\n\n以上实例存在的问题：\n\n- order-service 在发起远程调用的时候，该如何得知 user-service 实例的 ip 地址和端口？\n- 有多个 user-service 实例地址，order-service 调用时该如何选择？\n- order-service 如何得知某个 user-service 实例是否依然健康，是不是已经宕机？\n\n### Eureka 的结构和作用\n\n![Eureka的作用](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Eureka的作用.mzzzu1u538w.svg)\n\n问题1：order-service 如何得知 user-service 实例地址？获取地址信息的流程如下：\n\n- user-service 服务实例启动后，将自己的信息注册到 eureka-server（Eureka 服务端）。这个叫服务注册\n- eureka-server 保存服务名称到服务实例地址列表的映射关系\n- order-service 根据服务名称，拉取实例地址列表。这个叫服务发现或服务拉取\n\n问题2：order-service 如何从多个 user-service 实例中选择具体的实例？\n\n- order-service 从实例列表中利用负载均衡算法选中一个实例地址\n- 向该实例地址发起远程调用\n\n问题3：order-service 如何得知某个 user-service 实例是否依然健康，是不是已经宕机？\n\n- user-service 会每隔一段时间（默认 30 秒）向 eureka-server 发起请求，报告自己状态，称为心跳\n- 当超过一定时间没有发送心跳时，eureka-server 会认为微服务实例故障，将该实例从服务列表中剔除\n- order-service 拉取服务时，就能将故障实例排除了\n\n在 Eureka 架构中，微服务角色有两类：\n\n+ EurekaServer：服务端，注册中心。记录服务信息、心跳监控\n+ EurekaClient：客户端\n  + Provider：服务提供者，例如案例中的 user-service。注册自己的信息到 EurekaServer、每隔 30 秒向 EurekaServer 发送心跳\n  + Consumer：服务消费者，例如案例中的 order-service 根据服务名称从 EurekaServer 拉取服务列表基于服务列表做负载均衡，选中一个微服务后发起远程调用\n\n> 注意：一个微服务，既可以是服务提供者，又可以是服务消费者，因此 eureka 将服务注册、服务发现等功能统一封装到了eureka-client 端\n\neureka 服务注册分为以下步骤：\n\n+ 搭建注册中心：搭建 EurekaServer\n+ 服务注册：将 user-service、order-service 都注册到 eureka\n+ 服务发现：在 order-service 中完成服务拉取，然后通过负载均衡挑选一个服务，实现远程调用\n\n### 搭建 eureka-server\n\n首先大家注册中心服务端：eureka-server，这必须是一个独立的微服务\n\n创建 eureka-server 服务，在 spring-cloud-demo 父工程下，创建 eureka-server Maven 子模块\n\n引入 eureka 依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-eureka-server</artifactId>\n</dependency>\n```\n\n#### 编写启动类\n\n给 eureka-server 服务编写一个启动类，一定要添加一个 `@EnableEurekaServer` 注解，开启 eureka 的注册中心功能：\n\n```java\npackage cn.itcast.eureka;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\nimport org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;\n\n@SpringBootApplication\n@EnableEurekaServer\npublic class EurekaApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(EurekaApplication.class, args);\n    }\n}\n```\n\n#### 编写配置文件\n\n编写一个 application.yml 文件，内容如下：\n\n```yaml\nserver:\n  port: 10086 # 服务端口\nspring:\n  application:\n    name: eureka-server # 服务名称 必须\neureka:\n  client:\n    service-url: # eureka 的地址信息\n      defaultZone: http://127.0.0.1:10086/eureka\n```\n\n#### 启动服务\n\n启动微服务，然后在浏览器访问：http://127.0.0.1:10086\n\n看到下面结果应该是成功了：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3fxbktup2b40.png)\n\n代码：[链接](https://github.com/Lanqilu/HaloSpringCloud/tree/6485893c857e8407573b163f91fd7b6b7cfd4cfe)\n\n### Eureka 服务注册\n\n下面，我们将 user-service 注册到 eureka-server 中去\n\n#### 引入依赖\n\n在 user-service 的 pom 文件中，引入下面的 eureka-client 依赖：\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-netflix-eureka-client</artifactId>\n</dependency>\n```\n\n#### 修改配置文件\n\n在 user-service 中，修改 application.yml 文件，添加服务名称、eureka 地址：\n\n```yaml\nspring:\n  application:\n    name: user-service\neureka:\n  client:\n    service-url:\n      defaultZone: http://127.0.0.1:10086/eureka\n```\n\n用同样的方法可以注册 order-service\n\n#### 启动多个 user-service 实例\n\n为了演示一个服务有多个实例的场景，我们添加一个 SpringBoot 的启动配置，再启动一个 user-service。\n\n首先，复制原来的 user-service 启动配置：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.1oxav2o4lv7k.png)\n\n然后，在弹出的窗口中，填写信息：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.acb3rk5x180.png)\n\n启动两个 user-service 实例后，查看 eureka-server 管理页面：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.4tnhuetb1yc0.png)\n\n### Eureka 服务发现\n\n下面，我们将 order-service 的逻辑修改：向 eureka-server 拉取 user-service 的信息，实现服务发现。\n\n#### 引入依赖和修改配置文件\n\n之前说过，服务发现、服务注册统一都封装在 eureka-client 依赖，因此这一步与服务注册时一致。\n\n#### 服务拉取和负载均衡\n\n去 eureka-server 中拉取 user-service 服务的实例列表，并且实现负载均衡。\n\n在 order-service 的 OrderApplication 中，给 RestTemplate 这个 Bean 添加一个 `@LoadBalanced` 注解：\n\n```java\n/**\n * 创建 RestTemplate 并注入容器\n */\n@Bean\n@LoadBalanced\npublic RestTemplate restTemplate(){\n    return new RestTemplate();\n}\n```\n\n修改 order-service 服务中的 cn.itcast.order.service 包下的 OrderService 类中的queryOrderById 方法。修改访问的 url 路径，用服务名代替 ip、端口：\n\n```java\npublic Order queryOrderById(Long orderId) {\n    // 1.查询订单\n    Order order = orderMapper.findById(orderId);\n    // 2. 利用 RestTemplate 发起 http 请求，查询用户\n    String url = \"http://user-service/user/\" + order.getUserId();\n    User user = restTemplate.getForObject(url, User.class);\n    // 3. 封装 user 到 Order\n    order.setUser(user);\n    // 4.返回\n    return order;\n}\n```\n\nspring 会自动帮助我们从 eureka-server 端，根据 userservice 这个服务名称，获取实例列表，而后完成负载均衡（默认轮询）。\n\n### Eureka 注册中心小结\n\n1. 搭建 EurekaServer\n   + 引入 eureka-server 依赖\n   + 添加 `@EnableEurekaServer` 注解\n   + 在 application.yml 中配置 eureka 地址\n2. 服务注册\n   + 引入 eureka-client 依赖\n   + 在 application.yml 中配置 eureka 地址\n3. 服务发现\n   + 引入 eureka-client 依赖\n   + 在 application.yml 中配置 eureka 地址\n   + 给 RestTemplate 添加 `@LoadBalanced` 注解\n   + 用服务提供者的服务名称远程调用\n\n## Ribbon 负载均衡\n\n上一节中，我们添加了 @LoadBalanced 注解，即可实现负载均衡功能，这是什么原理呢？\n\n### 负载均衡原理\n\nSpring Cloud 底层其实是利用了一个名为 Ribbon 的组件，来实现负载均衡功能的。\n\n![Ribbon负载均衡流程](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Ribbon负载均衡流程.2mk0jmuwdoq0.svg)\n\n### 源码跟踪\n\n为什么我们只输入了 service 名称就可以访问了呢？之前还要获取 ip 和端口。\n\n显然有人帮我们根据 service 名称，获取到了服务实例的 ip 和端口。它就是 `LoadBalancerInterceptor`，这个类会在对 RestTemplate 的请求进行拦截，然后从 Eureka 根据服务 id 获取服务列表，随后利用负载均衡算法得到真实的服务地址信息，替换服务 id。\n\n我们进行源码跟踪：\n\n#### LoadBalancerIntercepor\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5mxujbposco0.png)\n\n可以看到这里的 intercept 方法，拦截了用户的 HttpRequest 请求，然后做了几件事：\n\n- `request.getURI()`：获取请求 url，本例中就是 http://user-service/user/8\n- `originalUri.getHost()`：获取 uri 路径的主机名，其实就是服务 id，`user-service`\n- `this.loadBalancer.execute()`：处理服务 id，和用户请求。\n\n这里的 `this.loadBalancer` 是 `LoadBalancerClient` 类型，我们继续跟入。\n\n#### LoadBalancerClient\n\n继续跟入 execute 方法：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.66vjvvg0xn40.png)\n\n代码是这样的：\n\n- `getLoadBalancer(serviceId)`：根据服务 id 获取 ILoadBalancer，而 ILoadBalancer 会拿着服务 id 去 eureka 中获取服务列表并保存起来。\n- `getServer(loadBalancer)`：利用内置的负载均衡算法，从服务列表中选择一个。本例中，可以看到获取了8081端口的服务\n\n#### 负载均衡策略 IRule\n\n在刚才的代码中，可以看到获取服务使通过一个 `getServer` 方法来做负载均衡:\n\n我们继续跟入：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3vkjab3blgm0.png)\n\n继续跟踪源码 chooseServer 方法，发现调用父类中 BaseLoadBalancer 一段代码：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.4ks2tojsyxe0.png)\n\n我们看看这个 rule 是谁：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.2jcbindlmai0.png)\n\n默认是使用轮询，到这里，整个负载均衡的流程我们就清楚了。\n\n#### 负载均衡原理源码分析小结\n\nSpring Cloud Ribbon 的底层采用了一个拦截器，拦截了 RestTemplate 发出的请求，对地址做了修改。基本流程如下：\n\n- 拦截我们的 RestTemplate 请求 http://userservice/user/1\n- RibbonLoadBalancerClient 会从请求 url 中获取服务名称，也就是 user-service\n- DynamicServerListLoadBalancer 根据 user-service 到 eureka 拉取服务列表\n- eureka 返回列表，localhost:8081、localhost:8082\n- IRule 利用内置负载均衡规则，从列表中选择一个，例如 localhost:8081\n- RibbonLoadBalancerClient 修改请求地址，用 localhost:8081 替代 userservice，得到 http://localhost:8081/user/1，发起真实请求\n\n### 负载均衡策略\n\n负载均衡的规则都定义在 IRule 接口中，而 IRule 有很多不同的实现类：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.61x1c4fc6pg0.png)\n\n常见的不同规则的含义如下：\n\n1. RoundRobinRule：  简单轮询服务列表来选择服务器。它是 Ribbon 默认的负载均衡规则。\n2. AvailabilityFilteringRule：对以下两种服务器进行忽略\n   + 在默认情况下，这台服务器如果 3 次连接失败，这台服务器就会被设置为“短路”状态。短路状态将持续 30 秒，如果再次连接失败，短路的持续时间就会几何级地增加。\n   +  并发数过高的服务器。如果一个服务器的并发连接数过高，配置了 AvailabilityFilteringRule 规则的客户端也会将其忽略。并发连接数的上限，可以由客户端的`<clientName>.<clientConfigNameSpace>.ActiveConnectionsLimit `属性进行配置。\n3. WeightedResponseTimeRule：为每一个服务器赋予一个权重值。服务器响应时间越长，这个服务器的权重就越小。这个规则会随机选择服务器，这个权重值会影响服务器的选择。\n4. ZoneAvoidanceRule：以区域可用的服务器为基础进行服务器的选择。使用 Zone 对服务器进行分类，这个 Zone 可以理解为一个机房、一个机架等。而后再对 Zone 内的多个服务做轮询。\n5. BestAvailableRule：忽略那些短路的服务器，并选择并发数较低的服务器。\n6. RandomRule：随机选择一个可用的服务器。\n7. RetryRule：  重试机制的选择逻辑\n\n默认的实现就是 ZoneAvoidanceRule，是一种轮询方案\n\n#### 自定义负载均衡策略\n\n通过定义 IRule 实现可以修改负载均衡规则，有两种方式：\n\n代码方式：在 order-service 中的 OrderApplication 类（或配置类）中，定义一个新的 IRule：\n\n```java\n@Bean\npublic IRule randomRule(){\n    return new RandomRule();\n}\n```\n\n配置文件方式：在 order-service 的 application.yml 文件中，添加新的配置也可以修改规则：\n\n```yaml\nuser-service: # 给某个微服务配置负载均衡规则，这里是user-service服务\n  ribbon:\n    NFLoadBalancerRuleClassName: com.netflix.loadbalancer.RandomRule # 负载均衡规则 \n```\n\n代码方式针对全局，配置文件方式可以对某个服务进行配置\n\n一般用默认的负载均衡规则，不做修改。\n\n#### 饥饿加载\n\nRibbon 默认是采用懒加载，即第一次访问时才会去创建 LoadBalanceClient，请求时间会很长。\n\n而饥饿加载则会在项目启动时创建，降低第一次访问的耗时，通过下面配置开启饥饿加载：\n\n```yaml\nribbon:\n  eager-load: \n    enabled: true # 开启饥饿加载\n    clients: user-service # 指定对 user-service 这个服务进行加载\n```\n\n### Ribbon 负载均衡小结\n\n1. Ribbon 负载均衡规则：\n   + 规则接口是 IRule\n   + 默认实现是 ZoneAvoidanceRule，根据 zone 选择服务列表，然后轮询\n2. 负载均衡自定义方式：\n   + 代码方式：配置灵活，但修改时需要重新打包发布\n   + 配置方式：直观，方便，无需重新打包发布，但是无法做全局配置\n3. 饥饿加载\n   + 开启饥饿加载，配置文件\n   + 指定饥饿加载的微服务名称，多个 clients 使用 yaml 列表\n\n## Nacos 注册中心\n\n### 认识和安装 Nacos\n\n[Nacos](https://nacos.io/) 是阿里巴巴的产品，现在是 [SpringCloud](https://spring.io/projects/spring-cloud) 中的一个组件。相比 [Eureka](https://github.com/Netflix/eureka) 功能更加丰富，在国内受欢迎程度较高。\n\nDocker 安装：[官网](https://nacos.io/zh-cn/docs/quick-start-docker.html)\n\n### 服务注册到 Nacos\n\nNacos 是 Spring Cloud Alibaba 的组件，而 Spring Cloud Alibaba 也遵循 Spring Cloud 中定义的服务注册、服务发现规范。因此使用 Nacos 和使用 Eureka 对于微服务来说，并没有太大区别。其主要差异在于：依赖不同、服务地址不同。\n\n#### 引入 Nacos 依赖\n\n在 spring-cloud-demo 父工程的 pom 文件中的 `<dependencyManagement>` 中引入 Spring Cloud Alibaba 的依赖：\n\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-alibaba-dependencies</artifactId>\n    <version>2.2.6.RELEASE</version>\n    <type>pom</type>\n    <scope>import</scope>\n</dependency>\n```\n\n然后在 user-service 和 order-service 中的 pom 文件中引入 nacos-discovery 依赖：\n\n```xml\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n\n> 注意：不要忘了注释掉 eureka 的依赖。\n\n#### 配置 Nacos 地址\n\n在 user-service 和 order-service 的 application.yml 中添加 nacos 地址：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      server-addr: n:8848\n```\n\n> 这里使用的是远程服务器的地址\n\n#### 启动项目\n\n启动 user-service 和 order-service 浏览器输入 http://halo:8848/nacos/ 账号密码默认都为 nacos，项目成功可以看到服务列表中的服务。  \n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.6jgz8xeif3g0.png)\n\n### 服务分级存储模型\n\n一个**服务**可以有多个**实例**，例如我们的 user-service，可以有:\n\n- 127.0.0.1:8081\n- 127.0.0.1:8082\n- 127.0.0.1:8083\n\n假如这些实例分布于全国各地的不同机房，例如：\n\n- 127.0.0.1:8081，在上海机房\n- 127.0.0.1:8082，在上海机房\n- 127.0.0.1:8083，在杭州机房\n\nNacos 就将同一机房内的实例划分为一个**集群**。\n\n也就是说，user-service 是服务，一个服务可以包含多个集群，如杭州、上海，每个集群下可以有多个实例，形成分级模型，如图：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.2mxp9c1ugiw0.png)\n\n微服务互相访问时，应该尽可能访问同集群实例，因为本地访问速度更快。当本集群内不可用时，才访问其它集群。例如：杭州机房内的 order-service 应该优先访问同机房的 user-service。\n\n#### 给 user-service 配置集群\n\n修改 user-service 的 application.yml 文件，添加集群配置：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      server-addr: halo:8848\n      discovery:\n        cluster-name: HZ # 集群名称\n```\n\n重启两个 user-service 实例后，我们再次复制一个 user-service 启动配置，添加属性：\n\n```sh\n-Dserver.port=8083 -Dspring.cloud.nacos.discovery.cluster-name=SH\n```\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.1piv5isgkpb4.png)\n\n我们可以在 Nacos 控制台看到下面结果：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3pz2tkuveru0.png)\n\n#### 同集群优先的负载均衡\n\n默认的 `ZoneAvoidanceRule` 并不能实现根据同集群优先来实现负载均衡。\n\n因此 Nacos 中提供了一个 `NacosRule` 的实现，可以优先从同集群中挑选实例。\n\n首先给 order-service 配置集群信息，方法同上一节\n\n修改 order-service 的 application.yml 文件，添加集群配置：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      server-addr: halo:8848\n      discovery:\n        cluster-name: HZ # 集群名称\n```\n\n修改负载均衡规则。修改 order-service 的 application.yml 文件，修改负载均衡规则：\n\n```yaml\nuser-service:\n  ribbon:\n    NFLoadBalancerRuleClassName: com.alibaba.cloud.nacos.ribbon.NacosRule # 负载均衡规则\n```\n\n本地集群中采用随机\n\nNacos Rule 负载均衡策略\n\n1. 优先选择同集群服务实例列表\n2. 本地集群找不到提供者，才去其它集群寻找，并且会报警告\n3. 确定了可用实例列表后，再采用随机负载均衡挑选实例\n\n### 权重配置\n\n实际部署中会出现这样的场景：服务器设备性能有差异，部分实例所在机器性能较好，另一些较差，我们希望性能好的机器承担更多的用户请求。\n\n但默认情况下 Nacos Rule 是同集群内随机挑选，不会考虑机器的性能问题。\n\n因此，Nacos 提供了权重配置来控制访问频率，权重越大则访问频率越高。\n\n在 Nacos 控制台，找到 user-service 的实例列表，点击编辑，即可修改权重：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5bywq83lkh00.png)\n\n> 注意：如果权重修改为 0，则该实例永远不会被访问\n\n### 环境隔离\n\nNacos 提供了 namespace 来实现环境隔离功能。\n\n- Nacos 中可以有多个 namespace\n- namespace 下可以有 group、service 等\n- 不同 namespace 之间相互隔离，例如不同 namespace 的服务互相不可见\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.33r23m595e00.png)\n\n#### 创建 namespace\n\n默认情况下，所有 service、data、group 都在同一个 namespace，名为 public：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3ebpxcypny00.png)\n\n我们可以点击页面新增按钮，添加一个 namespace\n\n#### 给微服务配置 namespace\n\n给微服务配置 namespace 只能通过修改配置来实现。\n\n例如，修改 order-service 的 application.yml 文件：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      server-addr: halo:8848\n      discovery:\n        cluster-name: HZ\n        namespace: 45e30304-1b64-4c21-8c83-22309949af10 # 命名空间，填ID\n```\n\n重启 order-service 后，访问控制台，可以看到下面的结果：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.7fljcch1djg0.png)\n\n此时访问 order-service，因为 namespace 不同，会导致找不到 user-service，控制台会报错：\n\n```\n09-09 22:11:49:886 ERROR 4100 --- [nio-8080-exec-1] o.a.c.c.C.[.[.[/].[dispatcherServlet]    : Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.lang.IllegalStateException: No instances available for user-service] with root cause\n```\n\n## Nacos 与 Eureka 的异同\n\n### Nacos 服务实例类型\n\nNacos 的服务实例分为两种类型：\n\n- 临时实例：如果实例宕机超过一定时间，会从服务列表剔除，默认的类型。\n- 非临时实例：如果实例宕机，不会从服务列表剔除，也可以叫永久实例。\n\n配置一个服务实例为永久实例：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      discovery:\n        ephemeral: false # 设置为非临时实例\n```\n\n### Nacos 注册中心原理\n\nNacos 和 Eureka 整体结构类似，服务注册、服务拉取、心跳等待，但是也存在一些差异：\n\n![Nacos注册中心原理](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Nacos注册中心原理.vsk7w614iqo.svg)\n\n### Nacos 与 Eureka 的共同点\n\n- 都支持服务注册和服务拉取\n- 都支持服务提供者心跳方式做健康检测\n\n### Nacos 与 Eureka 的区别\n\n- Nacos 支持服务端主动检测提供者状态：临时实例采用心跳模式，非临时实例采用主动检测模式\n- 临时实例心跳不正常会被剔除，非临时实例则不会被剔除\n- Nacos 支持服务列表变更的消息推送模式，服务列表更新更及时\n- Nacos 集群默认采用 AP 方式，当集群中存在非临时实例时，采用 CP 模式；Eureka采用 AP 方式\n\n## Nacos 配置管理\n\nNacos 除了可以做注册中心，也可以做配置管理来使用。\n\n### 统一配置管理\n\n当微服务部署的实例越来越多，达到数十、数百时，逐个修改微服务配置就会让人抓狂，而且很容易出错。我们需要一种统一配置管理方案，可以集中管理所有实例的配置。\n\nNacos 一方面可以将配置集中管理，另一方可以在配置变更时，及时通知微服务，实现配置的热更新。\n\n#### 在 Nacos 中添加配置文件\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.1k2q3p4hypa8.png)\n\n然后在弹出的表单中，填写配置信息：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.26dw95t2zibk.png)\n\n> 注意：项目的核心配置，需要热更新的配置才有放到 Nacos 管理的必要。基本不会变更的一些配置还是保存在微服务本地比较好。\n\n#### 从微服务拉取配置\n\n微服务要拉取 Nacos 中管理的配置，并且与本地的 application.yml 配置合并，才能完成项目启动。\n\n但如果尚未读取 application.yml，又如何得知 Nacos 地址呢？\n\n因此 Spring 引入了一种新的配置文件：bootstrap.yaml 文件，会在 application.yml 之前被读取，流程如下：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.50gh2h1avrw0.png)\n\n① 引入 nacos-config 依赖\n\n首先，在 user-service 服务中，引入 nacos-config 的客户端依赖：\n\n```xml\n<!--nacos配置管理依赖-->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-config</artifactId>\n</dependency>\n```\n\n② 添加 bootstrap.yaml\n\n然后，在 user-service 中添加一个 bootstrap.yaml 文件，内容如下：\n\n```yaml\nspring:\n  application:\n    name: user-service # 服务名称\n  profiles:\n    active: dev # 开发环境，这里是 dev \n  cloud:\n    nacos:\n      server-addr: halo:8848 # Nacos地址\n      config:\n        file-extension: yaml # 文件后缀名\n```\n\n这里会根据 `spring.cloud.nacos.server-addr` 获取 Nacos 地址，再根据 `${spring.application.name}-${spring.profiles.active}.${spring.cloud.nacos.config.file-extension}` 作为文件 id，来读取配置。\n\n本例中，就是去读取 `user-service-dev.yaml`：\n\n③ 读取 Nacos 配置\n\n在 user-service 中的 `UserController` 中添加业务逻辑，读取 `pattern.dateformat` 配置：\n\n```java\n@Value(\"${pattern.dateformat}\")\nprivate String dateformat;\n\n@GetMapping(\"now\")\npublic String now() {\n    return LocalDateTime.now().format(DateTimeFormatter.ofPattern(dateformat));\n}\n```\n\n### 配置热更新\n\n我们最终的目的，是修改 Nacos 中的配置后，微服务中无需重启即可让配置生效，也就是配置热更新。\n\n要实现配置热更新，可以使用两种方式：\n\n#### 方式一\n\n在 `@Value` 注入的变量所在类上添加注解 `@RefreshScope`：\n\n```java\n@Slf4j\n@RestController\n@RequestMapping(\"/user\")\n@RefreshScope\npublic class UserController {\n    @Value(\"${pattern.dateformat}\")\n    private String dateformat;\n    \n    // 略\n}\n```\n\n#### 方式二\n\n使用 `@ConfigurationProperties` 注解代替 `@Value` 注解。\n\n在 user-service 服务中，添加一个类，读取 `patterrn.dateformat` 属性：\n\n```java\npackage cn.itcast.user.config;\n\nimport lombok.Data;\nimport org.springframework.boot.context.properties.ConfigurationProperties;\nimport org.springframework.stereotype.Component;\n\n@Component\n@Data\n@ConfigurationProperties(prefix = \"pattern\")\npublic class PatternProperties {\n    private String dateformat;\n}\n```\n\n在 `UserController` 中使用这个类代替 `@Value`：\n\n```java\n@Autowired\nprivate PatternProperties properties;\n\n@GetMapping(\"now\")\npublic String now() {\n    return LocalDateTime.now().format(DateTimeFormatter.ofPattern(properties.getDateformat()));\n}\n```\n\n### 配置共享\n\n其实微服务启动时，会去 Nacos 读取多个配置文件，例如：\n\n- `[spring.application.name]-[spring.profiles.active].yaml`，例如：user-service-dev.yaml\n\n- `[spring.application.name].yaml`，例如：user-service.yaml\n\n而 `[spring.application.name].yaml` 不包含环境，因此可以被多个环境共享。\n\n下面我们通过案例来测试配置共享\n\n#### 添加一个环境共享配置\n\n在 Nacos 中添加一个 user-service.yaml 文件：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.4j1r0ype41k0.png)\n\n#### 在 user-service 中读取共享配置\n\n在 user-service 服务中，修改 `PatternProperties` 类，读取新添加的属性：\n\n```java\n@Data\n@Component\n@ConfigurationProperties(prefix = \"pattern\")\npublic class PatternProperties {\n    private String dateformat;\n    private String envShareValue;\n}\n```\n\n在 user-service 服务中，修改 `UserController`，添加一个方法：\n\n```java\n@Autowired\nprivate PatternProperties properties;\n\n@GetMapping(\"prop\")\npublic PatternProperties prop(){\n    return properties;\n}\n```\n\n#### 不同的 profile 下测试\n\n运行两个 UserApplication，使用不同的 profile。修改 UserApplication2 这个启动项，改变其 profile 值：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5fmr356kyr80.png)\n\n这样，UserApplication（8081） 使用的 profile 是 dev，UserApplication2（8082） 使用的 profile 是 test。\n\n启动 UserApplication 和 UserApplication2\n\n可以看出来，不管是 dev，还是 test 环境，都读取到了envSharedValue 这个属性的值。\n\n#### 配置共享的优先级\n\n当 Nacos、服务本地同时出现相同属性时，优先级有高低之分，优先级从高到低依次是：\n\n+ 服务名-[profile].yaml\n+ 服务名.yaml\n+ 本地配置\n\n## 搭建 Nacos 集群\n\n计划的集群结构：\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.3v4vof6qfki0.png)\n\n三个 nacos 节点的地址：\n\n| 节点   | ip   | port |\n| ------ | ---- | ---- |\n| nacos1 | halo | 8845 |\n| nacos2 | halo | 8846 |\n| nacos3 | halo | 8847 |\n\n搭建集群的基本步骤：\n\n- 搭建数据库，初始化数据库表结构\n- 下载 Nacos 安装包\n- 配置 Nacos\n- 启动 Nacos 集群\n- Nginx 反向代理\n\n### 初始化数据库\n\nNacos 默认数据存储在内嵌数据库 Derby 中，不属于生产可用的数据库。\n\n这里我们以单点的数据库为例来讲解。\n\n首先新建一个数据库，命名为 nacos，而后导入下面的 SQL：\n\n```sql\nCREATE TABLE `config_info` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \'id\',\n  `data_id` varchar(255) NOT NULL COMMENT \'data_id\',\n  `group_id` varchar(255) DEFAULT NULL,\n  `content` longtext NOT NULL COMMENT \'content\',\n  `md5` varchar(32) DEFAULT NULL COMMENT \'md5\',\n  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'创建时间\',\n  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'修改时间\',\n  `src_user` text COMMENT \'source user\',\n  `src_ip` varchar(50) DEFAULT NULL COMMENT \'source ip\',\n  `app_name` varchar(128) DEFAULT NULL,\n  `tenant_id` varchar(128) DEFAULT \'\' COMMENT \'租户字段\',\n  `c_desc` varchar(256) DEFAULT NULL,\n  `c_use` varchar(64) DEFAULT NULL,\n  `effect` varchar(64) DEFAULT NULL,\n  `type` varchar(64) DEFAULT NULL,\n  `c_schema` text,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_configinfo_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'config_info\';\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = config_info_aggr   */\n/******************************************/\nCREATE TABLE `config_info_aggr` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \'id\',\n  `data_id` varchar(255) NOT NULL COMMENT \'data_id\',\n  `group_id` varchar(255) NOT NULL COMMENT \'group_id\',\n  `datum_id` varchar(255) NOT NULL COMMENT \'datum_id\',\n  `content` longtext NOT NULL COMMENT \'内容\',\n  `gmt_modified` datetime NOT NULL COMMENT \'修改时间\',\n  `app_name` varchar(128) DEFAULT NULL,\n  `tenant_id` varchar(128) DEFAULT \'\' COMMENT \'租户字段\',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_configinfoaggr_datagrouptenantdatum` (`data_id`,`group_id`,`tenant_id`,`datum_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'增加租户字段\';\n\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = config_info_beta   */\n/******************************************/\nCREATE TABLE `config_info_beta` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \'id\',\n  `data_id` varchar(255) NOT NULL COMMENT \'data_id\',\n  `group_id` varchar(128) NOT NULL COMMENT \'group_id\',\n  `app_name` varchar(128) DEFAULT NULL COMMENT \'app_name\',\n  `content` longtext NOT NULL COMMENT \'content\',\n  `beta_ips` varchar(1024) DEFAULT NULL COMMENT \'betaIps\',\n  `md5` varchar(32) DEFAULT NULL COMMENT \'md5\',\n  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'创建时间\',\n  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'修改时间\',\n  `src_user` text COMMENT \'source user\',\n  `src_ip` varchar(50) DEFAULT NULL COMMENT \'source ip\',\n  `tenant_id` varchar(128) DEFAULT \'\' COMMENT \'租户字段\',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_configinfobeta_datagrouptenant` (`data_id`,`group_id`,`tenant_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'config_info_beta\';\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = config_info_tag   */\n/******************************************/\nCREATE TABLE `config_info_tag` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \'id\',\n  `data_id` varchar(255) NOT NULL COMMENT \'data_id\',\n  `group_id` varchar(128) NOT NULL COMMENT \'group_id\',\n  `tenant_id` varchar(128) DEFAULT \'\' COMMENT \'tenant_id\',\n  `tag_id` varchar(128) NOT NULL COMMENT \'tag_id\',\n  `app_name` varchar(128) DEFAULT NULL COMMENT \'app_name\',\n  `content` longtext NOT NULL COMMENT \'content\',\n  `md5` varchar(32) DEFAULT NULL COMMENT \'md5\',\n  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'创建时间\',\n  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'修改时间\',\n  `src_user` text COMMENT \'source user\',\n  `src_ip` varchar(50) DEFAULT NULL COMMENT \'source ip\',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_configinfotag_datagrouptenanttag` (`data_id`,`group_id`,`tenant_id`,`tag_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'config_info_tag\';\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = config_tags_relation   */\n/******************************************/\nCREATE TABLE `config_tags_relation` (\n  `id` bigint(20) NOT NULL COMMENT \'id\',\n  `tag_name` varchar(128) NOT NULL COMMENT \'tag_name\',\n  `tag_type` varchar(64) DEFAULT NULL COMMENT \'tag_type\',\n  `data_id` varchar(255) NOT NULL COMMENT \'data_id\',\n  `group_id` varchar(128) NOT NULL COMMENT \'group_id\',\n  `tenant_id` varchar(128) DEFAULT \'\' COMMENT \'tenant_id\',\n  `nid` bigint(20) NOT NULL AUTO_INCREMENT,\n  PRIMARY KEY (`nid`),\n  UNIQUE KEY `uk_configtagrelation_configidtag` (`id`,`tag_name`,`tag_type`),\n  KEY `idx_tenant_id` (`tenant_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'config_tag_relation\';\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = group_capacity   */\n/******************************************/\nCREATE TABLE `group_capacity` (\n  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \'主键ID\',\n  `group_id` varchar(128) NOT NULL DEFAULT \'\' COMMENT \'Group ID，空字符表示整个集群\',\n  `quota` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'配额，0表示使用默认值\',\n  `usage` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'使用量\',\n  `max_size` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'单个配置大小上限，单位为字节，0表示使用默认值\',\n  `max_aggr_count` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'聚合子配置最大个数，，0表示使用默认值\',\n  `max_aggr_size` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值\',\n  `max_history_count` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'最大变更历史数量\',\n  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'创建时间\',\n  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'修改时间\',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_group_id` (`group_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'集群、各Group容量信息表\';\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = his_config_info   */\n/******************************************/\nCREATE TABLE `his_config_info` (\n  `id` bigint(64) unsigned NOT NULL,\n  `nid` bigint(20) unsigned NOT NULL AUTO_INCREMENT,\n  `data_id` varchar(255) NOT NULL,\n  `group_id` varchar(128) NOT NULL,\n  `app_name` varchar(128) DEFAULT NULL COMMENT \'app_name\',\n  `content` longtext NOT NULL,\n  `md5` varchar(32) DEFAULT NULL,\n  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP,\n  `src_user` text,\n  `src_ip` varchar(50) DEFAULT NULL,\n  `op_type` char(10) DEFAULT NULL,\n  `tenant_id` varchar(128) DEFAULT \'\' COMMENT \'租户字段\',\n  PRIMARY KEY (`nid`),\n  KEY `idx_gmt_create` (`gmt_create`),\n  KEY `idx_gmt_modified` (`gmt_modified`),\n  KEY `idx_did` (`data_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'多租户改造\';\n\n\n/******************************************/\n/*   数据库全名 = nacos_config   */\n/*   表名称 = tenant_capacity   */\n/******************************************/\nCREATE TABLE `tenant_capacity` (\n  `id` bigint(20) unsigned NOT NULL AUTO_INCREMENT COMMENT \'主键ID\',\n  `tenant_id` varchar(128) NOT NULL DEFAULT \'\' COMMENT \'Tenant ID\',\n  `quota` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'配额，0表示使用默认值\',\n  `usage` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'使用量\',\n  `max_size` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'单个配置大小上限，单位为字节，0表示使用默认值\',\n  `max_aggr_count` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'聚合子配置最大个数\',\n  `max_aggr_size` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'单个聚合数据的子配置大小上限，单位为字节，0表示使用默认值\',\n  `max_history_count` int(10) unsigned NOT NULL DEFAULT \'0\' COMMENT \'最大变更历史数量\',\n  `gmt_create` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'创建时间\',\n  `gmt_modified` datetime NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT \'修改时间\',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_tenant_id` (`tenant_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'租户容量信息表\';\n\n\nCREATE TABLE `tenant_info` (\n  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT \'id\',\n  `kp` varchar(128) NOT NULL COMMENT \'kp\',\n  `tenant_id` varchar(128) default \'\' COMMENT \'tenant_id\',\n  `tenant_name` varchar(128) default \'\' COMMENT \'tenant_name\',\n  `tenant_desc` varchar(256) DEFAULT NULL COMMENT \'tenant_desc\',\n  `create_source` varchar(32) DEFAULT NULL COMMENT \'create_source\',\n  `gmt_create` bigint(20) NOT NULL COMMENT \'创建时间\',\n  `gmt_modified` bigint(20) NOT NULL COMMENT \'修改时间\',\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `uk_tenant_info_kptenantid` (`kp`,`tenant_id`),\n  KEY `idx_tenant_id` (`tenant_id`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COLLATE=utf8_bin COMMENT=\'tenant_info\';\n\nCREATE TABLE `users` (\n	`username` varchar(50) NOT NULL PRIMARY KEY,\n	`password` varchar(500) NOT NULL,\n	`enabled` boolean NOT NULL\n);\n\nCREATE TABLE `roles` (\n	`username` varchar(50) NOT NULL,\n	`role` varchar(50) NOT NULL,\n	UNIQUE INDEX `idx_user_role` (`username` ASC, `role` ASC) USING BTREE\n);\n\nCREATE TABLE `permissions` (\n    `role` varchar(50) NOT NULL,\n    `resource` varchar(255) NOT NULL,\n    `action` varchar(8) NOT NULL,\n    UNIQUE INDEX `uk_role_permission` (`role`,`resource`,`action`) USING BTREE\n);\n\nINSERT INTO users (username, password, enabled) VALUES (\'nacos\', \'$2a$10$EuWPZHzz32dJN7jexM34MOeYirDdFAZm2kuWj7VEOJhhZkDrxfvUu\', TRUE);\n\nINSERT INTO roles (username, role) VALUES (\'nacos\', \'ROLE_ADMIN\');\n```\n\n### 下载 Nacos\n\nNacos 在 GitHub 上有下载地址：https://github.com/alibaba/nacos/tags，可以选择任意版本下载。\n\n本例中才用 1.4.1 版本\n\n### 配置 Nacos\n\n将这个包解压到任意非中文目录下\n\n- bin：启动脚本\n- conf：配置文件\n\n进入 Nacos 的 conf 目录，修改配置文件 cluster.conf.example，重命名为 cluster.conf\n\n![image](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/image.5nlh9ki5w2s0.png)\n\n然后添加内容：\n\n```\n127.0.0.1:8845\n127.0.0.1.8846\n127.0.0.1.8847\n```\n\n然后修改 application.properties 文件，添加数据库配置\n\n```\nspring.datasource.platform=mysql\n\ndb.num=1\n\ndb.url.0=jdbc:mysql://halo:3306/nacos?characterEncoding=utf8&connectTimeout=1000&socketTimeout=3000&autoReconnect=true&useUnicode=true&useSSL=false&serverTimezone=UTC\ndb.user.0=root\ndb.password.0=mogu2018\n```\n\n### 启动 Nacos\n\n将 nacos 文件夹复制三份，分别命名为：nacos1、nacos2、nacos3\n\n然后分别修改三个文件夹中的 application.properties，\n\nnacos1:\n\n```properties\nserver.port=8845\n```\n\nnacos2:\n\n```properties\nserver.port=8846\n```\n\nnacos3:\n\n```properties\nserver.port=8847\n```\n\n然后分别启动三个 nacos 节点：\n\n```\nstartup.cmd\n```\n\n### Nginx 反向代理\n\n修改 conf/nginx.conf 文件，配置如下：\n\n```\nupstream nacos-cluster {\n    server 127.0.0.1:8845;\n	server 127.0.0.1:8846;\n	server 127.0.0.1:8847;\n}\n\nserver {\n    listen       80;\n    server_name  localhost;\n\n    location /nacos {\n        proxy_pass http://nacos-cluster;\n    }\n}\n```\n\n而后在浏览器访问：http://localhost/nacos 即可。\n\n代码中 application.yml 文件配置如下：\n\n```yaml\nspring:\n  cloud:\n    nacos:\n      server-addr: localhost:80 # Nacos地址\n```\n\n- 实际部署时，需要给做反向代理的 Nginx 服务器设置一个域名，这样后续如果有服务器迁移 Nacos 的客户端也无需更改配置。\n\n- Nacos 的各个节点应该部署到多个不同服务器，做好容灾和隔离\n\n## Feign 远程调用\n\n先来看我们以前利用 RestTemplate 发起远程调用的代码：\n\n```java\n// 2. 利用 RestTemplate 发起 http 请求，查询用户\nString url = \"http://user-service/user/\" + order.getUserId();\nUser user = restTemplate.getForObject(url, User.class);\n```\n\n存在下面的问题：\n\n+ 代码可读性差，编程体验不统一\n+ 参数复杂 URL 难以维护\n\nFeign 是一个声明式的 http 客户端，官方地址：https://github.com/OpenFeign/feign\n\n其作用就是帮助我们优雅的实现 http 请求的发送，解决上面提到的问题。\n\n### Feign 替代 RestTemplate\n\nFeign 的使用步骤如下：\n\n#### 引入依赖\n\n我们在 order-service 服务的 pom 文件中引入 feign 的依赖：\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n```\n\n#### 添加注解\n\n在 order-service 的启动类添加 `@EnableFeignClients` 注解开启 Feign 的功能：\n\n```java\n@EnableFeignClients\n@MapperScan(\"cn.itcast.order.mapper\")\n@SpringBootApplication\npublic class OrderApplication {\n    public static void main(String[] args) {\n        SpringApplication.run(OrderApplication.class, args);\n    }\n}\n```\n\n#### 编写 Feign 的客户端\n\n在 order-service 中新建一个接口，内容如下：\n\n```java\npackage cn.itcast.order.clients;\n\nimport cn.itcast.order.pojo.User;\nimport org.springframework.cloud.openfeign.FeignClient;\nimport org.springframework.web.bind.annotation.GetMapping;\nimport org.springframework.web.bind.annotation.PathVariable;\n\n@FeignClient(\"user-service\")\npublic interface UserClient {\n    @GetMapping(\"/user/{id}\")\n    User findById(@PathVariable(\"id\") Long id);\n}\n```\n\n这个客户端主要是基于 SpringMVC 的注解来声明远程调用的信息，比如：\n\n- 服务名称：user-service\n- 请求方式：GET\n- 请求路径：/user/{id}\n- 请求参数：Long id\n- 返回值类型：User\n\n这样，Feign 就可以帮助我们发送 http 请求，无需自己使用 RestTemplate 来发送了。\n\n#### 测试\n\n修改 order-service 中的 `OrderService` 类中的 `queryOrderById` 方法，使用 Feign 客户端代替 RestTemplate：\n\n```java\n@Service\npublic class OrderService {\n\n    @Autowired\n    private OrderMapper orderMapper;\n\n    @Autowired\n    private UserClient userClient;\n\n    public Order queryOrderById(Long orderId) {\n        // 1.查询订单\n        Order order = orderMapper.findById(orderId);\n        // 2. 使用 Feign 进行远程调用\n        User user = userClient.findById(order.getUserId());\n        // 3. 封装 user 到 Order\n        order.setUser(user);\n        // 4.返回\n        return order;\n    }\n}\n```\n\n#### Feign 替代 RestTemplate 小结\n\n使用 Feign 的步骤：\n\n1. 引入依赖\n2. 添加 `@EnableFeignClients` 注解\n3. 编写 FeignClient 接口\n4. 使用 FeignClient 中定义的方法代替 RestTemplate\n\n### Feign 的自定义配置\n\nFeign 可以支持很多的自定义配置，如下表所示：\n\n| 类型                  | 作用             | 说明                                                        |\n| --------------------- | ---------------- | ----------------------------------------------------------- |\n| `feign.Logger.Level`  | 修改日志级别     | 包含四种不同的级别：NONE、BASIC、HEADERS、FULL              |\n| `feign.codec.Decoder` | 响应结果的解析器 | http 远程调用的结果做解析，例如解析 JSON 字符串为 Java 对象 |\n| `feign.codec.Encoder` | 请求参数编码     | 将请求参数编码，便于通过 http 请求发送                      |\n| `feign.Contract`      | 支持的注解格式   | 默认是 SpringMVC 的注解                                     |\n| `feign.Retryer`       | 失败重试机制     | 请求失败的重试机制，默认是没有，不过会使用Ribbon 的重试     |\n\n一般情况下，默认值就能满足我们使用，如果要自定义时，只需要创建自定义的 `@Bean` 覆盖默认Bean 即可。\n\n下面以日志为例来演示如何自定义配置。\n\n#### 配置文件方式\n\n基于配置文件修改 Feign 的日志级别可以针对单个服务：\n\n```yaml\nfeign:  \n  client:\n    config: \n      userservice: # 针对某个微服务的配置\n        loggerLevel: FULL # 日志级别 \n```\n\n也可以针对所有服务：\n\n```yaml\nfeign:  \n  client:\n    config: \n      default: # 这里用 default 就是全局配置，如果是写服务名称，则是针对某个微服务的配置\n        loggerLevel: FULL # 日志级别 \n```\n\n而日志的级别分为四种：\n\n- NONE：不记录任何日志信息，这是默认值。\n- BASIC：仅记录请求的方法，URL 以及响应状态码和执行时间\n- HEADERS：在 BASIC 的基础上，额外记录了请求和响应的头信息\n- FULL：记录所有请求和响应的明细，包括头信息、请求体、元数据。\n\n#### Java 代码方式\n\n也可以基于 Java 代码来修改日志级别，先声明一个类，然后声明一个 `Logger.Level` 的对象：\n\n```java\npublic class DefaultFeignConfiguration  {\n    @Bean\n    public Logger.Level feignLogLevel(){\n        return Logger.Level.BASIC; // 日志级别为BASIC\n    }\n}\n```\n\n如果要全局生效，将其放到启动类的 `@EnableFeignClients` 这个注解中：\n\n```java\n@EnableFeignClients(defaultConfiguration = DefaultFeignConfiguration .class) \n```\n\n如果是局部生效，则把它放到对应的 `@FeignClient` 这个注解中：\n\n```java\n@FeignClient(value = \"user-service\", configuration = DefaultFeignConfiguration .class)\n```\n\n### Feign 使用优化\n\nFeign 底层发起 http 请求，依赖于其它的框架。其底层客户端实现包括：\n\n+ URLConnection：默认实现，不支持连接池\n+ Apache HttpClient ：支持连接池\n+ OKHttp：支持连接池\n\n因此提高 Feign 的性能主要手段就是使用连接池代替默认的 URLConnection。\n\n这里我们用 Apache 的 HttpClient 来演示。\n\n#### 引入依赖\n\n在 order-service 的 pom 文件中引入 Apache 的 HttpClient 依赖：\n\n```xml\n<!--httpClient的依赖 -->\n<dependency>\n    <groupId>io.github.openfeign</groupId>\n    <artifactId>feign-httpclient</artifactId>\n</dependency>\n```\n\n#### 配置连接池\n\n在 order-service 的 application.yml 中添加配置：\n\n```yaml\nfeign:\n  client:\n    config:\n      default: # default 全局的配置\n        loggerLevel: BASIC # 日志级别，BASIC 就是基本的请求和响应信息\n  httpclient:\n    enabled: true # 开启 feign 对 HttpClient 的支持\n    max-connections: 200 # 最大的连接数\n    max-connections-per-route: 50 # 每个路径的最大连接数\n```\n\n#### Feign 的优化小结\n\n1. 日志级别尽量用 basic\n2. 使用 HttpClient（或 OKHttp ）代替 URLConnection\n   + 引入 feign-httpclient 依赖\n   + 配置文件开启 httpclient 功能，设置连接池参数\n\n## Feign 的最佳实践\n\n所谓最近实践，就是使用过程中总结的经验，最好的一种使用方式。\n\n仔细观察可以发现，Feign 的客户端与服务提供者的 controller 代码非常相似\n\nFeign客户端：\n\n```java\n@GetMapping(\"/user/{id}\")\nUser findById(@PathVariable(\"id\") Long id);\n```\n\nUserController：\n\n```java\n@GetMapping(\"/{id}\")\npublic User queryById(@PathVariable(\"id\") Long id) {\n    return userService.queryById(id);\n}\n```\n\n有没有一种办法简化这种重复的代码编写呢？\n\n### 继承方式\n\n一样的代码可以通过继承来共享：\n\n1. 定义一个 API 接口，利用定义方法，并基于 SpringMVC 注解做声明。\n2. Feign 客户端和 Controller 都集成改接口\n\n优点：简单、实现了代码共享\n\n缺点：\n\n+ 服务提供方、服务消费方紧耦合\n+ 参数列表中的注解映射并不会继承，因此 Controller 中必须再次声明方法、参数列表、注解\n\n### 抽取方式\n\n将 Feign 的 Client 抽取为独立模块，并且把接口有关的 POJO、默认的 Feign 配置都放到这个模块中，提供给所有消费者使用。\n\n例如，将 UserClient、User、Feign 的默认配置都抽取到一个 feign-api 包中，所有微服务引用该依赖包，即可直接使用。\n\n### 基于抽取的最佳实践实现\n\n#### 抽取\n\n首先创建一个 module，命名为 feign-api\n\n在 feign-api 中然后引入 feign 的 starter 依赖\n\n```xml\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-openfeign</artifactId>\n</dependency>\n```\n\n然后，order-service 中编写的 UserClient、User、DefaultFeignConfiguration 都剪切到 feign-api项目中\n\n#### 使用 feign-api\n\n在 order-service 的 pom 文件中中引入 feign-api 的依赖：\n\n```xml\n<dependency>\n    <groupId>cn.itcast.demo</groupId>\n    <artifactId>feign-api</artifactId>\n    <version>1.0</version>\n</dependency>\n```\n\n修改 order-service 中的所有与上述三个组件有关的导包部分，改成导入 feign-api 中的包\n\n#### 解决扫描包问题\n\norder-service 的 `@EnableFeignClients` 注解是在 cn.itcast.order 包下，不在同一个包，无法扫描到 UserClient。\n\n方式一，指定 Feign 应该扫描的包：\n\n```java\n@EnableFeignClients(basePackages = \"cn.itcast.feign.clients\")\n```\n\n方式二，指定需要加载的 Client 接口：\n\n```java\n@EnableFeignClients(clients = {UserClient.class})\n```\n\n## Gateway 服务网关\n\nSpring Cloud Gateway 是 Spring Cloud 的一个全新项目，该项目是基于 Spring 5.0，Spring Boot 2.0 和 Project Reactor 等响应式编程和事件流技术开发的网关，它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。\n\n### 为什么需要网关\n\nGateway 网关是我们服务的守门神，所有微服务的统一入口。\n\n网关的核心功能特性：\n\n- 请求路由\n- 权限控制\n- 限流\n\n权限控制：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。\n\n路由和负载均衡：一切请求都必须先经过 Gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。\n\n限流：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。\n\n在 Spring Cloud 中网关的实现包括两种：Gateway、Zuul\n\nZuul 是基于 Servlet 的实现，属于阻塞式编程。而 Spring Cloud Gateway 则是基于 Spring 5 中提供的 WebFlux，属于响应式编程的实现，具备更好的性能。\n\n### Gateway 快速入门\n\n下面，我们就演示下网关的基本路由功能。基本步骤如下：\n\n1. 创建 Maven 工程 gateway，引入网关依赖\n2. 编写启动类\n3. 编写基础配置和路由规则\n4. 启动网关服务进行测试\n\n#### 创建 Gateway 服务并引入依赖\n\n创建 gateway 服务，引入一下依赖：\n\n```xml\n<!--网关-->\n<dependency>\n    <groupId>org.springframework.cloud</groupId>\n    <artifactId>spring-cloud-starter-gateway</artifactId>\n</dependency>\n<!--nacos服务发现依赖-->\n<dependency>\n    <groupId>com.alibaba.cloud</groupId>\n    <artifactId>spring-cloud-starter-alibaba-nacos-discovery</artifactId>\n</dependency>\n```\n\n#### 编写启动类\n\n```java\npackage cn.itcast.gateway;\n\nimport org.springframework.boot.SpringApplication;\nimport org.springframework.boot.autoconfigure.SpringBootApplication;\n\n@SpringBootApplication\npublic class GatewayApplication {\n\n	public static void main(String[] args) {\n		SpringApplication.run(GatewayApplication.class, args);\n	}\n}\n```\n\n#### 编写基础配置和路由规则\n\n创建 application.yml 文件，内容如下：\n\n```yaml\nserver:\n  port: 10010 # 网关端口\nspring:\n  application:\n    name: gateway # 服务名称\n  cloud:\n    nacos:\n      server-addr: halo:8848 # nacos地址\n    gateway:\n      routes: # 网关路由配置\n        - id: user-service-gateway # 路由id，自定义，只要唯一即可\n          # uri: http://127.0.0.1:8081 # 路由的目标地址 http就是固定地址\n          uri: lb://user-service # 路由的目标地址 lb就是负载均衡，后面跟服务名称\n          predicates: # 路由断言，也就是判断请求是否符合路由规则的条件\n            - Path=/user/** # 这个是按照路径匹配，只要以/user/开头就符合要求\n```\n\n我们将符合 `Path` 规则的一切请求，都代理到 `uri` 参数指定的地址。\n\n本例中，我们将 `/user/**`开头的请求，代理到 `lb://user-service`，lb 是负载均衡，根据服务名拉取服务列表，实现负载均衡。\n\n#### 启动测试\n\n启动网关，访问 http://localhost:10010/user/1 时，符合`/user/**`规则，请求转发到 uri：http://userservice/user/1，得到了结果\n\n#### 网关路由的流程图\n\n![Gateway网关路由的流程图](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/Gateway网关路由的流程图.6onddfdjlr00.svg)\n\n#### Gateway 快速入门小结\n\n网关搭建步骤：\n\n1. 创建项目，引入 nacos 服务发现和 gateway 依赖\n\n2. 配置 application.yml，包括服务基本信息、nacos 地址、路由\n\n路由配置包括：\n\n1. 路由 id：路由的唯一标示\n\n2. 路由目标（uri）：路由的目标地址，http 代表固定地址，lb 代表根据服务名负载均衡\n\n3. 路由断言（predicates）：判断路由的规则，\n\n4. 路由过滤器（filters）：对请求或响应做处理\n\n### 断言工厂\n\n我们在配置文件中写的断言规则只是字符串，这些字符串会被 Predicate Factory 读取并处理，转变为路由判断的条件\n\n例如 `Path=/user/**` 是按照路径匹配，这个规则是由 `org.springframework.cloud.gateway.handler.predicate.PathRoutePredicateFactory` 类来处理的，像这样的断言工厂在 Spring Cloud Gateway 还有十几个：\n\n| 名称       | 说明                            | 示例                                                         |\n| ---------- | ------------------------------- | ------------------------------------------------------------ |\n| After      | 是某个时间点后的请求            | `-  After=2037-01-20T17:42:47.789-07:00[America/Denver]`     |\n| Before     | 是某个时间点之前的请求          | `-  Before=2031-04-13T15:14:47.433+08:00[Asia/Shanghai]`     |\n| Between    | 是某两个时间点之前的请求        | `-  Between=2037-01-20T17:42:47.789-07:00[America/Denver],  2037-01-21T17:42:47.789-07:00[America/Denver]` |\n| Cookie     | 请求必须包含某些 cookie         | `- Cookie=chocolate, ch.p`                                   |\n| Header     | 请求必须包含某些 header         | `- Header=X-Request-Id, \\d+`                                 |\n| Host       | 请求必须是访问某个 host（域名） | `-  Host=**.somehost.org,**.anotherhost.org`                 |\n| Method     | 请求方式必须是指定方式          | `- Method=GET,POST`                                          |\n| Path       | 请求路径必须符合指定规则        | `- Path=/red/{segment},/blue/**`                             |\n| Query      | 请求参数必须包含指定参数        | `- Query=name, Jack` 或者 `-  Query=name`                    |\n| RemoteAddr | 请求者的 ip 必须是指定范围      | `- RemoteAddr=192.168.1.1/24`                                |\n| Weight     | 权重处理                        |                                                              |\n\n详情查阅：[官方文档](https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gateway-request-predicates-factories)\n\n### 过滤器工厂\n\nGateway Filter 是网关中提供的一种过滤器，可以对进入网关的请求和微服务返回的响应做处理：\n\n![过滤器工厂](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/过滤器工厂.2sw963vwfry0.svg)\n\n#### 路由过滤器的种类\n\nSpring 提供了 31 种不同的路由过滤器工厂。例如：\n\n| 名称                   | 说明                         |\n| ---------------------- | ---------------------------- |\n| `AddRequestHeader`     | 给当前请求添加一个请求头     |\n| `RemoveRequestHeader`  | 移除请求中的一个请求头       |\n| `AddResponseHeader`    | 给响应结果中添加一个响应头   |\n| `RemoveResponseHeader` | 从响应结果中移除有一个响应头 |\n| `RequestRateLimiter`   | 限制请求的流量               |\n\n详情查阅：[官方文档](https://docs.spring.io/spring-cloud-gateway/docs/current/reference/html/#gatewayfilter-factories)\n\n#### 请求头过滤器\n\n下面我们以 `AddRequestHeader` 为例来讲解。\n\n需求：给所有进入 user-service 的请求添加一个请求头：Truth=Halo\n\n只需要修改 gateway 服务的 application.yml 文件，添加路由过滤即可：\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: user-service \n        uri: lb://userservice \n        predicates: \n        - Path=/user/** \n        filters: # 过滤器\n        - AddRequestHeader=Truth, Halo # 添加请求头\n```\n\n当前过滤器写在 user-service 路由下，因此仅仅对访问 user-service 的请求有效。\n\n#### 默认过滤器\n\n如果要对所有的路由都生效，则可以将过滤器工厂写到 default 下。格式如下：\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      routes:\n      - id: user-service \n        uri: lb://userservice \n        predicates: \n        - Path=/user/**\n      default-filters: # 默认过滤项\n      - AddRequestHeader=Truth, Halo\n```\n\n#### 过滤器工厂总结\n\n过滤器的作用是什么？\n\n+ 对路由的请求或响应做加工处理，比如添加请求头\n+ 配置在路由下的过滤器只对当前路由的请求生效\n\ndefaultFilters 的作用是什么？\n\n+ 对所有路由都生效的过滤器\n\n### 全局过滤器\n\n上一节学习的过滤器，网关提供了 31 种，但每一种过滤器的作用都是固定的。如果我们希望拦截请求，做自己的业务逻辑则没办法实现。\n\n#### 全局过滤器作用\n\n全局过滤器的作用也是处理一切进入网关的请求和微服务响应，与 GatewayFilter 的作用一样。\n\n两者的区别在于： \n\n+ GatewayFilter 通过配置定义，处理逻辑是固定的；\n+ GlobalFilter 的逻辑需要自己写代码实现。\n\n定义方式是实现 GlobalFilter 接口。\n\n```java\npublic interface GlobalFilter {\n    /**\n     *  处理当前请求，有必要的话通过{@link GatewayFilterChain}将请求交给下一个过滤器处理\n     *\n     * @param exchange 请求上下文，里面可以获取Request、Response等信息\n     * @param chain 用来把请求委托给下一个过滤器 \n     * @return {@code Mono<Void>} 返回标示当前过滤器业务结束\n     */\n    Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain);\n}\n```\n\n在 filter 中编写自定义逻辑，可以实现下列功能：\n\n- 登录状态判断\n- 权限校验\n- 请求限流等\n\n#### 自定义全局过滤器\n\n需求：定义全局过滤器，拦截请求，判断请求的参数是否满足下面条件：\n\n- 参数中是否有 authorization，\n\n- authorization 参数值是否为 admin\n\n如果同时满足则放行，否则拦截\n\n实现，在 gateway 中定义一个过滤器：\n\n```java\n@Order(-1)\n@Component\npublic class AuthorizeFilter implements GlobalFilter {\n    @Override\n    public Mono<Void> filter(ServerWebExchange exchange, GatewayFilterChain chain) {\n        // 1. 获取请求参数\n        ServerHttpRequest request = exchange.getRequest();\n        MultiValueMap<String, String> queryParams = request.getQueryParams();\n        // 2. 获取参数中的 authorization\n        String auth = queryParams.getFirst(\"authorization\");\n        // 3. 判断参数值是否等于 admin\n        if (\"admin\".equals(auth)) {\n            // 放行\n            return chain.filter(exchange);\n        }\n        // 拦截\n        // 设置状态码\n        exchange.getResponse().setStatusCode(HttpStatus.UNAUTHORIZED);\n        // 拦截请求\n        return exchange.getResponse().setComplete();\n    }\n}\n```\n\n`@Order(-1)` 用于指定过滤器顺序，值越小优先级越高\n\n重启网关，访问 http://localhost:10010/user/1?authorization=admin\n\n#### 过滤器执行顺序\n\n请求进入网关会碰到三类过滤器：当前路由的过滤器、DefaultFilter、GlobalFilter\n\n请求路由后，会将当前路由过滤器和 DefaultFilter、GlobalFilter，合并到一个过滤器链（集合）中，排序后依次执行每个过滤器：\n\n![过滤器执行顺序](https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/过滤器执行顺序.4mfcqien0h60.svg)\n\n排序的规则是什么呢？\n\n- 首先，每一个过滤器都必须指定一个 int 类型的 order 值，order 值越小，优先级越高，执行顺序越靠前。\n- GlobalFilter 通过实现 Ordered 接口，或者添加 `@Order` 注解来指定 order 值，由我们自己指定。路由过滤器和 defaultFilter 的 order 由 Spring 指定，默认是按照声明顺序从 1 递增。\n- 当过滤器的 order 值一样时，会按照 defaultFilter、路由过滤器、GlobalFilter 的顺序执行。\n\n详细内容，可以查看源码：\n\n+ `org.springframework.cloud.gateway.route.RouteDefinitionRouteLocator#getFilters()` 方法是先加载 defaultFilters，然后再加载某个 route 的 filters，然后合并。\n+ `org.springframework.cloud.gateway.handler.FilteringWebHandler#handle()` 方法会加载全局过滤器，与前面的过滤器合并后根据order排序，组织过滤器链\n\n### 跨域问题\n\n#### 什么是跨域问题\n\n跨域：域名不一致就是跨域，主要包括：\n\n- 域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com\n\n- 域名相同，端口不同：localhost:8080 和 localhost8081\n\n跨域问题：浏览器禁止请求的发起者与服务端发生跨域 Ajax 请求，请求被浏览器拦截的问题\n\nCORS 解决方案，参考资料：https://www.ruanyifeng.com/blog/2016/04/cors.html\n\n#### 解决跨域问题\n\n在 gateway 服务的 application.yml 文件中，添加下面的配置：\n\n```yaml\nspring:\n  cloud:\n    gateway:\n      # .\n      globalcors: # 全局的跨域处理\n        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题\n        corsConfigurations:\n          \'[/**]\':\n            allowedOrigins: # 允许哪些网站的跨域请求 \n              - \"http://localhost:8090\"\n            allowedMethods: # 允许的跨域ajax的请求方式\n              - \"GET\"\n              - \"POST\"\n              - \"DELETE\"\n              - \"PUT\"\n              - \"OPTIONS\"\n            allowedHeaders: \"*\" # 允许在请求中携带的头信息\n            allowCredentials: true # 是否允许携带cookie\n            maxAge: 360000 # 这次跨域检测的有效期\n```\n\n\n\n\n\n\n\n\n\n', '2021-09-27 17:53:02', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 1, '2021-09-27 17:57:45', NULL, NULL, NULL, 1, 1, 0, NULL, 0);
INSERT INTO `m_blog` VALUES (16, 1, '141324', '1342142', '32441234', '2021-10-09 15:15:50', 1, 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-e@master/macos.6z1mshl4twk0.svg', 0, '2021-10-09 15:15:50', NULL, NULL, NULL, 1, 1, 0, NULL, 0);

-- ----------------------------
-- Table structure for m_blog_sort
-- ----------------------------
DROP TABLE IF EXISTS `m_blog_sort`;
CREATE TABLE `m_blog_sort`  (
  `id` bigint NOT NULL AUTO_INCREMENT COMMENT '唯一uid',
  `sort_name` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '分类内容',
  `content` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '分类简介',
  `create_time` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime NULL DEFAULT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `status` tinyint UNSIGNED NOT NULL DEFAULT 1 COMMENT '状态',
  `sort` int NULL DEFAULT 0 COMMENT '排序字段，越大越靠前',
  `click_count` int NULL DEFAULT 0 COMMENT '点击数',
  `user_id` bigint NULL DEFAULT NULL,
  `deleted` tinyint(1) NULL DEFAULT 0,
  PRIMARY KEY (`id`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 3 CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '博客分类表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of m_blog_sort
-- ----------------------------
INSERT INTO `m_blog_sort` VALUES (1, 'Java', 'Java', '2021-09-23 21:36:50', '2021-09-23 21:36:50', 1, 0, 0, 1, 0);
INSERT INTO `m_blog_sort` VALUES (2, 'Docker', 'Docker', '2021-09-23 21:37:01', '2021-09-23 21:37:01', 1, 0, 0, 1, 0);

-- ----------------------------
-- Table structure for m_blog_tag
-- ----------------------------
DROP TABLE IF EXISTS `m_blog_tag`;
CREATE TABLE `m_blog_tag`  (
  `uid` varchar(32) CHARACTER SET utf8 COLLATE utf8_general_ci NOT NULL COMMENT '唯一uid',
  `content` varchar(1000) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL COMMENT '标签内容',
  `status` tinyint UNSIGNED NOT NULL DEFAULT 1 COMMENT '状态：1[启用]，2[删除]',
  `click_count` int NULL DEFAULT 0 COMMENT '标签简介',
  `create_time` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '创建时间',
  `update_time` datetime NOT NULL ON UPDATE CURRENT_TIMESTAMP COMMENT '更新时间',
  `sort` int NULL DEFAULT 0 COMMENT '排序字段，越大越靠前',
  PRIMARY KEY (`uid`) USING BTREE
) ENGINE = InnoDB CHARACTER SET = utf8 COLLATE = utf8_general_ci COMMENT = '标签表' ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of m_blog_tag
-- ----------------------------

-- ----------------------------
-- Table structure for m_user
-- ----------------------------
DROP TABLE IF EXISTS `m_user`;
CREATE TABLE `m_user`  (
  `id` bigint NOT NULL AUTO_INCREMENT,
  `username` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `avatar` varchar(255) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-f@master/image.4skloqie47w0.png',
  `email` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `password` varchar(64) CHARACTER SET utf8 COLLATE utf8_general_ci NULL DEFAULT NULL,
  `status` int NOT NULL DEFAULT 0,
  `created` datetime NULL DEFAULT NULL,
  `last_login` datetime NULL DEFAULT NULL,
  PRIMARY KEY (`id`) USING BTREE,
  INDEX `UK_USERNAME`(`username`) USING BTREE
) ENGINE = InnoDB AUTO_INCREMENT = 9 CHARACTER SET = utf8 COLLATE = utf8_general_ci ROW_FORMAT = Dynamic;

-- ----------------------------
-- Records of m_user
-- ----------------------------
INSERT INTO `m_user` VALUES (1, 'HALO', 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-f@master/image.4skloqie47w0.png', '1379978893@qq.com', '96e79218965eb72c92a549dd5a330112', 0, '2021-09-18 15:38:39', NULL);
INSERT INTO `m_user` VALUES (3, 'hhhh545', 'https://cube.elemecdn.com/3/7c/3ea6beec64369c2642b92c6726f1epng.png', '4545454@qq.com', '96e79218965eb72c92a549dd5a330112', 0, '2021-09-26 12:08:53', NULL);
INSERT INTO `m_user` VALUES (4, 'hhhh3424', 'https://cube.elemecdn.com/3/7c/3ea6beec64369c2642b92c6726f1epng.png', '34233@qq.com', '96e79218965eb72c92a549dd5a330112', 0, '2021-09-26 21:43:32', NULL);
INSERT INTO `m_user` VALUES (9, 'hhhh', 'https://cdn.jsdelivr.net/gh/halo-blog/cdn-blog-img-f@master/image.4skloqie47w0.png', '13799788936@qq.com', '96e79218965eb72c92a549dd5a330112', 0, '2021-10-09 15:08:09', NULL);

SET FOREIGN_KEY_CHECKS = 1;
